<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Innodb索引和B+树]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F21%2FInnodb%E7%B4%A2%E5%BC%95%E5%92%8CB-%E6%A0%91%2F</url>
    <content type="text"><![CDATA[InnoDB 存储引擎在绝大多数情况下使用 B+ 树建立索引，这是关系型数据库中查找最为常用和有效的索引。 1.Innodb存储引擎索引概述Innodb存储引擎支持两种常见的索引：B+树索引和哈希索引。Innodb支持哈希索引是自适应的，Innodb会根据表的使用情况自动生成哈希索引。B+树索引就是传统意义上的索引，是关系型数据库中最常用最有效的索引。B+树是从最早的平衡二叉树演变而来，但是B+树不是一个二叉树。B+中的B不代表二叉(Binary),而是代表平衡(Balance)。 注意：B+树索引并不能找到一个键值对应的具体行，只能找到被查找数据行所在的页，然后数据库通过把页读入内存，再在内存中查找，最后得到结果。 2.理解B+树算法B+树是为磁盘及其他存储辅助设备而设计一种平衡查找树（不是二叉树）。B+树中，所有记录的节点按大小顺序存放在同一层的叶节点中，各页节点用指针进行连接。 下面演示一个B+数结构，高度为2，每页可放4条记录，扇出(fan out)为5。从下图1可以看出，所有记录都在页节点中，并且为顺序存放，我们从最左边的叶节点开始遍历，可以得到所有键值的顺序排序：5、10、15、20、25、30、50、55、60、65、75、80、85、90.图1 高度为2的B+树 （1） B+树的插入操作B+树的插入必须保证插入后叶节点的记录依然排序，同时要考虑插入B+树的三种情况，每种情况都可能导致不同的插入算法。如下表所示： Leaf Page Full Index Page Full 操作 No No 直接将记录插入叶节点 Yes No 1.拆分LeafPage 2.将中间的节点放入IndexPage 3.小于中间节点的记录放左边 4.大于等于中间节点的记录放右边 Yes Yes 1.拆分LeafPage 2.小于中间节点的记录放左边 3.大于等于中间节点的记录放右边 4.拆分IndexPage 5.小于中间节点的记录放左边 6.大于中间节点的记录放右边 7.中间节点放入上一层IndexPage 我们实例分析B+树的插入，在图1的B+树中，我们需要插入28这个值。因为Leaf Page和Index page都没有满，我们直接将记录插入叶节点就可以了。如下图所示：图2 插入键值28 下面我们再插入70这个值，这时Leaf Page已经满了，但是Index Page还没有满，符合上面的第二种情况。这时插入Leaf Page的情况为50、55、60、65、70.我们根据中间的值60拆分叶节点，可得到下图3所示（双向链表指针依然存在，没有画出）：图3 插入键值70 最后我们再插入95，这个Leaf Page和Index Page都满了，符合上面第三种情况。需要做2次拆分，如下图4所示：图4 插入键值95 可以看到，不管怎么变化，B+树总会保持平衡。可是为了保持平衡，对于新插入的键值可能需要做大量的拆分页动作。B+树主要用于磁盘，拆分意味这磁盘的操作，应该在可能的情况下尽可能减少对页的拆分。因此，B+树提供了旋转功能。旋转发在LeafPage已经满了，但是左右兄弟节点没有满的情况下。这时B+树并不是急着做页的拆分，而是将记录移到所在页的兄弟节点上。通常情况下，左兄弟被首先检查用来做旋转操作，这时我们插入键值70，其实B+树并不会急于去拆分叶节点，而是做旋转，50，55，55旋转。图5 B+树的旋转操作 (2) B+树的删除操作B+树使用填充因子来控制树的删除变化，填充因子可以设置的最小值为50%，B+树的删除操作同样保证删除后叶节点的记录依然排序。根据填充因子的变化，B+树删除依然需要考虑三种情况，如下表所示： Leaf Page Below Fill Factor Index Page Below Fill Factor 操作 No No 直接将记录从叶节点删除，如果改节点还是Index Page中的节点，则用该节点的右节点代替 Yes No 合并叶节点及其兄弟节点，同时更新Index Page Yes Yes 1.合并叶节点及其兄弟节点 2.更新Index Page 3.合并Index Page及其兄弟节点 根据图4的B+树，我们进行删除操作，首先删除键值为70的这条记录，该记录符合上表第一种情况，删除后如下图6所示：图6 删除键值70 接着我们删除键值为25的记录，这也是第一种情况，但是该值还是Index Page中的值，因此在删除Leaf Page中25的值后，还应将25的右兄弟节点的28更新到Page Index中，最后可得到图。图7 删除键值28 最后我们来看删除键值为60的情况，删除Leaf Page中键值为60的记录后，填充因子小于50%，这时需要做合并操作，同样，在删除Index Page中相关记录后需要做Index Page的合并操作，最后得到图。 三、B+树索引介绍B+树索引的本质是B+树在数据库中的实现。但是B+树有一个特点是高扇出性，因此在数据库中，B+树的高度一般在2到3层。也就是说查找某一键值的记录，最多只需要2到3次IO开销。按磁盘每秒100次IO来计算，查询时间只需0.0.2到0.03秒。 数据库中B+索引分为聚集索引（clustered index）和非聚集索引（secondary index）。这两种索引的共同点是内部都是B+树，高度都是平衡的，叶节点存放着所有数据。不同点是叶节点是否存放着一整行数据。 (1) 聚集索引Innodb存储引擎表是索引组织表，即表中数据按主键顺序存放。而聚集索引就是按每张表的主键构造一棵B+树，并且叶节点存放整张表的行记录数据。每张表只能有一个聚集索引（一个主键）。聚集索引的另一个好处是它对于主键的排序查找和范围的速度非常快，叶节点的数据就是我们要找的数据。 主键排序查找：例如我们要找出最新的10位女生，由于B+树是双项链表，我们可以迅速找到最后一个页，并取出10条记录，我们用Explain进行分析：12345678910111213explain select * from girl order by id desc limit 10*************************** 1. row *************************** id: 1 select_type: SIMPLE table: girl type: indexpossible_keys: NULL key: PRIMARY key_len: 4 ref: NULL rows: 10 Extra:1 row in set (0.00 sec) 主键范围查找：如果要通过主键查找某一范围内的数据，通过叶节点的上层中间节点就能得到页的范围，之后直接读取数据页即可：12345678910111213explain select * from girl where id&gt;10000000 and id&lt;12000000*************************** 1. row *************************** id: 1 select_type: SIMPLE table: girl type: rangepossible_keys: PRIMARY key: PRIMARY key_len: 8 ref: NULL rows: 4301486 Extra: Using where1 row in set (0.00 sec) (2) 辅助索引辅助索引（也称非聚集索引）。叶级别不包含行的全部数据，叶级别除了包含行的键值外，每个索引行还包含了一个书签（bookmark），该书签告诉InnoDB存储引擎，哪里可以找到与索引对应的数据，辅助索引的存在并不影响数据在聚集索引中的组织，因此一个表可以有多个辅助索引。当通过辅助索引查找数据时，innodb会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键。然后再通过主键索引找到一行完整的数据。 (3) B+树索引的管理索引的创建和删除可以用两种方式。一种是alter table,另一种是create/drop index alter table 创建和删除索引的语法为：1234567ALTER [ONLINE | OFFLINE] [IGNORE] TABLE tbl_name | ADD &#123;INDEX|KEY&#125; [index_name] [index_type] (index_col_name,…) [index_option] …ALTER [ONLINE | OFFLINE] [IGNORE] TABLE tbl_name | DROP PRIMARY KEY | DROP &#123;INDEX|KEY&#125; index_name create/drop index的语法为：12345CREATE [ONLINE|OFFLINE] [UNIQUE|FULLTEXT|SPATIAL] INDEX index_name [index_type] ON tbl_name (index_col_name,…)DROP [ONLINE|OFFLINE] INDEX index_name ON tbl_name MySQL索引注意的问题：对于MySQL索引的添加与删除，mysql先是创建一张加好索引的临时表，然后把数据导入临时表，再删除原表，把临时表重命名为原表。 Innodb存储引擎从Innodb Plugin版本开始，支持一种快速创建索引的方法（只限于辅助索引，主键索引仍需要临时建表）。首先对表加S锁，在创建的过程中不需要重建表，但是由于加上了S锁，在创建索引的过程中只能进行查询操作，不能更新数据。 B+树索引的使用(1).什么时候使用B+索引当查询表中很少一部分数据时，B+索引才有意义。对于性别，地区类型字段，他们的取值范围很小，即 低选择性 。这时B+索引是没有必要的。相反，某个字段取值范围很广，如姓名，几乎没有重复，即 高选择性 。则使用B+索引是比较合适的。因此。当访问高选择性字段并取出很少一部分数据时，该字段加B+索引是非常有效的。但是当取出的数据行占表中大部分数据时，数据库就不会使用B+索引了。 举例说明下，看下面这个团购订单表groupon_so的部分索引：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071show index from groupon_so;*************************** 1. row *************************** Table: groupon_so Non_unique: 0 Key_name: PRIMARY Seq_in_index: 1 Column_name: id Collation: A Cardinality: 10088342 Sub_part: NULL Packed: NULL Null: Index_type: BTREE Comment:Index_comment:*************************** 2. row *************************** Table: groupon_so Non_unique: 1 Key_name: idx_groupon_so_order_id Seq_in_index: 1 Column_name: order_id Collation: A Cardinality: 10088342 Sub_part: NULL Packed: NULL Null: Index_type: BTREE Comment:Index_comment:*************************** 3. row *************************** Table: groupon_so Non_unique: 1 Key_name: idx_groupon_so_order_code Seq_in_index: 1 Column_name: order_code Collation: A Cardinality: 10088342 Sub_part: NULL Packed: NULL Null: Index_type: BTREE Comment:Index_comment:*************************** 4. row *************************** Table: groupon_so Non_unique: 1 Key_name: idx_groupon_so_end_user_id Seq_in_index: 1 Column_name: end_user_id Collation: A Cardinality: 10088342 Sub_part: NULL Packed: NULL Null: YES Index_type: BTREE Comment:Index_comment:*************************** 5. row *************************** Table: groupon_so Non_unique: 1 Key_name: idx_groupon_so_groupon_id Seq_in_index: 1 Column_name: groupon_id Collation: A Cardinality: 148357 Sub_part: NULL Packed: NULL Null: Index_type: BTREE Comment:Index_comment: 其中有一个索引 idx_groupon_so_order_id ，这个索引里面字段订单号的值都是不重复的，是高选择性的字段。我们查找order_id为 99165590 的这条记录，执行计划如下：12345678910111213explain select * from groupon_so where order_id=99165590*************************** 1. row *************************** id: 1 select_type: SIMPLE table: groupon_so type: refpossible_keys: idx_groupon_so_order_id key: idx_groupon_so_order_id key_len: 8 ref: const rows: 1 Extra:1 row in set (0.00 sec) 可以看到使用了idx_groupon_so_order_id这个索引，符合高选择性，取少部分数据这个特性。但是如果执行下面这条语句：12345678910111213explain select * from groupon_so where order_id&gt;99165590;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: groupon_so type: ALLpossible_keys: idx_groupon_so_order_id key: NULL key_len: NULL ref: NULL rows: 10092839 Extra: Using where1 row in set (0.00 sec) 可以看到possible_keys依然是idx_groupon_so_order_code，但是索引优化使用的索引keys显示的是NULL，因为虽然这个字段是高选择性的，但是我们取出了表中的大部分数据，索引没有用到索引。1234567891011121314151617181920212223select @a:=count(id) from groupon_so where order_id&gt;99165590;+—————+| @a:=count(id) |+—————+| 8684424 |+—————+1 row in set (2.48 sec)select @a:=count(id) from groupon_so;+—————+| @a:=count(id) |+—————+| 9858135 |+—————+1 row in set (1.86 sec)select 8684424/9858135;+—————–+| 8684424/9858135 |+—————–+| 0.8809 |+—————–+1 row in set (0.00 sec) 可以看到我们取出了表中88%的数据，索引没有用到索引。 (2)顺序读、随机读与预读取顺序读是指顺序的读取磁盘上的块，随机读是指访问的块是不连续的，需要磁盘的磁头不断移动。随机读的性能是远远低于顺序读的。在数据库中，顺序读根据索引的叶节点就能顺序的读取所需的行数据，这个顺序读只是逻辑的顺序读，在磁盘上还可能是随机读。随机读是指访问辅助索引叶节点不能完全得到结果，需要根据辅助索引叶节点中的主键去寻找实际数据行。对于一些取表里很大部分的数据，正是因为读取是随机读，而随机读的性能会远低于顺序读，所以优化器才会选择全部扫描顺序读，而不使用索引。 Innodb存储引擎有两种预读取方式，随机预读取和线性预读取。随机预读取是指当一个区（共64个连续页）中有13个页在缓冲区中并被频繁访问时，Innodb存储引擎会将这个区中剩余的页预读到缓冲区。线性预读取基于缓冲池中页的访问方式，而不是数量。如果一个区中有24个页被顺序访问了，则Innodb会读取下一个区中所有的页到缓冲区。但是Innodb预读取经过测试后性能比较差，经过TPCC测试发现禁用预读取比启用预读取提高了10%的性能。在新版本Innodb中，mysql禁用了随机预读取，仅保留了线性预读取，并且加入了innodb_read_ahead_threshold参数，当连续访问页超过该值时才启用预读取，默认值为56。1234567show variables like &apos;innodb_read_ahead_threshold%&apos;;+—————————–+——-+| Variable_name | Value |+—————————–+——-+| innodb_read_ahead_threshold | 56 |+—————————–+——-+1 row in set (0.00 sec) (3)辅助索引的优化通过前面可知，辅助索引的叶节点包含主键，但是辅助索引的叶节点并不包含完整的行数据信息，因此，Innodb存储引擎总是会从辅助索引的叶节点判断是否能得到数据，让我们看个例子：1234567891011121314create table t (a int not null, b varchar(20), primary key(a),key(b));Query OK, 0 rows affected (0.18 sec)insert into t select 1, &apos; kangaroo&apos;;Query OK, 1 row affected (0.00 sec)Records: 1 Duplicates: 0 Warnings: 0insert into t select 2,&apos;dolphin&apos;;Query OK, 1 row affected (0.01 sec)Records: 1 Duplicates: 0 Warnings: 0insert into t select 3,&apos;dragon&apos;;Query OK, 1 row affected (0.01 sec)Records: 1 Duplicates: 0 Warnings: 0insert into t select 4,&apos;anteloge&apos;;Query OK, 1 row affected (0.01 sec)Records: 1 Duplicates: 0 Warnings: 0 如果执行select * from t很多人认为应该是如下结果：1234567891011121314mysql&gt; select * from t order by a;*************************** 1. row ***************************a: 1b: kangaroo*************************** 2. row ***************************a: 2b: dolphin*************************** 3. row ***************************a: 3b: dragon*************************** 4. row ***************************a: 4b: anteloge4 rows in set (0.00 sec) 但是实际执行结果确是：1234567891011121314mysql&gt; select * from t;*************************** 1. row ***************************a: 4b: anteloge*************************** 2. row ***************************a: 2b: dolphin*************************** 3. row ***************************a: 3b: dragon*************************** 4. row ***************************a: 1b: kangaroo4 rows in set (0.00 sec) 因为辅助索引包含了主键a的值，因此访问b列上的辅助索引就可以得到a的值，这样就可以得到表中所有的数据。我们看这条语句的执行计划：12345678910111213mysql&gt; explain select * from t;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: t type: indexpossible_keys: NULL key: b key_len: 23 ref: NULL rows: 4 Extra: Using index1 row in set (0.00 sec) 可以看到优化器最终走的索引b,如果想对a列进行排序，则需要进行order by操作：123456789101112131415161718192021222324252627mysql&gt; explain select * from t order by a;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: t type: indexpossible_keys: NULL key: PRIMARY key_len: 4 ref: NULL rows: 4 Extra: NULL1 row in set (0.00 sec)mysql&gt; select * from t order by a;*************************** 1. row ***************************a: 1b: kangaroo*************************** 2. row ***************************a: 2b: dolphin*************************** 3. row ***************************a: 3b: dragon*************************** 4. row ***************************a: 4b: anteloge 或者使用主键强制得到结果：1234567891011121314mysql&gt; select * from t force index(PRIMARY);*************************** 1. row ***************************a: 1b: kangaroo*************************** 2. row ***************************a: 2b: dolphin*************************** 3. row ***************************a: 3b: dragon*************************** 4. row ***************************a: 4b: anteloge4 rows in set (0.00 sec) (4)联合索引联合索引是指对表中多个列做索引，联合索引的创建方法和之前的一样，如下：123mysql&gt; alter table t add key idx_a_b(a,b);Query OK, 0 rows affected (0.17 sec)Records: 0 Duplicates: 0 Warnings: 0 联合索引还是一个B+树，不同的是联合索引键值的数量不是1，而是大于等于2.下面我们讨论一个两个整形列组成的联合索引，假定两个键值的名称分别为a和b，如下图8所示，每个节点上有两个键值，(1,1),(1,2),(2,1),(2,4),(3,1),(3,2), 数据按(a,b)顺序进行排列图8 多个键值的B+树 因此，对于查询select from t where a=xxx and b=xxx,显然可以使用(a,b)这个联合索引。对于单个a列查询 select from t where a=xxx也是可以使用(a,b)这个索引。但是对于b列的查询select * from t where b=xxx是用不到这颗B+树索引。可以看到叶节点上b的值为1、2、1、4、1、2.显然不是排序的，因此b列的查询使用不到(a,b)索引。 联合索引的第二个好处是，可以对第二键值进行排序。例如很多情况下我们需要查询某个用户的购物情况，并按照时间排序，取出最近3次的购买记录，这时使用联合索引可以避免多一次的排序操作。因为索引本身在叶节点中已经排序了。看下面示例：12345678910111213141516171819202122232425262728293031mysql&gt; create table buy_log(userid int unsigned not null, buy_date date);Query OK, 0 rows affected (0.09 sec)mysql&gt; insert into buy_log values(1,&apos;2013-01-01&apos;);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into buy_log values(2,&apos;2013-01-01&apos;);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into buy_log values(3,&apos;2013-01-01&apos;);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into buy_log values(1,&apos;2013-02-01&apos;);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into buy_log values(3,&apos;2013-02-01&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into buy_log values(1,&apos;2013-03-01&apos;);Query OK, 1 row affected (0.01 sec)mysql&gt; insert into buy_log values(1,&apos;2013-04-01&apos;);Query OK, 1 row affected (0.01 sec)mysql&gt; alter table buy_log add key(userid);Query OK, 0 rows affected (0.07 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; alter table buy_log add key(userid,buy_date);Query OK, 0 rows affected (0.11 sec)Records: 0 Duplicates: 0 Warnings: 0 上面我们建立了测试表和数据，建立了2个索引来比较。两个索引都包含了userid字段。如果只对于userid查询，优化器的选择是：12345678910111213mysql&gt; explain select * from buy_log where userid=2\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: buy_log type: refpossible_keys: userid,userid_2 key: userid key_len: 4 ref: const rows: 1 Extra: NULL1 row in set (0.00 sec) 可以看到possible_keys里面两个索引都可以使用，分别是单个的userid索引和userid,buy_date的联合索引。但是优化器最终选择的是userid，因为该叶节点包含单个键值，因此一个页存放的记录应该更多。 接下来看以下的查询，假定要取出userid=1最近的3次购买记录，分别使用单个索引和联合索引的区别：12345678910111213mysql&gt; explain select * from buy_log where userid=1 order by buy_date desc limit 3\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: buy_log type: refpossible_keys: userid,userid_2 key: userid_2 key_len: 4 ref: const rows: 4 Extra: Using where; Using index1 row in set (0.00 sec) 同样对于上述SQL，两个索引都可使用，但是查询优化器使用了userid和buy_date组成的联合索引userid_2.因为这个联合索引中buy_date已经排序好了，可以减少一次排序操作。12345678910111213mysql&gt; explain select * from buy_log force index(userid) where userid=1 order by buy_date desc limit 3\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: buy_log type: refpossible_keys: userid key: userid key_len: 4 ref: const rows: 4 Extra: Using where; Using filesort1 row in set (0.00 sec) 在Extra这里可以看到Using filesort，Using filesort指排序，但不一定是在文件中完成。 转载自： http://www.niceru.com/topic/420.html]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>Innodb</tag>
        <tag>B+树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础课程09]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F20%2FLinux%E5%9F%BA%E7%A1%80%E8%AF%BE%E7%A8%8B09%2F</url>
    <content type="text"><![CDATA[这一节我们来学习用nmtui命令配置网卡参数，通过nmcli命令查看网卡网络信息并管理网卡会话服务，让您能够在不同工作场景中快速地切换网卡网络参数，以及学习手工绑定mode6模式双网卡来实现对网络的负载均衡及冗余技术。深入了解ssh协议与sshd服务程序的理论知识，掌握对Linux系统的远程管理方法以及Linux系统中服务程序的配置方法，实践操作基于密钥验证的sshd服务程序远程验证登录，并学习用screen服务程序实现远程管理Linux系统的不间断会话技术。 配置网卡服务配置网卡参数在接下来学习配置服务之前，还必须先保证系统主机之间是否能够顺畅进行数据传输的，因为如果网络不通，那么即使各项服务部署得再好也不能让用户顺利的访问到，所以配置网络是正式学习部署服务前的最后一门重要知识。 先来学习用nmtui命令来配置网卡吧：1.执行nmtui命令来运行网络配置工具[root@localhost ~]# nmtui2.选中“编辑一个网卡连接(Edit a connection)”并敲击回车3.选中要编辑的网卡名称，然后敲击“编辑(Edit)”选项4.把网卡Ipv4配置方式改成“手动(Manual)”5.然后点击“显示(Show)”按钮来显示信息配置框6.填写入IP地址和网关信息7.点击网卡配置框最下面的确认按钮来保存配置8.点击界面最下面的来退出网卡编辑工具 虽然配置Linux系统网卡的步骤到此就已经可以结束了，但有时在安装红帽RHEL7系统的时候默认没有激活网卡，如果真遇到了这种情况也不用担心，只需要使用vim编辑器来将网卡配置文件中的ONBOOT参数修改成yes就可以保证网卡会在系统重启后依然生效了。1234567891011121314151617[root@localhost ~]# vim /etc/sysconfig/network-scripts/ifcfg-eno16777728TYPE=EthernetBOOTPROTO=noneDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noNAME=eno16777728UUID=b6dd5c6f-2b82-49c2-b218-bea21c5c9ae2ONBOOT=yes --！！！HWADDR=00:0C:29:0E:6A:ACIPADDR0=192.168.139.128PREFIX0=24IPV6_PEERDNS=yesIPV6_PEERROUTES=yes Linux系统的服务配置文件修改过后并不会对服务程序立即产生效果，要想让服务程序获取到最新的配置文件内容，咱们还需要手动的重启一下相应的服务~然后就能看到网络畅通了：1234567891011[root@localhost ~]# systemctl restart network[root@localhost ~]# ping -c 4 192.168.139.128PING 192.168.139.128 (192.168.139.128) 56(84) bytes of data.64 bytes from 192.168.139.128: icmp_seq=1 ttl=64 time=0.081 ms64 bytes from 192.168.139.128: icmp_seq=2 ttl=64 time=0.046 ms64 bytes from 192.168.139.128: icmp_seq=3 ttl=64 time=0.047 ms64 bytes from 192.168.139.128: icmp_seq=4 ttl=64 time=0.029 ms--- 192.168.139.128 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 2999msrtt min/avg/max/mdev = 0.029/0.050/0.081/0.020 ms 创建网络会话在红帽系统中一直默认使用这NetworkManager服务来提供网络服务，这是一种动态管理配置网络的守护进程服务，能够让网络设备连接保持工作状态，可以使用类似nmcli的命令来管理NetworkManager服务。nmcli命令是一款基于命令行终端的网卡配置管理工具，虽然功能强大但是参数复杂，它不仅能够轻松地查看网卡信息或网络状态，还可以管理网卡会话功能，更能够查看网络设备的具体详细信息：123456789101112131415161718[root@localhost ~]# nmcli connection showNAME UUID TYPE DEVICE eno16777728 b6dd5c6f-2b82-49c2-b218-bea21c5c9ae2 802-3-ethernet eno16777728[root@localhost ~]# nmcli con show eno16777728connection.id: eno16777728connection.uuid: b6dd5c6f-2b82-49c2-b218-bea21c5c9ae2connection.interface-name: --connection.type: 802-3-ethernetconnection.autoconnect: yesconnection.timestamp: 1505911856connection.read-only: noconnection.permissions: connection.zone: --connection.master: --connection.slave-type: --connection.secondaries: connection.gateway-ping-timeout: 0...... 另外在红帽RHEL7系统中的网卡服务已经支持多会话技术了，这个功能非常类似FireWalld防火墙服务中的zone区域技术，让用户能够在多个配置文件中快速切换。比如白天需要拿着笔记本电脑去公司上班，下午去咖啡厅休息一下，然后晚上再把笔记本电脑拿回到家中，如果在公司上班工作的时候是需要手工指定网卡IP地址，而晚上回家后用无线路由器是DHCP自动分配网卡IP地址，对传统网卡服务这样改来改去一定会很麻烦，但是使用了网卡会话功能就不一样了，咱们只需要在不同的使用环境中激活相应的会话服务，就能对网卡参数进行整体性的自动切换了。 可以使用nmcli命令将在公司上班时的网卡会话叫做company，而在家里的网卡会话叫做house，然后按照connection(会话),add(添加动作),con-name(会话名称),type(网卡类型),ifname(网卡名称)的格式来创建网卡会话就可以了，例如依次创建公司和家庭的网卡会话：1234[root@localhost ~]# nmcli connection add con-name company ifname eno16777728 autoconnect no type ethernet ip4 192.168.139.128/24 gw4 192.168.139.1Connection &apos;company&apos; (c0ec1b4a-6de3-47f1-9c2c-5c92ec69b7a2) successfully added.[root@localhost ~]# nmcli connection add con-name house type ethernet ifname eno16777728Connection &apos;house&apos; (5bb6fe21-8b5e-467d-b2d4-27ca6f8fd9b0) successfully added. 成功创建网卡会话后就可以使用nmcli命令来查看到所有的网卡会话列表了：12345[root@localhost ~]# nmcli connection showNAME UUID TYPE DEVICE house 5bb6fe21-8b5e-467d-b2d4-27ca6f8fd9b0 802-3-ethernet -- company c0ec1b4a-6de3-47f1-9c2c-5c92ec69b7a2 802-3-ethernet -- eno16777728 b6dd5c6f-2b82-49c2-b218-bea21c5c9ae2 802-3-ethernet eno16777728 nmcli命令配置过的网卡会话和参数会直接写入到配置文件中永久生效，这样晚上回到家中后顺手把house居家的网卡会话启用，就可以让网卡设备自动的从无线路由器中获取到IP地址啦，当然如果同学们是在使用虚拟机软件的话，请像如图9-9所示操作一下，把虚拟机系统网卡切换成桥接模式，然后记得重启网卡服务哦~：]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK1.8源码学习-集合框架]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F20%2FJDK1.8%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-4%2F</url>
    <content type="text"><![CDATA[Java集合工具包位于Java.util包下，包含了很多常用的数据结构，如数组、链表、栈、队列、集合、哈希表等。学习Java集合框架下大致可以分为如下五个部分：List列表、Set集合、Map映射、迭代器（Iterator、Enumeration）、工具类（Arrays、Collections）。 Java集合类的整体框架如下： 从上图可以看出，集合框架主要有两部分：Collection和Map。 Collection是List、Set等集合高度抽象出来的接口，它包含了这些集合的基本操作，它主要又分为两大部分：List和Set。 List接口通常表示一个列表（数组、队列、链表、栈等），其中的元素可以重复，常用实现类为ArrayList和LinkedList，另外还有不常用的Vector。另外，LinkedList还是实现了Queue接口，因此也可以作为队列使用。 Set接口通常表示一个集合，其中的元素不允许重复（通过hashcode和equals函数保证），常用实现类有HashSet和TreeSet，HashSet是通过Map中的HashMap实现的，而TreeSet是通过Map中的TreeMap实现的。另外，TreeSet还实现了SortedSet接口，因此是有序的集合（集合中的元素要实现Comparable接口，并覆写Compartor函数才行）。 我们看到，抽象类AbstractCollection、AbstractList和AbstractSet分别实现了Collection、List和Set接口，这就是在Java集合框架中用的很多的 适配器设计模式 ，用这些抽象类去实现接口，在抽象类中实现接口中的若干或全部方法，这样下面的一些类只需直接继承该抽象类，并实现自己需要的方法即可，而不用实现接口中的全部抽象方法。 Map是一个映射接口，其中的每个元素都是一个key-value键值对，同样抽象类AbstractMap通过适配器模式实现了Map接口中的大部分函数，TreeMap、HashMap、WeakHashMap等实现类都通过继承AbstractMap来实现，另外，不常用的HashTable直接实现了Map接口，它和Vector都是JDK1.0就引入的集合类。 Iterator是遍历集合的迭代器（不能遍历Map，只用来遍历Collection），Collection的实现类都实现了iterator()函数，它返回一个Iterator对象，用来遍历集合，ListIterator则专门用来遍历List。而Enumeration则是JDK1.0时引入的，作用与Iterator相同，但它的功能比Iterator要少，它只能再Hashtable、Vector和Stack中使用。 Arrays和Collections是用来操作数组、集合的两个工具类，例如在ArrayList和Vector中大量调用了Arrays.Copyof()方法，而Collections中有很多静态方法可以返回各集合类的synchronized版本，即线程安全的版本，当然了，如果要用线程安全的集合类，首选Concurrent并发包下的对应的集合类。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>jdk1.8</tag>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK1-8源码学习-Integer]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F19%2FJDK1.8%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-3%2F</url>
    <content type="text"><![CDATA[Integer 类在对象中包装了一个基本类型 int 的值。Integer 类型的对象包含一个 int 类型的字段。 Integer valueOf(int i)个人觉得是比较重要的方法：123456public static Integer valueOf(int i) &#123; //通常情况下，IntegerCache.low=-128，IntegerCache.high=127（除非显示声明java.lang.Integer.IntegerCache.high的值） if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; 这里关系到一个静态内部类，123456789101112131415161718192021222324252627282930313233private static class IntegerCache &#123; static final int low = -128; static final int high; static final Integer cache[]; static &#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;); if (integerCacheHighPropValue != null) &#123; try &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; catch( NumberFormatException nfe) &#123; // If the property cannot be parsed into an int, ignore it. &#125; &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127; &#125; private IntegerCache() &#123;&#125;&#125; 这里明显可用看到，当Integer类被加载时，就新建了-128到127的所有数字并缓存在Integer数组cache中。 再回到valueOf()代码，可以得出结论。当调用valueOf方法（包括后面会提到的重载的参数类型包含String的valueOf方法）时，如果参数的值在-128到127之间，则直接从缓存中返回一个已经存在的对象。如果参数的值不在这个范围内，则new一个Integer对象返回。为了验证以上推论，我们写个小程序看看：123456789Integer i1 = 100;Integer i2 = 100;System.out.println(i1 == i2);Integer i3 = 200;Integer i4 = 200;System.out.println(i3 == i4);运行结果：truefalse 第一个true是因为i1和i2都指向cache里的100，第二个false是因为cache里没有200，所以i3和i4各自new了一个新对象。注意的是，这个cache最大值127是可以配置的：-Djava.lang.Integer.IntegerCache.high=250，如图然后再次运行程序：12truetrue 剩下的方法不常用，就学习到这儿了。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>jdk1.8</tag>
        <tag>Integer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK1-8源码学习-StringBUilder，StringBUffer]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F19%2FJDK1.8%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-2%2F</url>
    <content type="text"><![CDATA[在编写JAVA代码的过程中有时要频繁地对字符串进行拼接，如果直接用”+”拼接的话会建立很多的String型对象，严重的话会对服务器资源和性能造成不小的影响；(其实在jdk1.5之后，String“+”拼接在底层已经用StringBuilder实现了)而使用StringBuilder和StringBuffer能解决以上问题。 AbsractStringBuilder这是jdk1.8中对StringBuilder的声明，可以看到也用final修饰了，那么为什么我们还说它是可变类呢，注意到它继承了AbstractStringBuilder，关键就是这个类。12345public final class StringBuilder extends AbstractStringBuilder implements java.io.Serializable, CharSequence&#123;&#125; 我们重点看到AbstractStringBuilder的append方法，有很多，选取其中一个：123456789101112131415161718192021public AbstractStringBuilder append(String str) &#123; if (str == null) return appendNull(); int len = str.length(); //先扩大自身容量 ensureCapacityInternal(count + len); //调用getChars()将str拼接/复制到自身后面 str.getChars(0, len, value, count); count += len; return this;&#125;public void getChars(int srcBegin, int srcEnd, char[] dst, int dstBegin)&#123; if (srcBegin &lt; 0) throw new StringIndexOutOfBoundsException(srcBegin); if ((srcEnd &lt; 0) || (srcEnd &gt; count)) throw new StringIndexOutOfBoundsException(srcEnd); if (srcBegin &gt; srcEnd) throw new StringIndexOutOfBoundsException(&quot;srcBegin &gt; srcEnd&quot;); System.arraycopy(value, srcBegin, dst, dstBegin, srcEnd - srcBegin);&#125; 从以上代码可以看到StringBuilder的append实际上是调用System.arraycopy()方法的，而且这个方法是一个native方法，从指定源数组中复制一个数组，复制从指定的位置开始， 到目标数组的指定位置结束，这个方法效率也不错。 还有一个delete方法,从StringBuilder中删除从start到end的字符：123456789101112131415public AbstractStringBuilder delete(int start, int end) &#123; if (start &lt; 0) throw new StringIndexOutOfBoundsException(start); if (end &gt; count) end = count; if (start &gt; end) throw new StringIndexOutOfBoundsException(); int len = end - start; if (len &gt; 0) &#123; //实质是调用System.arraycopy对自身进行复制 System.arraycopy(value, start+len, value, start, count-end); count -= len; &#125; return this;&#125; reverse方法，这是String没有的：1234567891011121314151617181920212223242526272829303132333435public AbstractStringBuilder reverse() &#123; boolean hasSurrogates = false; int n = count - 1; for (int j = (n-1) &gt;&gt; 1; j &gt;= 0; j--) &#123; int k = n - j; char cj = value[j]; char ck = value[k]; value[j] = ck; value[k] = cj; //这里是判断每个字符是否在Character.MIN_SURROGATE(\ud800)和Character.MAX_SURROGATE(\udfff)之间 if (Character.isSurrogate(cj) || Character.isSurrogate(ck)) &#123; hasSurrogates = true; &#125; &#125; if (hasSurrogates) &#123; reverseAllValidSurrogatePairs(); &#125; return this;&#125;private void reverseAllValidSurrogatePairs() &#123;//反转回有效代理对 for (int i = 0; i &lt; count - 1; i++) &#123; char c2 = value[i]; if (Character.isLowSurrogate(c2)) &#123; char c1 = value[i + 1]; if (Character.isHighSurrogate(c1)) &#123; //将i和i+1位字符互换 //高代理+低代理组合表示一个字符 value[i++] = c1; value[i] = c2; &#125; &#125; &#125;&#125; 这里反转还加了这些判断，为什么这样做？首先来看一个概念，下面这段话摘自知乎：12345Surrogate 這個概念，不是來自 Java 語言，而是來自 Unicode 編碼方式之一 UTF-16 。簡而言之，Java 語言內部的字符信息是使用 UTF-16 編碼。因為，char 這個類型是 16-bit 的。它可以有65536種取值，即65536個編號，每個編號可以代表1種字符。但是，Unicode 包含的字符已經遠遠超過65536個。那，編號大於65536的，還要用 16-bit 編碼，該怎麼辦？於是，Unicode 標準制定組想出的辦法就是，從這65536個編號裏，拿出2048個，規定它們是「Surrogates」，讓它們兩個為一組，來代表編號大於65536的那些字符。更具體地，編號為 U+D800 至 U+DBFF 的規定為「High Surrogates」，共1024個。編號為 U+DC00 至 U+DFFF 的規定為「Low Surrogates」，也是1024個。它們兩兩組合出現，就又可以多表示1048576種字符。 StringBuilderStringBuilder的大多数方法都是调用父类AbstractStringBuilder的方法，只是自己增加了writeObject()和readObject()的用于序列化/反序列化的方法。 StringBufferStringBuffer和StringBuilder的代码大致相同，只是在绝大多数方法前面都加了synchronized关键字，所以它是线程安全的，代价是性能低下。 相比而言StringBuilder是非线程安全的，性能很好。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>jdk1.8</tag>
        <tag>String</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK1.8源码学习-String]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F19%2FJDK1.8%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-1%2F</url>
    <content type="text"><![CDATA[从现在开始学习jdk1.8源码，先从常用的java.lang.String开始。 首先来看jdk1.8中java.lang.String的定义：public final class Stringimplements java.io.Serializable, Comparable&lt;String&gt;, CharSequence {}String类使用了final关键字修饰，是为不可变类，并且实现了序列化，比较器接口，还有一个CharSequence接口。CharSequence是字符数组，说明String本质上是通过字符数组实现的。这个CharSequence接口定义了一些String常用的方法：int length(); char charAt(int index); CharSequence subSequence(int start, int end); public String toString(); ...... 还有两个特殊的方法使用了default关键字：public default IntStream chars() { class CharIterator implements PrimitiveIterator.OfInt { ...... }这是Java8引入的新概念，叫做default方法，也可以称为Defender方法，或者虚拟扩展方法（Virtual extension methods)。在此不展开介绍，有兴趣的同学自己百度一下。 接下来看看String的成员，private final char value[];//用于存储String的字符下面有很多构造函数，都是一些常用的：public String() { this.value = new char[0]; }public String(String original) { this.value = original.value; this.hash = original.hash; }public String(char value[]) { this.value = Arrays.copyOf(value, value.length); } ...... 来看看我们重点学习的equls方法：12345678910111213141516171819202122public boolean equals(Object anObject) &#123; if (this == anObject) &#123; return true; &#125; if (anObject instanceof String) &#123; String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; //逐个比较字符 while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false;&#125; 众所周知，Object的equls方法是通过“==”实现的，可以看出String的equls是比较其内容的。嘻嘻，还有hashcode方法，利用每一位字符计算出一个哈希值：1234567891011121314private int hash; // Default to 0public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h;&#125; substring方法实际上返回了一个新的String，concat方法也是…12345678910public String substring(int beginIndex) &#123; if (beginIndex &lt; 0) &#123; throw new StringIndexOutOfBoundsException(beginIndex); &#125; int subLen = value.length - beginIndex; if (subLen &lt; 0) &#123; throw new StringIndexOutOfBoundsException(subLen); &#125; return (beginIndex == 0) ? this : new String(value, beginIndex, subLen);&#125; 最后是一个特殊的intern方法，是一个native方法：当一个String实例str调用intern()方法时，Java查找常量池中是否有相同Unicode的字符串常量，如果有，则返回其的引用， 如果没有，则在常量池中增加一个Unicode等于str的字符串并返回它的引用。有兴趣的同学还可以深入了解一下：1public native String intern(); 在jdk1.6及以前，字符串常量池是放在永久代（PermGen）的，据我所知，根据平台的不同，PermGen的大小从32M到96M不等。你可以增加它的大小，但它的大小固定在运行时不能改变，所以使用的时候要小心，如果不加控制，可能会导致OOM。 从jdk1.7开始，字符串常量池被移到了堆中，这意味着你不会再被一块固定大小的内存区域所限制。像大多数常规对象一样，所有的Strings现在会处于堆中。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>jdk1.8</tag>
        <tag>String</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础课程08]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F18%2FLinux%E5%9F%BA%E7%A1%80%E8%AF%BE%E7%A8%8B08%2F</url>
    <content type="text"><![CDATA[保证数据的安全性是继可用性之后最为重要的一项工作，防火墙技术作为公网与内网之间的保护屏障，起着至关重要的作用。大家一起先来学习在红帽RHEL7系统中firewalld防火墙服务与iptables防火墙服务之间的关系，从理论和事实层面剖析真相。 本节将会分别使用iptables，firewall-cmd，firewall-config和Tcp_wrappers等防火墙策略配置服务来完成数十个根据真实工作需求而设计的防火墙策略配置实验，让大家不仅能够熟练的对请求包流量进行过滤，还能够基于服务程序进行允许和关闭操作，做到保证Linux系统安全万无一失。 防火墙管理工具保证数据的安全性是继可用性之后最为重要的一项工作，众所周知外部公网相比企业内网更加的“罪恶丛生”，因此防火墙技术作为公网与内网之间的保护屏障，虽然有硬件和软件之分，但主要功能都是 依据策略对外部请求进行过滤，防火墙技术能够做到监控每一个数据包并判断是否有相应的匹配策略，直到匹配到其中一条策略规则或执行默认策略为止，防火墙策略可以基于来源地址，请求动作或协议等信息来定制，最终仅让合法的用户请求流入到内网，其余的均被抛弃。在红帽RHEL7系统中Filewalld服务取代了Iptables服务，对于接触Linux系统比较早或学习过红帽RHEL6系统的读者来讲，突然改用Firewalld服务后确实不免会有些抵触心理，或许会觉得Firewalld服务是一次不小的改变。但其实Iptables服务与Firewalld服务都不是真正的防火墙，它们都是用来定义防火墙策略功能的“防火墙管理工具”而已，iptables服务会把配置好的防火墙策略交由内核层面的netfilter网络过滤器来处理，而filewalld服务则是把配置好的防火墙策略交由内核层面的nftables包过滤框架来处理。换句话说，当前在Linux系统中其实同时有多个防火墙管理工具共同存在，它们的作用都是为了方便运维人员管理Linux系统的防火墙策略，而咱们只要配置妥当其中一个就足够了。虽然各个工具之间各有优劣特色，但对于防火墙策略的配置思路上是保持一致的，同学们甚至可以不用完全掌握本章节内的知识，而是在这诸多个防火墙管理工具中任选一款来学透即可，完全能够满足日常的工作所需。 Iptables在较早期的Linux系统中想配置防火墙默认使用的都是iptables防火墙管理命令，而新型firewalld防火墙管理服务已经被投入使用多年。 策略与匹配链防火墙会从上至下来读取规则策略，一旦匹配到了合适的就会去执行并立即结束匹配动作，但也有转了一圈之后发现没有匹配到合适规则的时候，那么就回去执行默认策略。因此对防火墙的策略无非就是两种，一种是“通”，另一种是“堵”————当防火墙的默认策略是拒绝的，就要设置允许规则，否则谁都进不来了，而如果防火墙的默认策略是允许的，就要设置拒绝规则，否则谁都能进来了，起不到防范的作用。 iptables命令把对数据进行过滤或处理数据包的策略叫做规则，把多条规则又存放到一个规则链中，规则链是依据处理数据包位置的不同而进行的分类，包括有：在进行路由选择前处理数据包（PREROUTING），处理流入的数据包（INPUT），处理流出的数据包（OUTPUT），处理转发的数据包（FORWARD），在进行路由选择后处理数据包（POSTROUTING）。从内网向外网发送的数据一把都是可控且良性的，因此显而易见咱们使用最多的就是INPUT数据链，这个链中定义的规则起到了保证私网设施不受外网骇客侵犯的作用。 比如您所居住的社区物业保安有两条规定——“禁止小商贩进入社区，各种车辆都需要登记”，这两条安保规定很明显应该是作用到了社区的正门（流量必须经过的地方），而不是每家每户的防盗门上。根据前面提到的防火墙策略的匹配顺序规则，咱们可以猜想有多种情况——比如来访人员是小商贩，则会被物业保安直接拒绝在大门外，也无需再对车辆进行登记，而如果来访人员是一辆汽车，那么因为第一条禁止小商贩策略就没有被匹配到，因而按顺序匹配到第二条策略，需要对车辆进行登记，再有如果来访的是社区居民，则既不满足小商贩策略，也不满足车辆登记策略，因此会执行默认的放行策略。 不过只有规则策略还不能保证社区的安全，物业保安还应该知道该怎么样处理这些被匹配到的流量，比如包括有“允许”、“登记”、“拒绝”、“不理他”，这些动作对应到iptables命令术语中是 ACCEPT（允许流量通过），LOG（记录日志信息），REJECT（拒绝流量通过），DROP（拒绝流量通过）。允许动作和记录日志工作都比较好理解，着重需要讲解的是这两条拒绝动作的的不同点，其中REJECT和DROP的动作操作都是把数据包拒绝，DROP是直接把数据包抛弃不响应，而REJECT会拒绝后在回复一条“您的信息我已收到，但被扔掉了”，让对方清晰的看到数据被拒绝的响应。就好比说您有一天正在家里看电视，突然有人敲门，透过“猫眼”一看是推销商品的，咱们如果不需要的情况下就会直接拒绝他们（REJECT）。但如果透过“猫眼”看到的是债主带了几十个小弟来讨债，这种情况不光要拒绝开门，还要默不作声，伪装成自己不在家的样子（DROP），这就是两种拒绝动作的不同之处。 把Linux系统设置成REJECT拒绝动作策略后，对方会看到本机的端口不可达的响应： 基本的命令参数iptables是一款基于命令行的防火墙策略管理工具，由于该命令是基于终端执行且存在有大量参数的，学习起来难度还是较大的，好在对于日常控制防火墙策略来讲，您无需深入的了解诸如“四表五链”的理论概念，只需要掌握常用的参数并做到灵活搭配即可，以便于能够更顺畅的胜任工作所需。iptables命令可以根据数据的流量的源地址，目的地址，传输协议，服务类型等等信息项进行匹配，一旦数据包和策略匹配上之后，iptables就会根据策略所预设的动作来处理这些数据包流量，另外再来提醒下同学们防火墙策略的匹配顺序规则是从上至下的，因此切记要把较为严格、优先级较高的策略放到靠前位置，否则有可能产生错误。下表中为读者们总结归纳了几乎所有常用的iptables命令参数， 参数 作用 -P 设置默认策略:iptables -P INPUT (DROP&#124;ACCEPT) -F 清空规则链 -L 查看规则链 -A 在规则链的末尾加入新规则 -l num 在规则链的头部加入新规则 -D num 删除某一条规则 -s 匹配来源地址IP/MASK，加叹号“!”表示除这个IP外 -d 匹配目标地址 -i 网卡名称 匹配从这块网卡流入的数据 -o 网卡名称 匹配从这块网卡流出的数据 -p 匹配协议，如tcp，udp，icmp –dport num 匹配目标端口号 –sport num 匹配来源端口号 使用iptables -L命令来查看已有的防火墙策略：[root@localhost ~]# iptables -LChain INPUT (policy ACCEPT)target prot opt source destinationACCEPT all -- anywhere anywhere ctstate RELATED,ESTABLISHEDACCEPT all -- anywhere anywhereINPUT_direct all -- anywhere anywhereINPUT_ZONES_SOURCE all -- anywhere anywhereINPUT_ZONES all -- anywhere anywhereACCEPT icmp -- anywhere anywhereREJECT all -- anywhere anywhere reject-with icmp-h...... 使用iptables -F命令来清空已有的防火墙策略：[root@localhost ~]# iptables -F[root@localhost ~]# iptables -LChain INPUT (policy ACCEPT)...... 将INPUT链的默认策略设置成拒绝：如前面所提到的防火墙策略设置无非有两种方式，一种是“通”，一种是“堵”，当把INPUT链设置为默认拒绝后，就要往里面写入允许策略了，否则所有流入的数据包都会被默认拒绝掉，同学们需要留意规则链的默认策略拒绝动作只能是DROP，而不能是REJECT。[root@localhost ~]# iptables -P INPUT DROP[root@localhost ~]# iptables -LChain INPUT (policy DROP)target prot opt source destination...... 向INPUT链中添加允许icmp数据包流入的允许策略：[root@localhost ~]# ping -c 4 192.168.139.128PING 192.168.139.128 (192.168.139.128) 56(84) bytes of data.--- 192.168.139.128 ping statistics ---4 packets transmitted, 0 received, 100% packet loss, time 3001ms[root@localhost ~]# iptables -I INPUT -p icmp -j ACCEPT[root@localhost ~]# ping -c 4 192.168.139.128PING 192.168.139.128 (192.168.139.128) 56(84) bytes of data.64 bytes from 192.168.139.128: icmp_seq=1 ttl=64 time=0.075 ms64 bytes from 192.168.139.128: icmp_seq=2 ttl=64 time=0.032 ms64 bytes from 192.168.139.128: icmp_seq=3 ttl=64 time=0.062 ms64 bytes from 192.168.139.128: icmp_seq=4 ttl=64 time=0.062 ms--- 192.168.139.128 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 3004msrtt min/avg/max/mdev = 0.032/0.057/0.075/0.018 ms 删除INPUT链中的那条策略，并把默认策略设置成还原：[root@localhost ~]# iptables -D INPUT 1[root@localhost ~]# iptables -P INPUT ACCEPT[root@localhost ~]# iptables -LChain INPUT (policy ACCEPT)target prot opt source destination 设置INPUT链只允许指定网段访问本机的22接口，拒绝其它所有主机的数据请求流量：[root@localhost ~]# iptables -I INPUT -s 192.168.139.0/24 -p tcp --dport 22 -j ACCEPT[root@localhost ~]# iptables -A INPUT -p tcp --dport 22 -j REJECT[root@localhost ~]# iptables -LChain INPUT (policy ACCEPT)target prot opt source destinationACCEPT tcp -- 192.168.139.0/24 anywhere tcp dpt:sshREJECT tcp -- anywhere anywhere tcp dpt:ssh reject-wi 使用IP地址在192.168.10.0/24网段内的主机访问服务器的22端口：[root@localhost ~]# ssh 192.168.139.128The authenticity of host &#39;192.168.139.128 (192.168.139.128)&#39; can&#39;t be established.ECDSA key fingerprint is 32:fe:4a:7b:85:e9:93:8f:d8:93:e1:94:81:00:c8:f1.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &#39;192.168.139.128&#39; (ECDSA) to the list of known hosts.root@192.168.139.128&#39;s password:Last login: Mon Sep 18 15:00:26 2017 使用IP地址在192.168.20.0/24网段外的主机访问服务器的22端口：[root@Client B ~]# ssh 192.168.139.128Connecting to 192.168.139.128:22...Could not connect to &#39;192.168.139.128&#39; (port 22): Connection failed. 向INPUT链中添加拒绝所有人访问本机12345端口的策略：[root@localhost ~]# iptables -I INPUT -p tcp --dport 12345 -j REJECT[root@localhost ~]# iptables -I INPUT -p udp --dport 12345 -j REJECT[root@localhost ~]# iptables -LChain INPUT (policy ACCEPT)target prot opt source destinationREJECT udp -- anywhere anywhere udp dpt:italk reject-with icmp-port-unreachableREJECT tcp -- anywhere anywhere tcp dpt:italk reject-with icmp-port-unreachableACCEPT tcp -- 192.168.139.0/24 anywhere tcp dpt:sshREJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable...... 向INPUT链中添加拒绝来自于指定192.168.139.127主机访问本机80端口（web服务）的防火墙策略：[root@localhost ~]# iptables -I INPUT -p tcp -s 192.168.139.127 --dport 80 -j REJECT[root@localhost ~]# iptables -LChain INPUT (policy ACCEPT)target prot opt source destinationREJECT tcp -- 192.168.139.127 anywhere tcp dpt:http reject-with icmp-port-unreachableREJECT udp -- anywhere anywhere udp dpt:italk reject-with icmp-port-unreachableREJECT tcp -- anywhere anywhere tcp dpt:italk reject-with icmp-port-unreachableACCEPT tcp -- 192.168.139.0/24 anywhere tcp dpt:sshREJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachable 向INPUT链中添加拒绝所有主机不能访问本机1000至1024端口的防火墙策略：[root@localhost ~]# iptables -A INPUT -p tcp --dport 1000:1024 -j REJECT[root@localhost ~]# iptables -A INPUT -p udp --dport 1000:1024 -j REJECT[root@localhost ~]# iptables -LChain INPUT (policy ACCEPT)target prot opt source destinationREJECT tcp -- 192.168.139.127 anywhere tcp dpt:http reject-with icmp-port-unreachableREJECT udp -- anywhere anywhere udp dpt:italk reject-with icmp-port-unreachableREJECT tcp -- anywhere anywhere tcp dpt:italk reject-with icmp-port-unreachableACCEPT tcp -- 192.168.139.0/24 anywhere tcp dpt:sshREJECT tcp -- anywhere anywhere tcp dpt:ssh reject-with icmp-port-unreachableREJECT tcp -- anywhere anywhere tcp dpts:cadlock2:1024 reject-with icmp-port-unreachableREJECT udp -- anywhere anywhere udp dpts:cadlock2:1024 reject-with icmp-port-unreachable是不是还意犹未尽？但对于iptables防火墙管理命令的学习到此就可以结束了，考虑到以后防火墙的发展趋势，同学们只要能把上面的实例看懂看熟就可以完全搞定日常的iptables防火墙配置工作了。但请特别留意下，iptables命令配置的防火墙规则默认会在下一次重启时失效，所以如果您想让配置的防火墙策略永久的生效下去，还要执行一下保存命令：[root@localhost ~]# service iptables saveiptables: Saving firewall rules to /etc/sysconfig/iptables:[ OK ] FirewalldRHEL7是一个集合多款防火墙管理工具并存的系统，Firewalld动态防火墙管理器服务（Dynamic Firewall Manager of Linux systems）是目前默认的防火墙管理工具，同时拥有命令行终端和图形化界面的配置工具，即使是对Linux命令并不熟悉的同学也能快速入门。相比于传统的防火墙管理工具还支持了动态更新技术并加入了“zone区域”的概念，简单来说就是事先为用户预先准备几套防火墙策略集合（策略模板），然后可以根据不同的生产场景而选择合适的策略集合，实现了防火墙策略之间的快速切换。例如咱们有一台笔记本电脑每天都要在办公室、咖啡厅和家里使用，按常理推断最安全的应该是家里的内网，其次是公司办公室，最后是咖啡厅，如果需要在办公室内允许文件共享服务的请求流量、回到家中需要允许所有的服务，而在咖啡店则是除了上网外不允许任何其他请求，这样的需求应该是很常见的，在以前只能频繁的进行手动设置，而现在只需要预设好zone区域集合，然后轻轻点击一下就可以切换过去了上百条策略了，极大的提高了防火墙策略的应用效率，常见的zone区域名称及应用可见下表（默认为public）： 区域 默认规则策略 trusted 允许所有的数据包 home 拒绝流入的数据包，除非与输出流量数据包相关或是ssh,mdns,ipp-client,samba-client与dhcpv6-client服务则允许。 internal 等同于home区域 work 拒绝流入的数据包，除非与输出流量数据包相关或是ssh,ipp-client与dhcpv6-client服务则允许。 public 拒绝流入的数据包，除非与输出流量数据包相关或是ssh,dhcpv6-client服务则允许。 external 拒绝流入的数据包，除非与输出流量数据包相关或是ssh服务则允许。 dmz 拒绝流入的数据包，除非与输出流量数据包相关或是ssh服务则允许。 block 拒绝流入的数据包，除非与输出流量数据包相关。 drop 拒绝流入的数据包，除非与输出流量数据包相关。 终端管理工具firewall-cmd命令是Firewalld动态防火墙管理器服务的命令行终端。它的参数一般都是以“长格式”来执行的，但同学们也不用太过于担心，因为红帽RHEL7系统非常酷的支持了部分命令的参数补齐，也正好包括了这条命令，也就是说现在除了能够用Tab键来补齐命令或文件名等等内容，还可以用Tab键来补齐下列长格式参数啦（这点特别的棒）。 参数 作用 –get-default-zone 查询默认的区域名称 –set-default-zone=&lt;区域名称&gt; 设置默认的区域，永久生效。 –get-zones 显示可用的区域。 –get-services 显示预先定义的服务。 –get-active-zones 显示当前正在使用的区域与网卡名称。 –add-source= 将来源于此IP或子网的流量导向指定的区域。 –remove-source= 不再将此IP或子网的流量导向指定的区域。 –add-interface=&lt;网卡名称&gt; 将来自于该网卡的所有流量都导向某个指定区域。 –change-interface=&lt;网卡名称&gt; 将某个网卡与区域做关联。 –list-all 显示当前区域的网卡配置参数，资源，端口号及服务等信息。 –list-all-zones 显示所有区域的网卡配置参数，资源，端口号及服务等信息。 –add-service=&lt;服务名&gt; 设置默认区域允许该服务的流量。 –add-port=&lt;端口号/协议&gt; 设置默认区域允许该端口的流量。 –remove-service=&lt;服务名&gt; 设置默认区域不再允许该服务的流量。 –remove-port=&lt;端口号/协议&gt; 设置默认区域不再允许该端口的流量。 –reload 让“永久生效”的配置规则立即生效，覆盖当前的。 如同其他的防火墙策略配置工具一样，Firewalld服务对防火墙策略的配置默认是当前生效模式（RunTime），配置信息会随着计算机重启而失效，如果想要让配置的策略一直存在，就需要使用永久生效模式（Permanent）了，方法就是在正常的命令中加入–permanent参数就可以代表针对于永久生效模式的命令了。但这个永久生效模式也有一个“不近人情”的特点，就是对它设置的策略需要重启后才能自动生效，如果想让配置的策略立即生效的话需要手动执行一下–reload参数。 查看FireWalld服务当前所使用的zone区域。[root@localhost ~]# firewall-cmd --get-default-zonepublic 查询eno16777728网卡在FireWalld服务中的zone区域。[root@localhost ~]# firewall-cmd --get-zone-of-interface=eno16777728public 把Firewalld防火墙服务中eno16777728网卡的默认区域修改为external，重启后再生效：[root@localhost ~]# firewall-cmd --get-zone-of-interface=eno16777728public[root@localhost ~]# firewall-cmd --permanent --zone=external --change-interface=eno16777728success[root@localhost ~]# firewall-cmd --get-zone-of-interface=eno16777728public重启后：[root@localhost ~]# firewall-cmd --permanent --get-zone-of-interface=eno16777728external 将FireWalld当前的默认区域设置为public：[root@localhost ~]# firewall-cmd --set-default-zone=publicWarning: ZONE_ALREADY_SET: public[root@localhost ~]# firewall-cmd --get-default-zonepublic 启动/关闭Firewalld防火墙服务的应急状况模式，阻断一切网络连接（当远程控制服务器时慎用）：[root@localhost ~]# firewall-cmd --panic-onsuccess[root@localhost ~]# firewall-cmd --panic-offsuccess 查询在public区域的ssh与https服务请求流量是否被允许.[root@localhost ~]# firewall-cmd --zone=public --query-service=sshyes[root@localhost ~]# firewall-cmd --zone=public --query-service=httpsno 把Firewalld防火墙服务中https服务的请求流量设置为永久允许，并当前立即生效：[root@localhost ~]# firewall-cmd --zone=public --add-service=https success[root@localhost ~]# firewall-cmd --permanent --zone=public --add-service=httpssuccess[root@localhost ~]# firewall-cmd --reloadsuccess 把FireWalld防火墙服务中http请求流量设置为永久拒绝，并当前立即生效：[root@localhost ~]# firewall-cmd --permanent --zone=public --remove-service=httpsuccess[root@localhost ~]# firewall-cmd --reloadsuccess 把FireWalld防火墙服务中8080和8081的请求流量允许放行，但仅限当前生效：[root@localhost ~]# firewall-cmd --zone=public --add-port=8080-8081/tcpsuccess[root@localhost ~]# firewall-cmd --zone=public --list-ports8080-8081/tcp 把原本访问本机888端口号的请求流量转发到22端口号，要求当前和长期均有效： 流量转发命令格式：firewall-cmd –permanent –zone=&lt;区域&gt; –add-forward-port=port=&lt;源端口号&gt;:proto=&lt;协议&gt;:toport=&lt;目标端口号&gt;:toaddr=&lt;目标IP地址&gt;[root@localhost ~]# firewall-cmd --permanent --zone=public --add-forward-port=port=888:proto=tcp:toport=22:toaddr=192.168.139.128success 在客户机使用ssh命令尝试访问192.168.10.10主机的888端口：1234567[root@client ~]# ssh -p 888 192.168.139.128The authenticity of host &apos;[192.168.139.128]:888 ([192.168.139.128]:888)&apos; can&apos;t be established.ECDSA key fingerprint is 32:fe:4a:7b:85:e9:93:8f:d8:93:e1:94:81:00:c8:f1.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;[192.168.139.128]:888&apos; (ECDSA) to the list of known hosts.root@192.168.139.128&apos;s password:Last login: Mon Sep 18 21:01:17 2017 在Firewalld防火墙服务中配置一条富规则，拒绝所有来自于192.168.10.0/24网段的用户访问本机ssh服务（22端口）：1234[root@localhost ~]# firewall-cmd --permanent --zone=public --add-rich-rule=&quot;rule family=&quot;ipv4&quot; source address=&quot;192.168.139.0/24&quot; service name=&quot;ssh&quot; reject&quot;success[root@localhost ~]# firewall-cmd --reloadsuccess 在客户机使用ssh命令尝试访问192.168.10.10主机的ssh服务（22端口）：[root@client ~]# ssh 192.168.139.128ssh: connect to host 192.168.139.128 port 22: Connection refused 图形管理工具firewall-config命令是管理Firewalld防火墙策略的图形化工具，界面和操作都颇为出人意料，几乎可以实现所有命令行终端的操作，可以毫不夸张的说，即使初学者没有扎实的Linux命令基础，也一样可以通过这款图形化工具配置好RHEL7系统的防火墙策略。输入一下命令：[root@localhost ~]# firewall-config &amp;`` [1] 6177`Firewalld防火墙图形化的界面如下图所示，功能分别为1:选择”当前立即生效（Runtime）”或”重启后长期生效(Permanent)”配置、2:可选策略集合区域列表、3:常用系统服务列表、4:当前正在使用的区域、5:管理当前被选中区域中的服务、6:管理当前被选中区域中的端口、7:开启或关闭SNAT（伪装）技术、8:设置端口转发策略、9:控制ICMP协议请求流量、10:管理防火墙的富规则、11:管理网卡设备、12:被选中区域的服务，前面有√的表示允许放行、13:Firewalld防火墙图形化工具的状态。这款Firewall-config图形化管理工具在配置策略后，您不需要点击保存或完成按钮，只要有修改内容工具就会自动保存好。例如咱们先来动手试一试把当前区域中http服务的请求流量允许放行吧，但仅限当前生效，如图所示：咱们尝试添加一条允许放行8080-8088端口号（tcp协议）入站请求数据的策略，并且把配置模式提前设置为永久长期生效，以达到重启后依然生效的目的，配置过程如图8-4所示，并且可以如图8-5所示，在菜单中点击Reload Firewalld选项，来让配置文件立即生效，这与在命令行终端中执行了–reload参数的效果是一样的。 SNAT源地址转换协议是为了解决IP地址资源匮乏问题而设计的技术协议，SNAT技术能够使得多个内网用户通过一个外网IP地址上网。如图，在一个局域网中有多台主机，如果网关之上没有经过SNAT处理，那么请求过后的回复数据包就不能在互联网中找到这个私网IP地址，所以用户也就不能顺利取得想要的资源了，但是若使用了SNAT源地址转换技术，服务器应答后先由网关服务器接收，再分发给内网的用户主机，从而使得用户顺利的拿到了所需资源。 使用iptables命令做SNAT源地址转换是一件很麻烦的事情，但在Firewalld防火墙图形化工具中只需要点击开启伪装区域技术就自动开启了SNAT源地址转换技术， 比如刚刚把所有向本机888端口请求的流量转发到22端口上，然后让防火墙配置策略当前及重启后都生效。 在Firewalld中的“富规则”代表着更细致、更详细的策略配置方法，咱们可以针对某个系统服务、端口号、来源地址、目的地址等诸多元素进行有针对性的策略配置，富规则策略的优先级是在策略中最高的。例如可以让192.168.139.0的主机能够访问到本机的1234端口号。当然，如果生成环境中有多块网卡在提供着服务（这种情况很常见），自然对内网和外网的网卡要选择的防火墙策略区域也不应是一样的，可用把网卡同防火墙策略zone区域做绑定，这样对不同网卡来源的请求流量进行不同策略区域的有针对性监控，效果会更好哦~ 服务的访问控制列表Tcp_wrappers是红帽RHEL7系统中默认已经启用的一款流量监控程序，它能够根据来访主机地址与本机目标服务程序做允许或拒绝操作。换句话说，Linux系统中其实有两个层面的防火墙，第一种是前面讲到的基于TCP/IP协议的流量过滤防护工具，而Tcp_wrappers服务则是能够对系统服务进行允许和禁止的防火墙，从而在更高层面保护了Linux系统的安全运行。控制列表文件修改后会立即生效，系统会先检查允许策略规则文件（/etc/hosts.allow），如果匹配到相应的允许策略则直接放行请求，如果没有匹配就会进一步匹配拒绝策略规则文件（/etc/hosts.deny）的内容，有匹配到相应的拒绝策略就会直接拒绝该请求流量，如果两个文件全都没有匹配到的话也会默认放行这次的请求流量。配置服务的参数并不复杂，如下表中就已经列出了几乎所有常见的情况： 客户端类型 示例 满足示例的客户端列表 单一主机 192.168.139.128 IP地址为192.168.139.128的主机。 指定网段 192.168.139. IP段为192.168.139.0/24的主机。 指定网段 192.168.139.0/255.255.255.0 IP段为192.168.139.0/24的主机。 指定DNS后缀 .linuxprobe.com 所有DNS后缀为.linuxprobe.com的主机 指定主机名称 www.linuxprobe.com 主机名称为www.linuxprobe.com的主机。 指定所有客户端 ALL 所有主机全部包括在内。 在正式配置Tcp_wrappers服务前有两点原则必须要提前讲清楚，第一，在写禁止项目的时候一定要写上的是服务名称，而不是某种协议的名称，第二，推荐先来编写拒绝规则，这样可以比较直观的看到相应的效果。例如先来通过拒绝策略文件禁止下所有访问本机sshd服务的请求数据吧（无需修改原有的注释信息）：12345678910111213141516[root@localhost ~]# vim /etc/hosts.deny## hosts.deny This file contains access rules which are used to# deny connections to network services that either use# the tcp_wrappers library or that have been# started through a tcp_wrappers-enabled xinetd.## The rules in this file can also be set up in# /etc/hosts.allow with a &apos;deny&apos; option instead.## See &apos;man 5 hosts_options&apos; and &apos;man 5 hosts_access&apos;# for information on rule syntax.# See &apos;man tcpd&apos; for information on tcp_wrapperssshd:*[root@localhost ~]# ssh 192.168.139.128ssh_exchange_identification: read: Connection reset by peer 接下来在允许策略文件中添加放行所有来自于192.168.139.0/24这个网段访问本机sshd服务请求的策略，咱们的服务器马上就允许了访问sshd服务的请求，效果非常直观：1234567891011121314[root@localhost ~]# vim /etc/hosts.allow## hosts.allow This file contains access rules which are used to# allow or deny connections to network services that# either use the tcp_wrappers library or that have been# started through a tcp_wrappers-enabled xinetd.## See &apos;man 5 hosts_options&apos; and &apos;man 5 hosts_access&apos;# for information on rule syntax.# See &apos;man tcpd&apos; for information on tcp_wrapperssshd:192.168.139.[root@localhost ~]# ssh 192.168.139.128root@192.168.139.128&apos;s password:Last login: Tue Sep 19 20:52:34 2017 from 192.168.139.129]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础课程07]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F17%2FLinux%E5%9F%BA%E7%A1%80%E8%AF%BE%E7%A8%8B07%2F</url>
    <content type="text"><![CDATA[前面学习了硬盘设备分区、格式化、挂载等知识技能后，为了能够进一步满足生产环境中对存储设备IO读写速度和数据冗余备份机制的更高需求，这里会深入学习各个常用RAID磁盘陈列组技术方案的特性，并实际部署RAID10，RAID5+备份盘等方案来更直观看到RAID磁盘阵列组的强大效果。 同时为了满足用户对存储资源动态调整的需求，还会深入学习LVM逻辑卷管理器的部署，扩容，缩小，快照，及卸载删除的步骤。 RAID磁盘冗余阵列现在计算机硬件中CPU处理器平均每年可提升30%-50%的计算性能，不仅如此，还在能耗方面有着不错的持续改善，但硬盘设备的性能提升仅仅为每年7%-10%，显然已经逐步成为了当代计算机整体性能的瓶颈问题，并且因为持续、频繁、大量的IO读写操作使得硬盘相比其他设备还存在很大损坏几率，导致重要的数据丢失。因此在1988年，由加利福尼亚大学伯克利分校发表的文章首次提到并定义了 RAID独立磁盘冗余阵列(Redundant Array of Independent Disks) ，RAID技术就是把很多块硬盘设备组合成一个容量更大，更安全的硬盘组，可以把数据切割成多个区段后分别存放再不同的物理硬盘设备上，然后利用分散读写需求来提升硬盘组整体的性能，同时把重要数据同步保存到多份不同不同的物理硬盘设备上，起到非常好的数据冗余备份效果。 当咱们坐下来静静思考下刚刚所说的优点也会发现一个重要事实——提高成本了。就像原本只有一个电话本，但是为了保障数据安全所以把联系人号码信息写成了两份，自然就要为多买的一个电话本而承担更多的成本支出，RAID硬盘组技术的设计初衷是减少对硬盘设备的支出花费，但与数据价值相比较，现在企业更在乎的是RAID技术不仅能提升硬盘的吞吐量，还为硬盘提供了冗余备份机制，也就是说不仅增加了存储设备的IO读写速度，还很大程度上降低了硬盘设备损坏后丢失数据的可能性，所以这项技术已经成为了大部分IDC运营商或大中型企业的必备能力了~ 接下来会逐个学习下RAID0、RAID1、RAID5与RAID10的四种最常见的方案。首先是RAID0硬盘组，这项技术是把多块物理硬盘设备通过硬件或软件的方式串联在一起，成为一个大的卷组，将数据依次分别写入到各个物理硬盘中，这样最理想的状态会使得读写性能提升数倍，但若任意一块硬盘故障则会让整个系统的数据都受到破坏。 通俗来说RAID0硬盘组技术至少需要两块物理硬盘设备，能够有效的提高硬盘的性能和吞吐量，但没有数据的冗余和错误修复能力。RAID0硬盘组技术虽然很大程度上提高了存储设备的IO读写速度，但仔细想想就不难发现数据是被分开存放的，也就是说假设任何其中的一块硬盘出现了问题都会破坏数据的完整性。因此再生产环境中如果需求不是增加存储设备的读写速度，而是追求数据安全性的时候就比较推荐使用RAID1硬盘组技术了。如下图，Raid1硬盘组技术是把两块以上的存储设备进行绑定，目的是让数据被多块硬盘同时写入，类似于把数据再制作出多份备份的镜像，当有一块硬盘损坏后一般可立即通过热交换方式来恢复数据的正常使用，RAID1硬盘组技术虽然十分注重数据的安全性，但因为是把数据同时写入两块以上的磁盘设备中，这无疑会增加一定系统计算能力的负载。那有没有RAID组合方案既考虑到存储设备的IO读写速度和数据安全性还能兼顾到成本问题呢？实际上单从数据安全和成本问题上来讲，就不可能在保持原有存储可用率同时还不增加新设备的情况下大幅提升数据的安全性，待会儿提到的RAID5硬盘组技术虽然理论上兼顾三者的，但实际上更像是对各个方面的“互相妥协”，如图所示，RAID5硬盘组技术是把其它存储设备中的数据奇偶校验信息互相保存到硬盘设备中。RAID5硬盘组阵列技术有两项技术特色，第一，数据的奇偶位校验信息并不是单独保存到某一块硬盘设备中，而是分别互相存储到其它每一块硬盘设备上，这样的好处就是当其中任何一设备损坏后不至于出现致命缺陷。第二，图中parity（绿底白字）部分实例的就是保存数据的奇偶校验信息，换句话说RAID5硬盘组技术并不是备份真正的硬盘实际数据信息，而是当设备出现问题后通过奇偶校验信息来尝试重建损坏的数据，这样的技术特性“妥协”的兼顾了存储设备性能，数据安全性和存储成本问题。由于RAID5硬盘组技术是因为成本问题对存储读写速度和安全性能而有了一定的妥协，但绝大部分情况下企业相比硬盘的价格，一定更加在乎数据的价值，生产环境中主要则是使用的RAID10硬盘组技术，顾名思义，这样技术就是对RAID1+RAID0硬盘组技术的一个“组合体”。如图所示，RAID10硬盘组至少需要4块硬盘来组建，先分别两两制作成RAID1磁盘组，保证数据的安全性，然后再对两个RAID1硬盘组实施RAID0技术，进一步的提高存储设备的读写速度，这样理论上只要坏的不是同一组中的所有硬盘，那么最多可以损坏50%的硬盘设备而不丢失数据，因此RAID10硬盘组技术继承了RAID0更高的读写速度和RAID1更安全的数据保障，在不考虑成本的情况下RAID10在读写速度和数据保障性方面都超过了RAID5，是较为广泛使用的存储技术。 部署磁盘阵列组首先需要为虚拟机中添加4块硬盘设备来制作一个RAID10磁盘阵列组，这几块硬盘设备是模拟出来的，不需要特意去买几块真实的物理硬盘插到电脑上，但请注意在虚拟机中添加硬盘的操作一定要记得关闭系统之后再做，否则有时因同学们的电脑架构不同会导致虚拟机系统识别不到硬盘设备。 mdadm命令用于管理系统软件RAID硬盘阵列，格式为：”mdadm [模式] [选项] [成员设备名称]”。在现在生产环境中的服务器一般都会配备有RAID阵列卡，价格也是越来越廉价，但没有必要让同学们为了做一个实验而单独去买一台服务器，mdadm命令能够在Linux系统中创建和管理软件RAID磁盘阵列组，对于其中的理论知识和操作过程是与生产环境保持一致的~mdadm命令的常用参数包括有： 参数 作用 -a 检测设备名称 -n 指定设备数量 -l 指定RAID级别 -C 创建 -v 显示过程 -f 模拟设备损坏 -r 移除设备 -Q 查看摘要信息 -D 查看详细信息 -S 停止阵列 第1步：使用mdadm命令创建RAID10,名称为”/dev/md0”。前面了解过udev是Linux系统内核中用来给硬件命名的服务，命名规则也非常的简单，可以猜测到第二个SCSI存储设备的名称会是为/dev/sdb，然后以此类推。使用硬盘设备做RAID磁盘阵列组很像几个同学组成一个班级，但班级的名称总不能叫做/dev/sdbsdcsddsde吧，这样虽然可以一眼看出是由那些元素组成的，但明显非常的不利于记忆和阅读吧，更何况如果是用10、50、100个硬盘组成的设备呢？因此需要用 -C参数 代表创建一个RAID阵列卡，-v参数来显示创建的过程，这样以后/dev/md0就是创建出RAID磁盘阵列组的名称啦，-a yes参数 代表自动创建设备文件，-n 4参数 代表使用4块硬盘来制作这个RAID硬盘阵列组，而 -l 10参数 则代表RAID10方案，最后面再加上4块硬盘设备的名称就搞定啦：[root@localhost ~]# mdadm -Cv /dev/md0 -a yes -n 4 -l 10 /dev/sdb /dev/sdc /dev/sdd /dev/sdemdadm: layout defaults to n2mdadm: layout defaults to n2mdadm: chunk size defaults to 512Kmdadm: size set to 20954624Kmdadm: Defaulting to version 1.2 metadatamdadm: array /dev/md0 started.把制作好的RAID磁盘阵列组格式化为ext4格式：[root@localhost ~]# mkfs.ext4 /dev/md0mke2fs 1.42.9 (28-Dec-2013)Filesystem label=OS type: LinuxBlock size=4096 (log=2)Fragment size=4096 (log=2)Stride=128 blocks, Stripe width=256 blocks2621440 inodes, 10477312 blocks523865 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=2157969408320 block groups32768 blocks per group, 32768 fragments per group8192 inodes per groupSuperblock backups stored on blocks:32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,4096000, 7962624Allocating group tables: doneWriting inode tables: doneCreating journal (32768 blocks): doneWriting superblocks and filesystem accounting information: done第三步：创建挂载点然后把存储设备进行挂载操作，挂载成功后：[root@localhost ~]# mkdir /RAID[root@localhost ~]# mount /dev/md0 /RAID[root@localhost ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/rhel-root 18G 2.9G 15G 17% /devtmpfs 905M 0 905M 0% /devtmpfs 914M 92K 914M 1% /dev/shmtmpfs 914M 8.8M 905M 1% /runtmpfs 914M 0 914M 0% /sys/fs/cgroup/dev/sda1 497M 127M 371M 26% /boot/dev/md0 40G 49M 38G 1% /RAID第四步：查看/dev/md0磁盘阵列设备组详细信息，并把挂载信息写入到配置文件中永久生效。[root@localhost ~]# mdadm -D /dev/md0/dev/md0:Version : 1.2Creation Time : Sun Sep 17 17:05:05 2017Raid Level : raid10Array Size : 41909248 (39.97 GiB 42.92 GB)Used Dev Size : 20954624 (19.98 GiB 21.46 GB)Raid Devices : 4Total Devices : 4Persistence : Superblock is persistentUpdate Time : Sun Sep 17 17:09:46 2017State : cleanActive Devices : 4Working Devices : 4Failed Devices : 0Spare Devices : 0Layout : near=2Chunk Size : 512KName : localhost.localdomain:0 (local to host localhost.localdomain)UUID : ed936caa:5758c536:76fac0c7:d08110d4Events : 19Number Major Minor RaidDevice State0 8 16 0 active sync /dev/sdb1 8 32 1 active sync /dev/sdc2 8 48 2 active sync /dev/sdd3 8 64 3 active sync /dev/sde[root@localhost ~]# echo &quot;/dev/md0 /RAID ext4 defaults 0 0&quot; &gt;&gt; /etc/fstab 损坏磁盘阵列及修复在生产环境中部署RAID10磁盘阵列组目的就是为了提高存储设备的IO读写速度及数据的安全性，但因为这次是在本机电脑上模拟出来的硬盘设备所以对于读写速度的改善可能并不直观。接下来学习RAID磁盘阵列组损坏后的处理方法，这样以后步入了运维岗位后不会因为突发事件而手忙脚乱。首先确认有一块物理硬盘设备出现损坏不能再继续正常使用后，应该使用mdadm命令来予以移除之后查看下RAID磁盘阵列组的状态已经被改变：[root@localhost ~]# mdadm /dev/md0 -f /dev/sdbmdadm: set /dev/sdb faulty in /dev/md0[root@localhost ~]# mdadm -D /dev/md0/dev/md0:Version : 1.2Creation Time : Sun Sep 17 17:05:05 2017Raid Level : raid10Array Size : 41909248 (39.97 GiB 42.92 GB)Used Dev Size : 20954624 (19.98 GiB 21.46 GB)Raid Devices : 4Total Devices : 4Persistence : Superblock is persistent Update Time : Sun Sep 17 17:20:33 2017State : clean, degradedActive Devices : 3Working Devices : 3Failed Devices : 1Spare Devices : 0 Layout : near=2Chunk Size : 512K Name : localhost.localdomain:0 (local to host localhost.localdomain)UUID : ed936caa:5758c536:76fac0c7:d08110d4Events : 21 Number Major Minor RaidDevice State0 0 0 0 removed1 8 32 1 active sync /dev/sdc2 8 48 2 active sync /dev/sdd3 8 64 3 active sync /dev/sde 0 8 16 - faulty /dev/sdb因为RAID10级别的磁盘阵列组允许一组RAID1硬盘组中存在一个故障盘而不影响使用，所以同学们此时可以尝试下在/RAID目录中正常的创建或删除文件都是不受影响的。当购买了新的硬盘存储设备后再使用mdadm命令来予以恢复即可，但因为虚拟机模拟硬盘的原因需要重启后才把新的硬盘添加到RAID磁盘阵列组中。[root@localhost ~]# umount /RAID[root@localhost ~]# mdadm /dev/md0 -a /dev/sdbmdadm: added /dev/sdb[root@localhost ~]# mdadm -D /dev/md0/dev/md0:Version : 1.2Creation Time : Sun Sep 17 17:05:05 2017Raid Level : raid10Array Size : 41909248 (39.97 GiB 42.92 GB)Used Dev Size : 20954624 (19.98 GiB 21.46 GB)Raid Devices : 4Total Devices : 4Persistence : Superblock is persistent Update Time : Sun Sep 17 17:27:42 2017State : clean, degraded, recoveringActive Devices : 3Working Devices : 4Failed Devices : 0Spare Devices : 1 Layout : near=2Chunk Size : 512K Rebuild Status : 13% complete Name : localhost.localdomain:0 (local to host localhost.localdomain)UUID : ed936caa:5758c536:76fac0c7:d08110d4Events : 37 Number Major Minor RaidDevice State4 8 16 0 spare rebuilding /dev/sdb1 8 32 1 active sync /dev/sdc2 8 48 2 active sync /dev/sdd3 8 64 3 active sync /dev/sde 磁盘阵列组+备份盘大家有没有想到还有一种极端情况，RAID10最多允许损坏50%的硬盘设备，但如果同一组中的设备同时全部损坏也会导致数据丢失，换句话说，如果当RAID10磁盘阵列组中某一块硬盘出现了故障，而咱们正在前往修复它的路上，恰巧此时同RAID1组中的另一块硬盘设备也出现故障，那么数据就被彻底损坏了。那这样情况该怎么办呢？其实就可以使用RAID备份盘技术来预防这类事故，顾名思义就是准备一块足够大的硬盘，这块硬盘设备平时是闲置状态不用工作，一旦RAID磁盘阵列组中有硬盘出现故障后则会马上自动顶替上去，这样很棒吧！ 为了避免多个实验之间产生冲突，咱们需要保证每个实验之间的相对独立性，因此请大家自行还原下虚拟机到最初始状态吧。另外因为刚刚已经给同学们演示了RAID10磁盘阵列组的部署方法，所以现在换一个RAID5来看看效果吧，RAID5磁盘阵列组技术至少需要3块盘来做，加上1块备份盘，总共是需要向虚拟机中模拟4块硬盘设备。 咱们现在来创建一个RAID5磁盘阵列组+备份盘吧，-n 3参数 代表创建这个RAID5所需的硬盘个数，-l 5参数 代表RAID磁盘阵列的级别，而 -x 1参数 则代表有1块备份盘，当查看/dev/md0磁盘阵列组的时候就能看到有一块备份盘在等待中了。[root@localhost ~]# mdadm -Cv /dev/md0 -n 3 -l 5 -x 1 /dev/sdb /dev/sdc /dev/sdd /dev/sdemdadm: layout defaults to left-symmetricmdadm: layout defaults to left-symmetricmdadm: chunk size defaults to 512Kmdadm: size set to 20954624Kmdadm: Defaulting to version 1.2 metadatamdadm: array /dev/md0 started.[root@localhost ~]# mdadm -D /dev/md0/dev/md0:Version : 1.2Creation Time : Sun Sep 17 19:46:30 2017Raid Level : raid5Array Size : 41909248 (39.97 GiB 42.92 GB)Used Dev Size : 20954624 (19.98 GiB 21.46 GB)Raid Devices : 3Total Devices : 4Persistence : Superblock is persistent Update Time : Sun Sep 17 19:46:50 2017State : clean, degraded, recoveringActive Devices : 2Working Devices : 4Failed Devices : 0Spare Devices : 2 Layout : left-symmetricChunk Size : 512K Rebuild Status : 19% complete Name : localhost.localdomain:0 (local to host localhost.localdomain)UUID : bd83d916:c14b4f9e:0dae6d1f:1460e51eEvents : 4 Number Major Minor RaidDevice State0 8 16 0 active sync /dev/sdb1 8 32 1 active sync /dev/sdc4 8 48 2 spare rebuilding /dev/sdd 3 8 64 - spare /dev/sde把这块制作的RAID5磁盘阵列组格式化为ext4文件格式后挂载到目录上吧，这样就可以使用啦~[root@localhost ~]# mkfs.ext4 /dev/md0mke2fs 1.42.9 (28-Dec-2013)Filesystem label=OS type: LinuxBlock size=4096 (log=2)Fragment size=4096 (log=2)Stride=128 blocks, Stripe width=256 blocks2621440 inodes, 10477312 blocks523865 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=2157969408320 block groups32768 blocks per group, 32768 fragments per group8192 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000, 7962624 Allocating group tables: doneWriting inode tables: doneCreating journal (32768 blocks): doneWriting superblocks and filesystem accounting information: done [root@localhost ~]# echo &quot;/dev/md0 /RAID ext4 defaults 0 0&quot; &gt;&gt; /etc/fstab[root@localhost ~]# mkdir /RAID[root@localhost ~]# mount -a最后就是见证奇迹的时刻啦，咱们再次把硬盘设备/dev/sdb移出磁盘阵列组，这样快速看下/dev/md0磁盘阵列组的状态就会发现备份盘已经被自动顶替上去，这是非常实用的，在RAID磁盘阵列组数据安全保证的基础上进一步提高数据可靠性，所以如果您的公司不差钱的话还是再买上一块备份盘以防万一吧。[root@localhost ~]# mdadm /dev/md0 -f /dev/sdbmdadm: set /dev/sdb faulty in /dev/md0[root@localhost ~]# mdadm -D /dev/md0/dev/md0:Version : 1.2Creation Time : Sun Sep 17 19:46:30 2017Raid Level : raid5Array Size : 41909248 (39.97 GiB 42.92 GB)Used Dev Size : 20954624 (19.98 GiB 21.46 GB)Raid Devices : 3Total Devices : 4Persistence : Superblock is persistent Update Time : Sun Sep 17 19:53:18 2017State : clean, degraded, recoveringActive Devices : 2Working Devices : 3Failed Devices : 1Spare Devices : 1 Layout : left-symmetricChunk Size : 512K Rebuild Status : 2% complete Name : localhost.localdomain:0 (local to host localhost.localdomain)UUID : bd83d916:c14b4f9e:0dae6d1f:1460e51eEvents : 36 Number Major Minor RaidDevice State3 8 64 0 spare rebuilding /dev/sde1 8 32 1 active sync /dev/sdc4 8 48 2 active sync /dev/sdd 0 8 16 - faulty /dev/sdb LVM逻辑卷管理器LVM逻辑卷管理器（Logical Volumn Manager） 是一项非常普及的硬盘设备资源管理器。在前面学习的硬盘设备管理技术虽然能够有效的提高存储设备的读写速度并能够很好的提高数据的安全性，但似乎一旦把硬盘分区或RAID磁盘阵列组部署后再想修改空间大小就不容易啦。换句话说，当用户想要随着实际需求的变化不断对硬盘分区进行增大或减小等调整时经常会受到硬盘“灵活性”的限制，有时真的很不方便，而LVM逻辑卷管理器技术就是为了满足用户对硬盘资源动态调整的期望。 LVM逻辑卷管理器是一项理论性较强的技术，它是Linux系统中对硬盘分区进行管理的一种机制，开创这项技术的初衷是为了解决传统硬盘分区创建后不易更改其大小的弱点，对于传统硬盘分区进行强制扩容和缩小技术理论上虽然是可行的，但却有可能造成数据的丢失，LVM逻辑卷管理器技术能够把多块硬盘进行卷组合并，让用户不必关心设备底层的架构和布局，拿来即用。LVM逻辑卷管理器实在磁盘区间和文件系统之间添加的逻辑层，它提供了一个抽象的卷组，可以使得多块硬盘可以卷组合并，让用户不必关心物理硬盘设备的底层结构，从而实现对分区的灵活动态调整。 LVM逻辑卷管理器的技术结构如图，举个例子吧，比如家里想吃馒头但面粉不够了，妈妈从隔壁老王家、老李家、老张家分别借来一些面粉，蒸出馒头后大家一起来吃，首先需要把这些面粉（ 物理卷PV ，Physical Volume）合并成一个大面团（ 卷组VG ，Volume Group），然后把这一大团面再分割成一个个小馒头（ 逻辑卷LV ，Logical Volume），每个小馒头的重量必须是每勺面粉（ 基本单元PE ，Physical Extent）的倍数。物理卷是出于逻辑卷管理器中最底层的资源，可以理解成物理硬盘、硬盘分区或者RAID磁盘阵列组都可以，而卷组是建立在物理卷之上的，一个卷组中可以包含多个物理卷，当然在卷组创建之后也可以继续向其中添加新的物理卷，而逻辑卷是建立在卷组之上的，把卷组中空闲的资源建立出新的逻辑卷，并且逻辑卷建立之后可以动态的扩展或缩小空间，这也就是LVM逻辑卷管理器的核心理念。 部署逻辑卷很多时候最初咱们都不能够精准的评估和分配每个硬盘分区以后的使用情况，有可能会随着业务量的增加导致数据库目录的体积也增加，也有可能需要分析用户行为而做记录导致日志目录的体积不断变大，或者有些较小概率还要对原先错误分配过大的分区进行精简，那么这些知识都属于这一节的学习范畴。LVM逻辑卷管理器是对Linux系统中对存储资源进行管理的一种机制，部署LVM逻辑卷管理器需要依次对对物理卷、卷组和逻辑卷的逐个配置，常见的命令分别包括有： 功能/命令 物理卷管理 卷组管理 逻辑卷管理 扫描 pvscan vgscan lvscan 建立 pvcreate vgcreate lvcreate 显示 pvdisplay vgdispaly lvdisplay 删除 pvremove vgremove lvremove 扩展 vgextend lvextend 缩小 vgreduce lvreduce 为避免实验之间互相冲突，请您自行还原虚拟机到最初始状态，并在虚拟机中添加两块新硬盘设备后开机，如图所示：在虚拟机中添加两块新硬盘设备的目的是为了更好的向同学们演示LVM逻辑卷管理器对于让用户无需关心底层物理硬盘设备的特性，咱们将会对这两块新的硬盘先进行创建物理卷操作，可以简单理解成让硬盘设备支持LVM技术，然后对两块硬盘进行卷组合并，卷组的名称可以由您来自定义，接下来是把合并后的卷组根据需求再切割出一个约为150M的逻辑卷设备，最后把这个逻辑卷设备格式化成ext4格式文件系统后挂载使用，第一步，让新添加的两块硬盘支持LVM逻辑卷管理技术技术。[root@localhost ~]# pvcreate /dev/sdb /dev/sdcPhysical volume &quot;/dev/sdb&quot; successfully createdPhysical volume &quot;/dev/sdc&quot; successfully created第二步，把两块硬盘设备都加入到storage卷组中，然后查看卷组的状态。[root@localhost ~]# vgcreate storage /dev/sdb /dev/sdcVolume group &quot;storage&quot; successfully created[root@localhost ~]# vgdisplay--- Volume group ---VG Name storageSystem IDFormat lvm2Metadata Areas 2Metadata Sequence No 1VG Access read/writeVG Status resizableMAX LV 0Cur LV 0Open LV 0Max PV 0Cur PV 2Act PV 2VG Size 39.99 GiBPE Size 4.00 MiBTotal PE 10238Alloc PE / Size 0 / 0Free PE / Size 10238 / 39.99 GiBVG UUID EI7OeB-HJZG-JXJ7-40qF-vaBP-8NUf-szmJs7......第三步，切割出一个约为150M的逻辑卷。需要注意下切割单位的问题，在LVM逻辑卷管理器对LV逻辑卷的切割上面有两种计量单位，第一种是常见以-L参数来以容量单位为对象，例如使用-L 150M来生成一个大小为150M的逻辑卷，还可以使用-l参数来指定要使用PE基本单元的个数，默认每个PE的大小为4M，因此允许使用-l 37来生成一个大小为37*4M=148M的逻辑卷：[root@localhost ~]# lvcreate -n vo -l 37 storageLogical volume &quot;vo&quot; created[root@localhost ~]# lvdisplay--- Logical volume ---LV Path /dev/storage/voLV Name voVG Name storageLV UUID iJfuTt-ICmE-N321-4hDl-f6LG-eOcy-EC81ziLV Write Access read/writeLV Creation host, time localhost.localdomain, 2017-09-17 20:42:15 +0800LV Status available# open 0LV Size 148.00 MiBCurrent LE 37Segments 1Allocation inheritRead ahead sectors auto- currently set to 8192Block device 253:2...... 第四步，把生成好的逻辑卷格式化后挂载使用。Linux系统会把LVM逻辑卷管理器中的逻辑卷设备存放在/dev设备目录中（实际上是做了一个符号链接，但读者们无需关心）， 同时会以卷组的名称来建立一个目录，其中保存有逻辑卷的设备映射文件，（即/dev/卷组名称/逻辑卷名称）。[root@localhost ~]# mkfs.ext4 /dev/storage/vomke2fs 1.42.9 (28-Dec-2013)Filesystem label=OS type: LinuxBlock size=1024 (log=0)Fragment size=1024 (log=0)Stride=0 blocks, Stripe width=0 blocks38000 inodes, 151552 blocks7577 blocks (5.00%) reserved for the super userFirst data block=1Maximum filesystem blocks=3381657619 block groups8192 blocks per group, 8192 fragments per group2000 inodes per groupSuperblock backups stored on blocks:8193, 24577, 40961, 57345, 73729 Allocating group tables: doneWriting inode tables: doneCreating journal (4096 blocks): doneWriting superblocks and filesystem accounting information: done [root@localhost ~]# mkdir /linux[root@localhost ~]# mount /dev/storage/vo /linux 第五步，查看挂载状态，并写入配置文件中永久生效。[root@localhost ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/rhel-root 18G 2.9G 15G 17% /devtmpfs 905M 0 905M 0% /devtmpfs 914M 92K 914M 1% /dev/shmtmpfs 914M 8.8M 905M 1% /runtmpfs 914M 0 914M 0% /sys/fs/cgroup/dev/sda1 497M 119M 379M 24% /boot/dev/sr0 3.5G 3.5G 0 100% /run/media/caijy/RHEL-7.0 Server.x86_64/dev/mapper/storage-vo 140M 1.6M 128M 2% /linux[root@localhost ~]# echo &quot;/dev/storage/vo /linux ext4 defaults 0 0&quot; &gt;&gt; /etc/fstab 扩容逻辑卷虽然卷组是由两块硬盘设备共同组成的，但用户使用存储资源时感知不到底层硬盘的结构，也不用关心底层是由多少块硬盘组成的，只要卷组中的资源足够就可以一直为逻辑卷扩容，扩展前请一定要记得卸载设备和挂载点的关联。[root@localhost ~]# umount /linux 第一步，把上个实验中的逻辑卷vo扩展至290M。[root@localhost ~]# lvextend -L290M /dev/storage/voRounding size to boundary between physical extents: 292.00 MiBExtending logical volume vo to 292.00 MiBLogical volume vo successfully resized 第二步，检查磁盘完整性，重置磁盘容量。[root@localhost ~]# e2fsck -f /dev/storage/voe2fsck 1.42.9 (28-Dec-2013)Pass 1: Checking inodes, blocks, and sizesPass 2: Checking directory structurePass 3: Checking directory connectivityPass 4: Checking reference countsPass 5: Checking group summary information/dev/storage/vo: 11/38000 files (0.0% non-contiguous), 10453/151552 blocks[root@localhost ~]# resize2fs /dev/storage/voresize2fs 1.42.9 (28-Dec-2013)Resizing the filesystem on /dev/storage/vo to 299008 (1k) blocks.The filesystem on /dev/storage/vo is now 299008 blocks long. 第三步，重新挂载硬盘设备并查看挂载状态。[root@localhost ~]# mount -a[root@localhost ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/rhel-root 18G 2.9G 15G 17% /devtmpfs 905M 0 905M 0% /devtmpfs 914M 92K 914M 1% /dev/shmtmpfs 914M 8.8M 905M 1% /runtmpfs 914M 0 914M 0% /sys/fs/cgroup/dev/sda1 497M 119M 379M 24% /boot/dev/sr0 3.5G 3.5G 0 100% /run/media/caijy/RHEL-7.0 Server.x86_64/dev/mapper/storage-vo 279M 2.1M 259M 1% /linux 缩小逻辑卷相比于扩容逻辑卷来讲，对逻辑卷的缩小操作存在着更高丢失数据的风险，所以在生产环境中同学们一定要留心记得提前备份好数据，另外Linux系统规定对LVM逻辑卷的缩小操作需要先检查文件系统的完整性，当然这也是在保证咱们的数据安全，操作前记得先把文件系统卸载掉：[root@localhost ~]# umount /linux 第一步，检查文件系统的完整性。[root@localhost ~]# e2fsck -f /dev/storage/voe2fsck 1.42.9 (28-Dec-2013)Pass 1: Checking inodes, blocks, and sizesPass 2: Checking directory structurePass 3: Checking directory connectivityPass 4: Checking reference countsPass 5: Checking group summary information/dev/storage/vo: 11/74000 files (0.0% non-contiguous), 15507/299008 blocks 第二步，把LV逻辑卷的容量减小至120M。[root@localhost ~]# resize2fs /dev/storage/vo 120Mresize2fs 1.42.9 (28-Dec-2013)Resizing the filesystem on /dev/storage/vo to 122880 (1k) blocks.The filesystem on /dev/storage/vo is now 122880 blocks long. 第三步，把文件系统重新挂载并查看挂载状态。[root@localhost ~]# mount -a[root@localhost ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/rhel-root 18G 2.9G 15G 17% /devtmpfs 905M 0 905M 0% /devtmpfs 914M 92K 914M 1% /dev/shmtmpfs 914M 8.8M 905M 1% /runtmpfs 914M 0 914M 0% /sys/fs/cgroup/dev/sda1 497M 119M 379M 24% /boot/dev/sr0 3.5G 3.5G 0 100% /run/media/caijy/RHEL-7.0 Server.x86_64/dev/mapper/storage-vo 113M 1.6M 103M 2% /linux 逻辑卷快照LVM逻辑卷管理器还具备有“快照卷”的功能，这项功能很类似于虚拟机软件的还原时间点功能。例如可以对某一个LV逻辑卷设备做一次快照，如果今后发现数据被改错了，咱们可以把之前做好的快照卷进行覆盖还原，LVM逻辑卷管理器的快照功能有两项特点：第一是快照卷的大小应该尽量等同于LV逻辑卷的容量，第二是快照功能仅一次有效，一旦被还原后则会被立即删除， 首先应当查看下卷组的信息：[root@localhost ~]# vgdisplay--- Volume group ---VG Name storageSystem IDFormat lvm2Metadata Areas 2Metadata Sequence No 3VG Access read/writeVG Status resizableMAX LV 0Cur LV 1Open LV 1Max PV 0Cur PV 2Act PV 2VG Size 39.99 GiBPE Size 4.00 MiBTotal PE 10238Alloc PE / Size 73 / 292.00 MiBFree PE / Size 10165 / 39.71 GiBVG UUID EI7OeB-HJZG-JXJ7-40qF-vaBP-8NUf-szmJs7......接下来往逻辑卷设备所挂载的目录中用重定向写入一个文件吧：[root@localhost ~]# echo &quot;Welcome to linux&quot; &gt; /linux/readme.txt[root@localhost ~]# ls -l /linuxtotal 14drwx------. 2 root root 12288 Sep 17 20:47 lost+found-rw-r--r--. 1 root root 17 Sep 17 21:07 readme.txt 第一步，使用-s参数生成一个快照卷，使用-L参数来指定切割的大小，另外要记得在后面写上这个快照是针对那个LV逻辑卷设备做的。[root@localhost ~]# lvcreate -L 120M -s -n SNAP /dev/storage/voLogical volume &quot;SNAP&quot; created[root@localhost ~]# lvdisplay......--- Logical volume ---LV Path /dev/storage/SNAPLV Name SNAPVG Name storageLV UUID OxieTi-p4yd-llT6-UG22-V1us-mau4-efv4RiLV Write Access read/writeLV Creation host, time localhost.localdomain, 2017-09-17 21:09:02 +0800LV snapshot status active destination for voLV Status available# open 0LV Size 292.00 MiBCurrent LE 73COW-table size 120.00 MiBCOW-table LE 30Allocated to snapshot 0.01%Snapshot chunk size 4.00 KiBSegments 1Allocation inheritRead ahead sectors auto- currently set to 8192Block device 253:3...... 第二步，将LV设备卷缩挂载的目录中创建一个100M的垃圾文件，这样再来看快照卷的状态就会发现使用率上升了：[root@localhost ~]# dd if=/dev/zero of=/linux/files count=1 bs=100M1+0 records in1+0 records out104857600 bytes (105 MB) copied, 1.65885 s, 63.2 MB/s[root@localhost ~]# lvdisplay......--- Logical volume ---LV Path /dev/storage/SNAPLV Name SNAPVG Name storageLV UUID OxieTi-p4yd-llT6-UG22-V1us-mau4-efv4RiLV Write Access read/writeLV Creation host, time localhost.localdomain, 2017-09-17 21:09:02 +0800LV snapshot status active destination for voLV Status available# open 0LV Size 292.00 MiBCurrent LE 73COW-table size 120.00 MiBCOW-table LE 30Allocated to snapshot 83.71% --!!!Snapshot chunk size 4.00 KiBSegments 1Allocation inheritRead ahead sectors auto- currently set to 8192Block device 253:3...... 第三步，为了检验SNAP快照卷的效果，需要对逻辑卷进行快照合并还原操作，在这之前记得先卸载掉逻辑卷设备与目录的挂载~[root@localhost ~]# umount /linux[root@localhost ~]# lvconvert --merge /dev/storage/SNAPMerging of volume SNAP started.vo: Merged: 16.3%vo: Merged: 100.0%Merge of snapshot into logical volume vo has finished.Logical volume &quot;SNAP&quot; successfully removed 第四步，快照卷会被自动删除掉，并且刚刚在逻辑卷被快照后创建的100M垃圾文件也被清除了。[root@localhost ~]# mount -a[root@localhost ~]# ls /linuxlost+found readme.txt 删除逻辑卷当生产环境中想要重新部署或者不需要再继续使用LVM逻辑卷管理器了，除了提前备份好重要数据信息，还必须 依次删除LV逻辑卷、VG卷组后再移除PV物理卷设备，这样的顺序不可颠倒。 第一步，取消逻辑卷与目录的挂载关联，删除配置文件中永久生效的设备参数。[root@localhost ~]# umount /linux[root@localhost ~]# vim /etc/fstab## /etc/fstab# Created by anaconda on Sun Sep 17 19:11:14 2017## Accessible filesystems, by reference, are maintained under &#39;/dev/disk&#39;# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/rhel-root / xfs defaults 1 1 UUID=d357b1a3-003d-46b4-8c15-6beedeab36ca /boot xfs defaults 1 2/dev/mapper/rhel-swap swap swap defaults 0 0 第二步，把LV逻辑卷设备删除，需要手工输入y来确认操作：[root@localhost ~]# lvremove /dev/storage/voDo you really want to remove active logical volume vo? [y/n]: yLogical volume &quot;vo&quot; successfully removed 第三步，把VG卷组删除，此处只需要写卷组名称即可，而无需设备完整绝对路径：[root@localhost ~]# vgremove storageVolume group &quot;storage&quot; successfully removed 第四步，把PV物理卷设备移除。[root@localhost ~]# pvremove /dev/sdb /dev/sdcLabels on physical volume &quot;/dev/sdb&quot; successfully wipedLabels on physical volume &quot;/dev/sdc&quot; successfully wiped执行以上操作后大家可以再分别执行下lvdisplay、vgdisplay、pvdisplay命令来查看逻辑卷管理器信息，操作正确则会不能再看到逻辑卷设备信息了。 转载自：http://www.linuxprobe.com/chapter-07.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础课程06]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F15%2FLinux%E5%9F%BA%E7%A1%80%E8%AF%BE%E7%A8%8B06%2F</url>
    <content type="text"><![CDATA[Linux系统中颇具特色的文件存储结构常常搞的新手头晕，这里将从Linux系统中的文件存储结构引入，讲述FHS文件系统标准协定、Udev硬件命名规则以及硬盘分区的规划方法。为了使得同学们更好的理解文件系统的作用，我们将着重练习对硬盘设备分区、格式化以及挂载等常用硬盘管理操作，帮助大家更熟练的掌握文件系统使用的方法。基于扎实的理论与实践练习课程后，咱们会进一步完整的部署SWAP交换分区、配置quota磁盘配额服务以及掌握ln命令带来的软硬链接，总之学习完大家不论是对Linux系统还是对Windows系统中的硬盘存储及文件系统都会有了深刻的理解。 一切从“/”开始Linux系统中的目录、字符设备、块设备、套接字、打印机等等都被抽象成了文件,即——Linux系统中一切都是文件。既然平时跟咱们打交道的都是文件，那么又应该如何的找到它们呢？在Windows操作系统中想要找到一个文件，肯定就要依次进入“D盘”后再进入某某目录中找到所需要的文件，但在Linux系统中可并不存在C/D/E/F盘符呦，一切的文件都是从“根(/)”目录开始的，按照FHS文件系统层次结构标准协定采用树形结构来存放文件并定义了每个区域的用途。另外在Linux系统中的文件及目录名称是严格区分大小写的，例如root、rOOt、Root、rooT等等均代表是不同的独立目录，并且名称中不得包含斜杠(/)。刚刚提到的FHS文件系统层次结构标准协定（Filesystem Hierarchy Standard）是工程师们在Linux系统中存储文件的时候需要遵守的规则，FHS是根据以往无数Linux系统用户和开发者的经验而总结出来的，指导咱们应该把文件保存到什么位置，以及告诉运维人员应该在何处找到所需的文件。但目前FHS对于运维工程师来讲也算是一种道德操守，有些运维人员就是懒得遵守，或者根本没有听说过这个东东，依然会把文件到处乱放。最常见的目录所对应的用处包括有： 目录名称 应放置文件的内容 /boot 开机所需文件——内核,开机菜单及所需配置文件等 /dev 任何设备与接口都以文件形式存放在此目录 /etc 配置文件 /home 用户主目录 /bin 单用户维护模式下还能被操作的命令 /lib 开机时用到的函数库及/bin与/sbin下面命令要调用的函数 /sbin 开机过程中需要的 /media 一般挂载和删除的设备 /opt 放置第三方的软件 /root 系统管理员的主文件夹 /srv 一些网络服务的数据目录 /tmp 任何人均可使用的“共享”临时目录 /proc 虚拟文件系统，例如系统内核，进程，外部设备及网络状态等 /usr/local 用户自行安装的软件 /usr/sbin 非系统开机时用到的软件/命令/脚本 /usr/share 帮助与说明文件，也可放置共享文件 /var 主要存放经常变化的文件，如：日志 /lost+found 当文件系统发生错误时，将一些丢失的文件片段存放在这里 另外还有一个重要的概念——“路径”，路径指的是如何定位到某个文件，分为 绝对路径 和 相对路径，在Linux系统中的绝对路径指的是从根目录（/）开始写起的文件或目录名称，而相对路径则指的是相对于当前路径的写法。 物理设备的命名规则Linux系统中一切都是文件，那么硬件设备肯定也不例外，既然是文件就必须有名称啦，系统内核的udev设备管理器会自动把硬件名称规范起来，目的是让运维人员可以通过设备文件的名字猜出设备大致的属性以及分区信息等，对于陌生的设备这点特别的方便，另外udev服务会一直以守护进程的形式运行并侦听来自内核发出的信号来管理/dev目录下的设备文件，常见的硬件命名规则如下： 硬件设备 文件名称 IDE设备 /dev/hd[a-d] SCSI/SATA/U盘 /dev/sd[a-p] 软驱 /dev/fd[0-1] 打印机 /dev/lp[0-15] 光驱 /dev/cdrom 鼠标 /dev/mouse 磁带机 /dev/st0或/dev/ht0(IDE设备) 因为现在的IDE设备已经很少见啦，所有一般的硬盘设备都是以 “/dev/sd” 开头的，而一台主机上可以有多块硬盘，因此系统便会用 a-p 来代表16块不同的硬盘（默认从a开始分配）且分区编号也很有讲究。 主分区或扩展分区的编号从1开始至4结束。 逻辑分区从编号5开始 很多技术书籍中提到比如/dev/sda就是代表系统主板上第一个插槽上的存储设备，同学们在实践操作的时候会发现果然如此，也就对这条理论知识更加深信不疑，但其实并不是这样的，/dev目录中sda设备之所以是a，并不是由插槽决定的，而是由系统内核的识别顺序决定的，而恰巧很多主板的插槽顺序就是系统内核的识别顺序因此才会被命名为/dev/sda，以后在使用iscsi网络存储设备时候就会发现，明明主板上第二个插槽是空着的，但却能识别到/dev/sdb这个设备就是这个道理。多Linux老师告诉学生分区的编号代表分区的个数，例如sda3就代表这个设备上的第三个分区，一般学生做实验的时候确实也会得出同样的效果，但这并不正确，因为分区的数字编码不一定是强制顺延下来的，而有可能是手工指定的，因此sda3只能表示是编号为3的分区文件，而不能因此判断sda设备上已经存在了3个分区。接下来一起分析/dev/sda5这个设备文件包含有那些信息吧~首先 /dev/ 目录中保存的是硬件设备文件，其次 sd 开头代表是存储设备，然后 a 代表是系统中同类接口中第一个被识别到设备，最后的 5 代表这个设备一定是个逻辑分区。简单总结来说“/dev/sda5”代表的就是—— “这是系统中第一块被识别到的硬件设备中分区编号为5的逻辑分区的文件”，很多同学可能基础并不好，不太理解前面所说的主分区、扩展分区和逻辑分区的概念，接下来简单科普下硬盘的知识，看懂就好。计算机中有了硬盘设备才使得游戏通关过后可以保存记录而不是再每次再重头开始，硬盘设备则是由大量的 扇区 组成的，其中第一个扇区最重要，它里面保存着 主引导记录 与 分区表信息。单个扇区容量为 512bytes 组成，主引导记录需要占用446bytes，分区表的为64bytes，结束符占用2bytes，而其中每记录一个分区信息需要16bytes，这最多四个能有幸被写到第一个扇区中的分区信息就叫做主分区，扇区的信息写入如图：那么问题来了——好像最多只能创建出4个分区？于是为了解决分区个数不够的问题，可以将其中的16bytes(原本要写入主分区信息)的空间拿出来指向到另外一个分区上面，也就是说扩展分区其实并不是一个“分区”，而更像是一个“指针”，指向了另外的一个分区的指针。那么运维人员一般会选择用3个主分区加1个扩展分区的方法，然后在扩展分区中创建出数个逻辑分区，这样就可以用分区来满足多分区的需求了， 文件系统与数据资料用户在硬件存储设备上正常 建立文件，写入，读取，修改，转存文件与控制文件 等等操作，都是依靠文件系统完成的，文件系统的作用是把硬盘合理的规划，保证用户正常的使用需求，在Linux系统中支持的文件系统就有数十种，而最常见的文件系统有： Ext3 是一款日志文件系统，能够在异常宕机中避免文件系统资料丢失的情况，自动修复数据的不一致与错误，然而对于容量较大的硬盘来说需要耗费在修复的时间也非常多，并且也不能保证100%资料不丢失，它会把整个磁盘的写入动作细节都预先记录下来，以便在异常宕机后能够回溯追踪到被中断的部分。 Ext4 可以称为是Ext3的后继版本，作为RHEL6系统中的默认文件管理系统，它支持更大的文件系统到1EB（1EB=1,073,741,824GB且能够有无限多的子目录），另外Ext4文件系统能够批量分配block块并作“Extends”极大的提高了读写效率。 XFS 作为最新RHEL7中默认的文件管理系统，它的日志型文件管理系统的优势在意外宕机后尤其明显， 可以快速恢复可能被破坏的文件，另外经过优化后日志功能对硬盘性能影响非常小，同时最大支持18EB的存储容量满足了几乎所有需求。 在红帽RHEL7系统中比较大的变化之一就是在文件系统方面使用XFS替换了Ext4，从红帽官方发布的说明来看确实是一次不小的进步，但是我在实测中发现并不完全属实，因为单讲对于测试一款文件系统的“读取”这一评测项目，到底要测试读取的文件个数有多少个？每个文件的大小是多少？读取时占用CPU、内存等系统资源情况，以及操作系统、不同的硬件配置等等，在效能方面XFS虽然比Ext4有所提升，但绝不是压倒性的，因此XFS文件系统最卓越的亮点应该当属可支持18EB的存储容量吧~ 当咱们拿到了一块新的硬盘存储设备之后首先要分区，然后格式化文件系统最后才能挂载正常的使用，就像当拿到了一张大白纸，首先为了使用方便要裁剪，然后为了书写工整要先画格。分区的操作取决于您的需求和硬盘大小，也是可以不做的，而格式化文件系统则是必做的。 日常中在硬盘要保存的数据实在太多了，于是就有个叫“super block”的硬盘地图，并不是把数据直接写在这个大地图里面，而是在上面记录着整个文件系统的信息，因为如果把所有信息都写入这里面的话，就一定会导致它的体积变大，查询与写入的速度会变呃很慢，于是每个文件的权限与属性都会记录在“inode”中（每个文件都会占用一个inode表格，大小为128bytes），记录着： 该文件的访问权限(read,write,execute) 该文件的所属主和组(owner,group) 该文件的大小（size） 该文件的创建和状态改变时间（ctime） 该文件最后一次访问时间（atime） 该文件的修改时间（mtime） 文件的特殊权限（SUID，SGID，SBIT） 该文件的真实数据地址(point) 而文件的实际数据内容则保存在block块中（大小可以是1K、2K或4K），一个inode大小仅为128bytes（Ext3），记录一个block消耗4bytes，一般当把inode写满后就会取出一个block用于号码记录而不再是保存实际的文件系统。下面的说明中以4K为例。 文件体积很小（1K），那么依然会占用一个block，潜在的浪费3K。 文件体积很大（5K），那么会占用两个（5K-4K剩下的1K也要占用一个block）。 实际上随着计算机系统的发展产生出了众多的文件系统，为了使用户在读取或写入文件时不用关心底层的硬盘结构，于是在Linux内核中的软件层为用户程序提供了一个VFS文件系统接口（Virtul File System），这样就转而统一对这个虚拟文件系统进行操作啦。如图，即 实际文件系统在VFS下隐藏了自己的特性与细节，使得咱们在日常使用时觉得“文件系统都是一样的”，比如使用cp命令就在任何文件系统中复制文件了。 挂载硬件设备用习惯了Windows系统让咱们觉得一切都理所应当，平时把U盘插入到电脑后也根本没有考虑过到底系统做了那些事情，又是为什么能够访问到这个U盘内资料的。前面所讲当拿到了一块全新的硬盘存储设备之后首先要分区，然后格式化最后才能挂载正常使用。分区和格式化大家以前常常听到，但“挂载”又是个什么东东呢？有一个简单，贴切的解释——挂载操作指的是当用户需要硬盘设备或分区数据时，需要先将其与一个已存在的目录文件“做关联”，而这个动作就交“挂载”。 mount命令用于挂载文件系统，格式为：“mount 文件系统 挂载目录”。 挂载是使用硬件设备前的最后一步操作，只需要用mount命令把硬件设备与一个目录做关联，然后就能在这个目录中看到硬件设备中的数据。对于比较新的Linux系统来讲一般是不需要用-t参数来指定文件系统类型的，这点Linux系统会自行判断，而mount -a命令参数是非常厉害的，执行后会自动检查/etc/fstab文件中是否有无疏漏被挂载的设备文件，然后进行自动挂载： 参数 作用 -a 挂载所有在/etc/fstab中定义的文件系统 -t 指定文件的类型 例如需要把设备”/dev/sdb2”挂载到”/backup”目录，文件格式是ext4。mount命令只需要填写设备与挂载目录参数就行，一般系统会自动去判断要挂载文件的类型~因此只需要这样来做： 执行命令：mount /dev/sdb2 /backup 虽然按照上面的方法执行mount命令后就能立即使用文件系统了，但重启后挂载就会失效，也就是说需要每次开机后都手动的挂载一下，这肯定不是咱们想要的方案，因此如果想把硬件设备和目录永久的进行自动关联，就必须把挂在信息按照指定的格式写入 /etc/fstab 文件中这个文件中包含着诸多挂载所需的信息项目，一旦配置好之后就能永久的为您服务啦。 填写格式如下：“设备文件 挂载目录 格式类型 权限选项 自检 优先级” 设备文件：一般为设备的路径+设备名称，也可以写UUID。 挂载目录：指定要挂载到的目录，需挂载前先创建好。 格式类型：即指定文件系统的格式，比如有ext3/ext4/xfs/swap/iso9660（此为光盘设备）等等。 权限选项：默认为defaults（rw，suid，dev，exec，auto，nouser，async） 自检：若为1则开机后进行磁盘自检，0为不自检。 优先级：若“自检为1”，则可对多块硬盘进行优先级设置。 那么要想让文件系统为”ext4”的硬件设备”/dev/sdb2”开机后自动挂载到”/backup”目录上，默认权限且无需开机自检，就需要在/etc/fstab文件中写入下面的信息，重启后检查也会成功~[root@caijy ~]# vim /etc/fstab## /etc/fstab# Created by anaconda on Wed May 4 19:26:23 2017## Accessible filesystems, by reference, are maintained under &#39;/dev/disk&#39;# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/rhel-root / xfs defaults 1 1UUID=812b1f7c-8b5b-43da-8c06-b9999e0fe48b /boot xfs defaults 1 2/dev/mapper/rhel-swap swap swap defaults 0 0/dev/cdrom /media/cdrom iso9660 defaults 0 0/dev/sdb2 /backup ext4 defaults 0 0 umount命令用于撤销已经挂载的设备文件，格式为：“unmount [挂载点/设备文件]”。挂载文件系统是为了使用硬件资源，卸载文件系统就意味不再使用硬件的设备资源，而挂载的操作就是硬件设备与目录的关联动作，因此卸载操作只需要说明想要取消关联的设备文件或挂载目录其中的一项即可，而且一般也不需要加其他额外的参数，例如来尝试手动的卸载掉“/dev/sdb2”这个设备文件吧：[root@caijy ~]# umount /dev/sdb2 添加硬盘设备根据刚刚对管理硬件设备所学的理论知识，先来理清一下思路吧~首先需要在虚拟机中模拟再添加入一块新的硬盘存储设备，然后逐步的进行分区、格式化、挂载操作，最后通过检查系统挂载状态和真实的使用来最终验证硬件是否已正确部署好了吧。 使用虚拟机软件的好处又一次体现出来了，因为咱们不需要为了做这个实验而特意去买一块真实的硬盘，而是通过虚拟机软件进行硬件模拟就可以，操作步骤首先是把虚拟机系统关机后点击“编辑虚拟设置”选项，选择添加按钮新增一块新的硬件设备,依次点击下一步即可（步骤省略，若不会请自行百度）。 在虚拟机中成功模拟了硬盘设备后就应该能够看到抽象成的设备文件了，按照前面说的udev服务命名规则，第二个被识别的SCSI设备应该会被保存成/dev/sdb，这个就是硬盘设备文件啦。但在开始使用前还应该进行分区操作，从中取出一个500M的分区设备以供后面的操作使用。fdisk命令用于管理磁盘分区，格式为：“fdisk [磁盘文件]”管理Linux系统中的硬盘设备最常用的方法就当属是用fdisk命令了，这条命令提供了添加，删除，转换分区等等功能于一身的“一站式分区服务”，不过这条命令的参数是交互式的，而不是像咱们以前直接写到命令后面的参数一样，因此在管理硬盘设备的时候特别方便，可以根据需求动态的调整。 参数 作用 m 查看全部可用的参数 n 添加新的分区 d 删除某个分区信息 I 列出所有可用的分区类型 t 改变某个分区的类型 P 查看分区表信息 w 保存并退出 q 不保存直接退出 第1步：首先使用fdisk命令尝试管理/dev/sdb硬盘设备，看到提示信息后输入参数p来查看硬盘设备内已有的分区信息，这其中包括了硬盘的容量大小，扇区个数等等信息：[root@linuxprobe ~]# fdisk /dev/sdbWelcome to fdisk (util-linux 2.23.2).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Device does not contain a recognized partition tableBuilding a new DOS disklabel with disk identifier 0x47d24a34.Command (m for help): pDisk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x47d24a34Device Boot Start End Blocks Id System 第2步：输入参数n来尝试新建分区信息，系统会要求选择继续输入参数p来创建主分区，或者输入参数e来创建扩展分区，因此输入参数p来创建一个主分区：Command (m for help): nPartition type:p primary (0 primary, 0 extended, 4 free)e extendedSelect (default p): p第3步：确认创建一个主分区后，系统要求您先输入分区的编号，既然已经知道主分区的编号范围是1-4，因此默认输入1就可以了，接下来系统会提示定义下起始的扇区，这一项默认不需要改动，系统会自动计算出最靠前空闲的扇区位置，咱们敲击一下回车就可以，最后系统会要求定义分区的结束扇区位置，这其实就是想要去定义下整个分区的大小是多少，但其实不用去算扇区的个数，只需要输入+2G即可创建出一个容量为2G的硬盘分区。Partition number (1-4, default 1): 1First sector (2048-41943039, default 2048):此处敲击回车Using default value 2048Last sector, +sectors or +size{K,M,G} (2048-41943039, default 41943039): +2GPartition 1 of type Linux and of size 2 GiB is set第4步：再次使用参数p来查看下硬盘设备中的分区信息，果然就能看到一个名称为/dev/sdb1，起始扇区为2048，结束扇区是4196351的分区啦，这时候千万不要直接关闭窗口，而应该敲击参数w后回车，这样分区信息才是真正的写入成功啦。Command (m for help): pDisk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x47d24a34Device Boot Start End Blocks Id System/dev/sdb1 2048 4196351 2097152 83 LinuxCommand (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks.第5步：当做完上面所说的所有步骤后，Linux系统会自动把这个硬盘分区抽象成/dev/sdb1这个设备文件，可以用file命令来看到这个文件的属性，但是有些时候系统并没有自动的把分区信息同步给Linux内核，而且这种情况似乎还比较常见，但不能算作是严重的bug，因为如果设备信息没有被抽象为文件，也可以输入partprobe命令来手动的同步信息到内核，而且一般推荐敲击两次会效果更佳，但一旦遇到连这个命令都不能解决的时候，那么就重启计算机吧，这个杀手锏百试百灵，一定会有用的。[root@caijy ]# file /dev/sdb1/dev/sdb1: cannot open (No such file or directory)[root@caijy ]# partprobe[root@caijy ]# partprobe[root@caijy ]# file /dev/sdb1/dev/sdb1: block specialLinux系统对于没有被格式化的存储设备是不知道怎么样写入数据的，因此当咱们对存储设备分区后需要再进行一次格式化操作，很类似于平时给白纸划上横线，这样再写字的时候就会十分规整有条理啦，在Linux系统中用于格式化的是mkfs命令，这条命令很有意思，因为在Shell终端中输入mkfs后再敲击两下Tab键补齐命令就会有这样的效果：[root@caijy ~]# mkfsmkfs mkfs.cramfs mkfs.ext3 mkfs.fat mkfs.msdos mkfs.xfsmkfs.btrfs mkfs.ext2 mkfs.ext4 mkfs.minix mkfs.vfat对！这个mkfs命令作为一款格式化的工具非常贴心，它把常用的文件系统名称用后缀的方式保存成了文件，使用方法非常的简单：”mkfs.文件类型名称”，例如要格式分区为xfs文件系统，则命令应为”mkfs.xfs /dev/sdb1”。[root@linuxprobe ~]# mkfs.xfs /dev/sdb1meta-data=/dev/sdb1 isize=256 agcount=4, agsize=131072 blks= sectsz=512 attr=2, projid32bit=1= crc=0data = bsize=4096 blocks=524288, imaxpct=25= sunit=0 swidth=0 blksnaming =version 2 bsize=4096 ascii-ci=0 ftype=0log =internal log bsize=4096 blocks=2560, version=2= sectsz=512 sunit=0 blks, lazy-count=1realtime =none extsz=4096 blocks=0, rtextents=0终于把存储设备给分区、格式化好了，接下来就是要来挂载并使用啦。这些步骤也非常的简单，首先是创建一个用于挂载设备的挂载点目录，然后用mount命令将存储设备与挂载点进行关联，最后还可以用df -h命令来查看下挂载状态和硬盘使用量信息。[root@caijy ~]# mkdir /newFS[root@caijy ~]# mount /dev/sdb1 /newFS/[root@caijy ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/rhel-root 18G 3.4G 15G 20% /devtmpfs 905M 0 905M 0% /devtmpfs 914M 148K 914M 1% /dev/shmtmpfs 914M 8.9M 905M 1% /runtmpfs 914M 0 914M 0% /sys/fs/cgroup/dev/sr0 3.5G 3.5G 0 100% /media/cdrom/dev/sda1 497M 118M 379M 24% /boot/dev/sdb1 2.0G 33M 2.0G 2% /newFS du命令用于查看文件的数据占用量，格式为：“ du [选项] [文件]”。既然存储设备已经顺利的挂载完毕，就可以来尝试通过挂载点目录往存储设备中写入文件了，顺便再给同学们介绍一下用于查看文件数据占用量的du命令，简单来说就是看一个或多个文件占用了多大的硬盘空间，[root@caijy ~]# cp -rf /etc/* /newFS/[root@caijy ~]# ls /newFS/abrt hosts pulseadjtime hosts.allow purplealiases hosts.deny qemu-gaaliases.db hp qemu-kvmalsa idmapd.conf radvd.confalternatives init.d rc0.danacrontab inittab rc1.d………………省略部分输入信息………………[root@linuxprobe ~]# du -sh /newFS/35M /newFS/细心的同学一定想到刚刚讲过使用mount命令挂载的设备文件会在下一次重启的时候失效，因此如果您还想让这个设备文件的挂载永久的有效下去，需要把挂载的信息项目写入到配置文件才可以：[root@caijy ~]# vim /etc/fstab## /etc/fstab# Created by anaconda on Wed May 4 19:26:23 2017## Accessible filesystems, by reference, are maintained under &#39;/dev/disk&#39;# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/rhel-root / xfs defaults 1 1UUID=812b1f7c-8b5b-43da-8c06-b9999e0fe48b /boot xfs defaults 1 2/dev/mapper/rhel-swap swap swap defaults 0 0/dev/cdrom /media/cdrom iso9660 defaults 0 0/dev/sdb1 /newFS xfs defaults 0 0 添加交换分区SWAP交换分区是一种类似于Windows系统虚拟内存的功能，通过把一部分硬盘空间虚拟成内存来使用，从而解决内存容量不足的情况。但由于SWAP毕竟是用硬盘资源虚拟的，速度上比真实物理内存要慢很多，所以一般只有当真实物理内存耗尽时才会调用SWAP交换分区，把内存中暂时不常用的数据临时存放到硬盘中，腾出内存空间让更活跃的程序服务来使用。 第1步：SWAP交换分区的创建过程非常类似于上一个小节所讲到的分区设备挂载使用的方法，首先第一步就是再进行对/dev/sdb存储设备分区操作，取出一个大小为5GB的主存储分区然后保存退出即可：[root@caijy ~]# fdisk /dev/sdbWelcome to fdisk (util-linux 2.23.2).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Device does not contain a recognized partition tableBuilding a new DOS disklabel with disk identifier 0xb3d27ce1.Command (m for help): nPartition type:p primary (1 primary, 0 extended, 3 free)e extendedSelect (default p): pPartition number (2-4, default 2):First sector (4196352-41943039, default 4196352): 此处敲击回车Using default value 4196352Last sector, +sectors or +size{K,M,G} (4196352-41943039, default 41943039): +5GPartition 2 of type Linux and of size 5 GiB is setCommand (m for help): pDisk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0xb0ced57fDevice Boot Start End Blocks Id System/dev/sdb1 2048 4196351 2097152 83 Linux/dev/sdb2 4196352 14682111 5242880 83 LinuxCommand (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.WARNING: Re-reading the partition table failed with error 16: Device or resource busy.The kernel still uses the old table. The new table will be used atthe next reboot or after you run partprobe(8) or kpartx(8)Syncing disks.第2步：把新建的存储分区使用SWAP交换分区专用的格式化mkswap命令进行格式化操作：[root@caijy ~]# mkswap /dev/sdb2Setting up swapspace version 1, size = 5242876 KiBno label, UUID=2972f9cb-17f0-4113-84c6-c64b97c40c75第3步：接下来使用swapon命令把准备好的SWAP交换分区设备正式的挂载到系统中，并可以使用free -m 命令来看到交换分区大小的变化（由2047M提升至了7167M）：[root@caijy ~]# free -mtotal used free shared buffers cachedMem: 1483 782 701 9 0 254-/+ buffers/cache: 526 957Swap: 2047 0 2047[root@linuxprobe ~]# swapon /dev/sdb2[root@linuxprobe ~]# free -mtotal used free shared buffers cachedMem: 1483 785 697 9 0 254-/+ buffers/cache: 530 953Swap: 7167 0 7167第4步：对了~为了能够让新的SWAP交换分区设备在重启后依然生效，需要按照下面的格式写入到配置文件中，记得保存哦~[root@caijy ~]# vim /etc/fstab## /etc/fstab# Created by anaconda on Wed May 4 19:26:23 2017## Accessible filesystems, by reference, are maintained under &#39;/dev/disk&#39;# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/rhel-root / xfs defaults 1 1UUID=812b1f7c-8b5b-43da-8c06-b9999e0fe48b /boot xfs defaults 1 2/dev/mapper/rhel-swap swap swap defaults 0 0/dev/cdrom /media/cdrom iso9660 defaults 0 0/dev/sdb1 /newFS xfs defaults 0 0/dev/sdb2 swap swap defaults 0 0 磁盘容量配额Linux系统的设计初衷理念就让许多人一起使用，成为多用户、多任务的操作系统，但是硬件的资源是固定有限的，如果出现个小破坏份子不断的创建文件或下载电影，那么硬盘空间总有一天会被占满的吧.这时就需要 磁盘配额服务 帮助管理员限制某用户或某个用户组对特定文件夹可以使用的最大硬盘空间，一旦超出预算就不再允许他们继续使用。quato服务做磁盘配额可以限制用户的硬盘可用量或最大创建文件数量，并且还有软、硬限制的功能： 软限制：当达到软限制时会提示用户，但允许用户在规定限额内继续使用 硬限制：当达到软限制时会提示用户，且强制终止用户的操作。 在红帽RHEL7系统中已经默认安装了quota磁盘配额服务程序包，但是硬盘设备默认是没有支持的，需要手动的编辑一下配置文件让对应的/boot目录能够支持了quota磁盘配额技术，重启后用mount命令看到/boot目录已经支持了quota磁盘配额技术啦：[root@localhost ~]# vim /etc/fstab## /etc/fstab# Created by anaconda on Sat Sep 16 17:56:05 2017## Accessible filesystems, by reference, are maintained under &#39;/dev/disk&#39;# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/rhel-root / xfs defaults 1 1UUID=d09730e2-1dca-4504-9c00-dfaca1288bd8 /boot xfs defaults,uquota 1 2/dev/mapper/rhel-swap swap swap defaults 0 0重启后：[caijy@localhost Desktop]$ mount | grep boot/dev/sda1 on /boot type xfs (rw,relatime,seclabel,attr2,inode64,usrquota)接下来创建一个用于检查磁盘配额效果的用户，并对/boot目录增加其他人的写权限，保证用户能够正常的写入数据：[root@localhost ~]# useradd tom[root@localhost ~]# chmod -Rf o+w /boot xfs_quota命令用于管理XFS文件系统的quota硬盘配额，格式为：“quota [参数] 配额 文件系统”。这是一个专门针对于xfs文件管理系统管理quota磁盘配额服务而设计的命令，其中 -c 参数用于以参数的形式设置要执行的命令，-x 参数是专家模式，让运维人员能够对quota服务做更多复杂的配置。那么就来用xfs-quota命令设置tom用户对/boot目录的磁盘限额，具体的限额控制包括有硬盘使用软限制为3M，硬盘使用硬限制为6M，创建文件数量软限制为3个，创建文件硬限制为6个。[root@localhost ~]# xfs_quota -x -c &#39;limit bsoft=3m bhard=6m isoft=3 ihard=6 tom&#39; /boot[root@localhost ~]# xfs_quota -x -c report /bootUser quota on /boot (/dev/sda1)BlocksUser ID Used Soft Hard Warn/Grace---------- --------------------------------------------------root 95340 0 0 00 [--------]tom 0 3072 6144 00 [--------]当配置好quota磁盘配额服务对tom用户在/boot目录上的各种限制后，就可以尝试切换到这个普通用户的身份上，然后分别尝试创建一个体积为5M和8M的文件，很明显第二次就会受到了系统限制：[tom@localhost ~]$ dd if=/dev/zero of=/boot/tom bs=5M count=11+0 records in1+0 records out5242880 bytes (5.2 MB) copied, 0.00638878 s, 821 MB/s[tom@localhost ~]$ dd if=/dev/zero of=/boot/tom bs=8M count=1dd: error writing ‘/boot/tom’: Disk quota exceeded1+0 records in0+0 records out6291456 bytes (6.3 MB) copied, 0.00983008 s, 640 MB/s edquota命令用于编辑用户的quota配额限制，格式为：“edquota [参数] [用户]”。在为用户设置了quota磁盘配额限制后可以用edquota来随着需求的变化而进一步修改限额的数值，其中 -u 参数代表要针对那个用户进行的设置，-g 参数则代表要针对那个用户组进行的设置，edquota命令会调用vi或vim编辑器来让用户修改要限制的项目，比如把tom用户的硬盘使用量限额从5M提升到8M来试一试吧：[root@localhost ~]# edquota -u tomDisk quotas for user tom (uid 1001):Filesystem blocks soft hard inodes soft hard/dev/sda1 6144 3072 8192 1 3 6[tom@localhost ~]$ dd if=/dev/zero of=/boot/tom bs=8M count=11+0 records in1+0 records out8388608 bytes (8.4 MB) copied, 0.00972946 s, 862 MB/s[tom@localhost ~]$ dd if=/dev/zero of=/boot/tom bs=10M count=1dd: error writing ‘/boot/tom’: Disk quota exceeded1+0 records in0+0 records out8388608 bytes (8.4 MB) copied, 0.0371469 s, 226 MB/s 软硬方式链接现在可以学习Linux系统中的“快捷方式”，在Windows系统中的快捷方式就是指向原始文件的一个链接文件，让用户能够从不同的位置来访问到原始的文件，而原文件一旦被删除或剪切到其他地方也会导致链接文件失效，但是这个看似简单的东东在Linux系统中可不太一样。 硬链接（hard link） 可以被理解为一个“指向原文件inode的指针”，系统不为它分配独立的inode和文件，所有实际上来说 硬链接文件和原始文件其实是同一个文件，只是名字不同。 于是每添加一个硬链接，该文件的inode连接数就会增加1，直到该文件的inode连接数归0才是彻底删除。也就是说因为硬链接实际就是指向原文件inode的指针，即便原始文件被删除依然可以通过链接文件访问，但是由于技术的局限性而不能跨文件系统也不能链接目录文件。 软链接也称为符号链接（symbolic link） 即“仅仅包含它所要链接文件的路径名”，因此能做目录链接也可以跨越文件系统，但原始文件被删除后链接文件也将失效，性质上和Windows™系统中的“快捷方式”是一样的。 ln命令用于创建链接文件，格式为：“ln [选项] 目标”。为了更好的理解软、硬链接文件的不同性质，先来尝试创建一个类似于Windows系统中的快捷方式软链接吧，这样当原始文件被删除后，新建出来的链接文件一定也就不能再继续读取了。[root@localhost ~]# echo &quot;Welcome to linux&quot; &gt; readme.txt[root@localhost ~]# ln -s readme.txt readit.txt[root@localhost ~]# cat readme.txtWelcome to linux[root@localhost ~]# cat readit.txtWelcome to linux[root@localhost ~]# ls -l readme.txt-rw-r--r--. 1 root root 17 Sep 16 18:59 readme.txt[root@localhost ~]# rm readme.txtrm: remove regular file ‘readme.txt’? y[root@localhost ~]# cat readit.txtcat: readit.txt: No such file or directory接下来创建一个Linux系统中的硬链接来再对原文件硬盘存储位置做一个指针，而这样就不再依赖于原始文件的名称等等信息，也不会在因原文件被删除后导致新的文件读取失败，同时可以看到创建硬链接后的原文件的硬盘链接数量被增加到了2。[root@localhost ~]# echo &quot;Welcome to linux&quot; &gt; readme.txt[root@localhost ~]# ln readme.txt readit.txt[root@localhost ~]# cat readme.txtWelcome to linux[root@localhost ~]# cat readit.txtWelcome to linux[root@localhost ~]# ls -l readme.txt-rw-r--r--. 2 root root 17 Sep 16 19:02 readme.txt[root@localhost ~]# rm readme.txtrm: remove regular file ‘readme.txt’? y[root@localhost ~]# cat readit.txtWelcome to linux 转载自：http://www.linuxprobe.com/chapter-06.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础课程05]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F15%2FLinux%E5%9F%BA%E7%A1%80%E8%AF%BE%E7%A8%8B05%2F</url>
    <content type="text"><![CDATA[Linux系统具有多用户、多任务的历史发展特点，所以也迫使其具有了很好的安全性，保障Linux系统安全的背后是复杂的配置工作。这一节我们学习Linux系统中文件的 所有者、所有组以及其他人 所对应的读(r)写(w)执行(x)的一般权限的作用，会添加、删除、修改用户帐户信息。咱们还可以使用 SUID、SGID与SBIT特殊权限位 让系统权限功能更加的灵活，弥补单纯对文件设置一般权限的功能不足。隐藏权限 能够让系统多一层隐形的防护层，让黑客对关键日志信息最多只能看，而不能修改或删除。通过 ACL访问控制列表 再进一步的针对单一用户、用户组对单一文件或目录进行特殊的权限安排，让文件的权限最大限度满足工作的需求。最后还将学习到使用 su命令与sudo服务 来让普通用户既能够使用到超级管理员的权限来满足日常的工作需求还兼顾系统的安全性，最佳搭配方案。 用户身份与能力安装红帽REHL7操作系统时特别要求设置root用户密码，这个root用户就是存在所有类UNix系统的 超级用户，拥有最高的系统所有权，能够管理系统的各项能力，比如 添加/删除用户，启动/关闭服务进程，开启/禁用硬件设备 等权限。虽然使用root用户工作时不会受到系统的种种限制，但老话讲能力越大，责任越大，一旦使用这个高能的root用户执行了错误的命令有可能会直接回调整个系统~ Linux系统的超级用户之所以是root，并不是因为它的名字叫root，而是因为该用户身份号码——即UID(User IDentification)的数值为0，在Linux系统中的UID就相当于人类社会中的身份证号码一样权威、唯一性，因此Linux系统是通过用户的UID的值来判断用户身份，RHEL7系统中的用户身份包括有： 超级用户UID0：系统的超级用户 系统用户UID1-999：系统中程序服务由不同用户运行，更加安全，默认被限制不能登录系统 普通用户UID1000-：即管理员创建的用于日常工作而不能管理系统的普通用户。 注意UID一定是不能冲突的，管理员创建的普通用户UID从1000开始，即便前面有闲置的号码。 为了方便管理同一组的用户还有一个用户组的概念，用户组号码——GID（Group IDentification），使得咱们可以把多个用户加入到同一个组中，方便统一规划权限或任务，想象公司中有多个部门，而每个部门中又有很多同事，那么如果只想让员工获取到本部门内的共享资源，则就可以针对部门设置权限，而非针对于某个人，例如只有属于技术部分组的人才可以访问公司的数据库信息等等。另外在Linux系统中每个用户在建立时也会自动创建一个与其同名的 基本用户组，这个基本用户组只有该用户一个人，而该用户以后被归纳入的用户组则叫做 扩展用户组，因此一个用户只有一个基本用户组，而可以有多个扩展用户组，来满足日常的工作需要。 useradd命令用于创建新的用户，格式为：“useradd [选项] 用户名”。可以使用这个命令来创建用户账户，默认的用户家目录会被存放在/home目录，默认的Shell解释器是/bin/bash，默认会创建一个与该用户同名的基本用户组以及默认该用户不包含其他的扩展用户组，这些默认值可以依据下面useradd命令的参数来自行修改： 参数 作用 -d 指定用户的家目录（默认为/home/username） -e 账号有效截至日期，格式：YYYY-MM-DD. -u 指定该用户的默认UID -g 指定该用户的默认UID -G 指定一个或多个扩展用户组 -N 不创建与用户同名的基本用户组 -s 指定该用户的默认Shell 创建一个普通用户并指定家目录路径、UID用户身份号码以及Shell解释器，其中/sbin/nologin是终端解释器的一员，它与bash解释器有着天壤之别，因为一旦用户的解释器被设置成了nologin，那么则代表该用户不能登录到系统：[root@caijy Desktop]# useradd -d /home/linux -u 8888 -s /sbin/nologin linuxprobe[root@caijy Desktop]# id linuxprobeuid=8888(linuxprobe) gid=8888(linuxprobe) groups=8888(linuxprobe) groupadd命令用于创建群组，格式为：”groupadd [选项] 群组名”。为了能够让系统中各个用户的权限指派更加的有效率，工作中常常会把几个用户组设置成某个用户的扩展用户组，这样的话就可以针对于一类用户进行统一的权限安排了，而这个步骤非常的简单，例如创建一个名字叫做ronny的用户组：[root@caijy Desktop]# groupadd ronny usermod命令用于修改用户的属性，格式为“usermod [选项] 用户名”。在Linux系统中一切都是文件，因此在系统中创建用户也是修改配置文件的过程，用户的信息被保存在/etc/passwd文件中，可以直接使用文本编辑器来修改其中的数值项目，也可以用usermod命令来修改已经创建的用户信息项目，诸如用户身份号码、基本/扩展用户组、默认终端等等： 参数 作用 -c 填写帐号的备注信息 -d -m -m与-d连用，可重新指定用户的家目录并自动把旧的数据转移过去。 -e 账户到期时间，格式“YYYY-MM-DD” -g 变更所属用户组 -G 变更扩展用户组 -L 锁定用户禁止其登陆系统 -U 解锁用户，允许其登陆系统 -s 变更默认终端 -u 修改用户UID 不要被这么多参数吓坏啦~先来看下某个帐户的默认信息：[root@caijy Desktop]# id caijyuid=1000(caijy) gid=1000(caijy) groups=1000(caijy),10(wheel)接下来学习如何为用户增添到一个额外的扩展用户组中，以及修改该用户的身份号码：[root@caijy Desktop]# usermod -G root linuxprobe[root@caijy Desktop]# id linuxprobeuid=8888(linuxprobe) gid=8888(linuxprobe) groups=8888(linuxprobe) 0(root)[root@caijy Desktop]# usermod -u 8889 linuxprobe[root@caijy Desktop]# id linuxprobeuid=8889(linuxprobe) gid=8888(linuxprobe) groups=8888(linuxprobe),0(root) passwd命令用于修改用户的密码，格式为：“passwd [选项] [用户名]”。该命令用于修改用户的密码，，过期时间，认证信息等，普通的用户只有权限修改自身的系统密码，而超级用户则有权限来修改其它所有人的密码。更酷的是Linux系统中root管理员修改自己或他人的密码是不需要验证旧密码的，这点特别的方便。既然root用户都有权限修改或登录了该用户，就代表已经对该用户有完全的管理权限了，因此尝试修改该用户密码时不再重复要求验证旧密码其实也并不存在安全隐患： 参数 作用 -l 锁定用户禁止其登录 -u 解除锁定，允许用户登录 –stdin 允许从标准输入修改用户密码，如(echo “NewPassWord” &#124; passwd –stdin Username) -d 使账号无密码 -e 强制用户下次登陆时修改密码 -S 显示用户的密码状态 接下来学习如何修改用户自己的密码，以及如何修改其他人的密码（该动作仅限root管理员用户可使用）：[root@caijy Desktop]# passwdChanging password for user root.New password:BAD PASSWORD: The password is shorter than 8 charactersRetype new password:passwd: all authentication tokens updated successfully.[root@caijy Desktop]# passwd linuxprobeChanging password for user linuxprobe.New password:BAD PASSWORD: The password is shorter than 8 charactersRetype new password:passwd: all authentication tokens updated successfully.当有个同事请了长假时，还可以用这个命令来禁止或允许某个用户登录到本系统，而不是删除该用户，这样既保证了这段时间内系统的安全，也避免频繁添加、删除用户带来的麻烦：[root@caijy Desktop]# passwd -l linuxprobeLocking password for user linuxprobe.passwd: Success[root@caijy Desktop]# passwd -S linuxprobelinuxprobe LK 2017-09-15 0 99999 7 -1 (Password locked.)[root@caijy Desktop]# passwd -u linuxprobeUnlocking password for user linuxprobe.passwd: Success[root@caijy Desktop]# passwd -S linuxprobelinuxprobe PS 2017-09-15 0 99999 7 -1 (Password set, SHA512 crypt.) userdel命令用于删除用户，格式为：“userdel [选项] 用户名”。如果咱们确认以后不需要再让某个用户登录到本地系统中，则可以通过userdel命令来删除有关该用户的所有信息，默认该用户的家目录数据会被保留下来，而如果想要一起删除的话可以加上 -r 参数即可：[root@caijy Desktop]# id linuxprobeuid=8889(linuxprobe) gid=8888(linuxprobe) groups=8888(linuxprobe),0(root)[root@caijy Desktop]# userdel -r linuxprobe[root@caijy Desktop]# id linuxprobeid: linuxprobe: no such user 文件权限与归属Linux系统中一切都是文件，但每个文件的类型不尽相同，并且Linux系统会用不同的符号进行区分，常见的包括有： -:普通文件, d:目录文件, l:链接文件, b:块设备文件, c:字符设备文件, p:管道文件每个文件都有其相对应的所有者和所有组，还有分别规定对所有者、所有组和其他人的可读、可写、可执行的权限。对于一般文件来讲的权限比较好理解，可读权限就是能够读取该文件的实际内容，可写权限就是能够编辑、新增、修改文件的实际内容，可执行则代表能够运行一个脚本程序的权限。但对于目录文件的权限设置就不太好掌握了，首先对于目录文件的可读权限就是能够读取该目录内的结构和文件列表，可写权限就是能够更改目录内文件结构列表，新增，删除，重命名文件，而可执行的实质是代表进入该目录的权限。 读(read)，写(write)，执行（execute）简写即为 (r,w,x)，亦可用数字 (4,2,1) 表示，如下表：数字法是基于rwx的权限计算而来，主要是为了简化权限的表示信息。举例来说若某个文件的权限为7则代表可读，可写，可执行(4+2+1)，若权限为6则代表可读，可写(4+2)。因此例如说一个文件可以让所有者可读可写也可执行，对于文件的所属组来讲可读可写，而除了所有者和所有组以外的其他人则只有可读的权限，那么权限就是rwxrw-r–，数字法表示即为764，不过千万别算出来7+6+4=17，这是小学的数学加减法，不是Linux系统的权限数字法，三组之间没有相通关系。 下面一起分析下图的文件信息：图中所示包括有文件的类型、访问权限、所属者（属主）、所有组（属组）、占用大小、修改时间和文件名称等信息。通过分析可得知该文件类型为一般文件，所有者权限为可读可写（rw-），所有组权限为可读（r–），除此以外的其他人也只有可读权限（r–），文件的磁盘占用大小是34298字节，最近一次的修改时间为4月2日的凌晨23分，文件的名称为install.log。 文件的特殊权限在复杂多变的生产环境中，单纯对文件设置rwx权限肯定不能满足咱们对安全、便捷工作的需求，因此便有了SUID、SGID与SBIT的特殊权限机制。特殊权限位是针对于文件设置的一种特殊的功能，而且与一般权限可同时出现使用，用于弥补一般权限不能实现的功能。SUID:让执行者临时拥有属主的权限（仅对拥有执行权限的二进制程序有效）考虑下面一种情形，我们知道在Linux系统中，所有的账号密码都记录在/etc/shadow这个文件中，这个文件的权限为———- 1 root root，也就是说只有root用户才能修改这个文件，但是我们一般账号可使用passwd命令来修改密码，从而修改这个文件，这是怎么做到呢？答案就是SUID。该权限仅在执行该程序的过程中（run-time）有效[root@caijy Desktop]# ls -l /etc/shadow----------. 1 root root 1891 Sep 15 11:12 /etc/shadow[root@caijy Desktop]# ls -l /bin/passwd-rwsr-xr-x. 1 root root 27832 Jan 30 2014 /bin/passwd SGID功能一：让执行者临时拥有属组的权限（对拥有执行权限的二进制程序设置）这种特殊权限就是参考SUID而设计的，不同点就是让程序的执行者获取的不再是文件所有者的临时权限，而是获取到文件的所有组的权限。举例来说，在早期的Linux系统中/dev/kmem是一个字符设备文件，用于存储内核程序要访问的数据，权限为： cr–r—– 1 root system 2, 1 Feb 11 2017 kmem 也就是除了root超级用户身份或属于system组成员外的所有用户都没有读取该文件的权限，但平时咱们需要查看系统进程状态，为了让用户能够获取到系统状态信息，因此将用于查看系统进程状态的ps命令权限上增加了SGID特殊权限位： -r-xr-sr-x 1 bin system 59346 Feb 11 2017 ps 这样的话因为ps命令被赋予了SGID特殊权限位，所以当用户执行了该命令，实际上临时获取到了有效用户组system的权限啦，能够顺利的读取设备文件啦~ SGID功能二：在该目录中创建的文件自动继承此目录的用户组（只可以对目录设置）正如前面提到过每个文件都有其归属的所有者和所有组，而当创建或传送一个文件后，这个文件就会自动的归属于执行这个操作的用户。那么比如工作中需要设置一个部门内的共享目录，让所有组内的人都能够读取里面的内容，那么咱们就可以创建部门共享目录后，把该目录设置上SGID特殊权限位，这样任何用户在里面创建的任何文件都会归属于本目录的所有组，而不再是自己的基本用户组。[root@caijy ~]# cd /tmp[root@caijy tmp]# mkdir testdir[root@caijy tmp]# ls -ald testdir/drwxr-xr-x. 2 root root 6 Sep 15 15:04 testdir/[root@caijy tmp]# chmod -Rf 777 testdir/[root@caijy tmp]# chmod -Rf g+s testdir/[root@caijy tmp]# ls -ald testdir/drwxrwsrwx. 2 root root 6 Sep 15 15:04 testdir/这样设置好777权限以保证普通用户可以写入文件，并为该目录设置了SGID特殊权限位后，就可以切换至一个普通用户尝试在该目录创建文件，看看新建出来的文件是否会继承上级目录的所有组名称：[root@caijy tmp]# su - caijyLast login: Fri Sep 15 10:30:27 CST 2017 on :0[caijy@caijy ~]$ cd /tmp/testdir[caijy@caijy testdir]$ echo &quot;linux&quot; &gt; test[caijy@caijy testdir]$ ls -al test-rw-rw-r--. 1 caijy root 6 Sep 15 15:11 test chmod命令用于修改文件或目录的权限，格式为：”chmod [参数] 权限 文件或目录名称”。这是一个非常实用的命令，能够用来设置文件或目录的权限，例如想要把一个文件的权限设置成所有者都可以可读写执行、所有组可读写而其他人没有任何权限，这样对应起来就是rwxrw—-，用数字法来设置也就是760啦，于是通过前面的基础学习到当前实践操作，同学们马上就能感受到了数字法设置权限的便捷性了吧~[root@caijy ~]# cd /tmp/testdir[root@caijy testdir]# ls -al test-rw-rw-r--. 1 caijy root 6 Sep 15 15:11 test[root@caijy testdir]# chmod 760 test[root@caijy testdir]# ls -al test-rwxrw----. 1 caijy root 6 Sep 15 15:11 test chown命令用于修改文件或目录的所属主与所属组，格式为：“chown [参数] 所属主:所属组 文件或目录名称”。除了修改文件的权限外，还可以使用chown命令来设置文件的所有者和所有组。chmod和chown命令是对文件属性和权限修改最常用的命令，它们还有一个特别的共性，就是对于目录文件时需要加上大写参数-R来表示递归操作，即对目录内所有的文件进行整体操作的意思。[root@caijy testdir]# ls -l test-rwxrw----. 1 caijy root 6 Sep 15 15:11 test[root@caijy testdir]# chown root:bin test[root@caijy testdir]# ls -l test-rwxrw----. 1 root bin 6 Sep 15 15:11 test SBIT(Sticky Bit):只可管理自己的数据而不能删除他人文件(仅对目录有效)SBIT特殊权限位的设置目的和效果是不让其他人删除自己的文件，换句话说就是文件只能被所有者执行删除操作。在RHEL7系统中的/tmp作为一个共享文件的目录默认已经被设置了SBIT特殊权限位，因此这里面的文件其他人是不能乱删除的：[andy@caijy tmp]$ su - caijyPassword:Last login: Fri Sep 15 15:25:26 CST 2017 on pts/0[caijy@caijy ~]$ ls -ald /tmpdrwxrwxrwt. 16 root root 4096 Sep 15 15:30 /tmp[caijy@caijy ~]$ cd /tmp[caijy@caijy tmp]$ ls -alddrwxrwxrwt. 16 root root 4096 Sep 15 15:30 .[caijy@caijy tmp]$ echo &quot;Welcome to linux&quot; &gt; test[caijy@caijy tmp]$ chmod 777 test[caijy@caijy tmp]$ ls -ald test-rwxrwxrwx. 1 caijy caijy 17 Sep 15 15:31 test其实文件能否被删除并不取决于自身的权限大小，而是看上级目录是否有写入权限，这个是前面提到过的，但为了避免很多同学不放心，所以还是赋予了这个文件最大的777权限(rwxrwxrwx)。切换到另外一个普通用户然后尝试删除这个别人的文件就会发现，即便权限十分的充足，但是由于SBIT特殊权限位的缘故依然导致了无法删除其他人的文件：[caijy@caijy tmp]$ su - andyPassword:Last login: Fri Sep 15 15:29:12 CST 2017 on pts/0[andy@caijy ~]$ cd /tmp[andy@caijy tmp]$ rm -f testrm: cannot remove ‘test’: Operation not permitted 文件的隐藏属性在Linux系统中除了能对文件设置一般权限和特殊权限外还有一种叫做隐藏权限的功能，顾名思义就是被隐藏起来的权限，即在默认情况下是不能直接被用户发觉的。在真实的工作环境和红帽RHCE考试题目中碰到过明明权限很充足但却不能删除某个文件的情况，或者仅仅能对日志文件进行追加内容而不能删除或减少，一定程度上阻止了黑客篡改系统日志的图谋，因此这种很“奇怪”的文件让Linux系统更加的安全。 chattr命令用于设置文件的隐藏权限，格式为：“chattr [参数] 文件”。可以使用chattr命令来设置文件的隐藏权限，如果想要把某个隐藏功能添加到文件上面，则使用 +参数，如果想要把某个隐藏功能移出文件，则使用 -参数。可供咱们选择的隐藏权限功能非常丰富，常见的隐藏权限包括有： 参数 作用 i 将无法对文件进行修改,若对目录设置后则仅能修改子文件而不能新建或删除。 a 仅允许补充（追加）内容.无法覆盖/删除(Append Only)。 S 文件内容变更后立即同步到硬盘(sync)。 s 彻底从硬盘中删除，不可恢复(用0填充原文件所在硬盘区域)。 A 不再修改这个文件的最后访问时间（atime） b 不再修改这个文件的存取时间 D 检查压缩文件中的错误 d 当使用“dump”命令备份时忽略本文件/目录 c 默认将文件或目录进行压缩 u 当删除此文件后依然保留其在硬盘中的数据，以便日后恢复 t 让文件系统支持尾部合并（tail-merging） X 直接访问压缩文件中的内容 为了能更好的见识到隐藏权限的效果，先来创建一个普通文件后立即尝试删除，这个肯定是毫无悬念会成功的：[root@caijy ~]# echo &quot;for test&quot; &gt; test[root@caijy ~]# rm testrm: remove regular file ‘test’? y实践是检验真理的唯一标准，如果没有亲眼见见隐藏权限强大功能的美妙，就一定不会相信原来Linux系统会如此的安全且复杂。当咱们再次新建了一个普通文件并设置了不允许删除与覆盖(+a参数)权限后的效果：[root@caijy ~]# echo &quot;for test&quot; &gt; test[root@caijy ~]# chattr +a test[root@caijy ~]# rm testrm: remove regular file ‘test’? yrm: cannot remove ‘test’: Operation not permitted lsattr命令用于显示文件的隐藏权限，格式为：“lsattr [参数] 文件”。对于Linux系统中的隐藏权限必须用lsattr命令才能够看到，平时使用的ls之类的命令是看不出异样的：[root@caijy ~]# ls -al test-rw-r--r--. 1 root root 9 Sep 15 15:50 test一旦使用了lsattr命令后文件上被赋予的隐藏权限就会马上原形毕露出来，只需要按照提示的隐藏权限的类型（字母）来使用chattr命令去掉即可：[root@caijy ~]# lsattr test-----a---------- test[root@caijy ~]# chattr -a test[root@caijy ~]# lsattr test---------------- test[root@caijy ~]# rm testrm: remove regular file ‘test’? y 文件访问控制列表不知大家有没有发现其实上面讲到的一般权限、特殊权限、隐藏权限其实有个共性——权限是针对某一类用户设置的。而如果希望对某个指定的用户进行单独的权限控制，那么就需要用文件的访问控制列表来实现啦。基于普通文件或目录设置ACL访问控制策略，通俗来说就是设置指定的特定用户或用户组对某个文件的操作权限，另外如果对某个目录设置了访问控制策略，那么子文件则继承其访问策略，而若对文件设置了访问控制策略则不再继承上级目录的控制策略。 为了更直观的看到ACL访问控制列表对文件权限控制的强大效果，因此先切换到普通用户后尝试进入到root超级用户的家目录中：[root@caijy ~]# su - caijyLast login: Fri Sep 15 15:30:25 CST 2017 on pts/0[caijy@caijy ~]$ cd /root-bash: cd: /root: Permission denied[caijy@caijy ~]$ exitACL提供的是在所有者，所有组，其它人的读写执行权限外的特殊权限控制，使用setfacl命令可以让咱们能够针对单一用户或用户组，单一文件或目录来进行读写执行权限的控制，其中对于目录文件需要用到递归-R参数，对普通文件需要用到-m参数，而如果想要删除某个文件的访问控制策略的话可以使用-b参数，于是快来设置下用户在/root目录上面的权限吧：[root@caijy ~]# setfacl -Rm u:caijy:wrx /root[root@caijy ~]# su - caijyLast login: Fri Sep 15 16:05:49 CST 2017 on pts/0[caijy@caijy ~]$ cd /root[caijy@caijy root]$ lsanaconda-ks.cfg initial-setup-ks.cfg[caijy@caijy root]$ cat anaconda-ks.cfg#version=RHEL7# System authorization informationauth --enableshadow --passalgo=sha512...... 是不是觉得效果很酷呢？但是又遇到了一个小问题——怎么样去查看文件上面有那些ACL策略呢？常用的ls命令是看不到访问控制列表信息的，但是却可以看到文件的权限最后一个点(.)变成了加号（+）,而这就意味着这个文件已经被设置有了ACL访问策略啦。现在是不是感觉学得越多，越不敢说自己精通于Linux系统了呢？这么一个不起眼的点(.)竟然还意味着这么一种重要的权限呢。[caijy@caijy root]$ ls -ld /rootdr-xrwx---+ 5 root root 4096 Sep 15 15:53 /root getfacl命令用于显示文件的ACL规则，格式为：”getfacl 文件名称”。在Linux系统中的命令就是这么又可爱又好记，想要设置ACL访问策略的话就是setfacl命令，而查看ACL访问策略的话就是getfacl命令。使用getfacl命令能够显示出在文件上设置的所有访问策略规则信息。[caijy@caijy root]$ getfacl /rootgetfacl: Removing leading &#39;/&#39; from absolute path names# file: root# owner: root# group: rootuser::r-xuser:caijy:rwxgroup::r-xmask::rwxother::--- su命令与sudo服务使用su命令可以让使用者在不注销的情况下顺畅的切换至其他用户，例如从root超级用户切换至普通用户：[root@caijy ~]# iduid=0(root) gid=0(root) groups=0(root) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023[root@caijy ~]# su - caijyLast login: Fri Sep 15 16:14:54 CST 2017 on pts/0[caijy@caijy ~]$ iduid=1000(caijy) gid=1000(caijy) groups=1000(caijy),10(wheel) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023细心的同学一定会发现上面的su命令与用户名之间有一个减号(-)，这意味着完全的切换到新的用户，即把环境变量信息也变更为新的用户，而不保留原始的用户信息，这个是推荐必加的参数，一定要记下哦~另外当超级用户切换到普通用户时是不需要密码验证的，而普通用户切换成超级用户身份就需要密码验证后才能成功了，这是一个必要的安全检查：[caijy@caijy ~]$ su - rootPassword:Last login: Fri Sep 15 16:20:16 CST 2017 on pts/0[root@caijy ~]# su - caijyLast login: Fri Sep 15 16:20:27 CST 2017 on pts/0[caijy@caijy ~]$ exitlogout[root@caijy ~]#虽说像上面使用su命令允许普通用户完全变更为root用户身份来完成工作，但这也无疑会暴露了root超级管理员的密码，使得系统密码被黑客获取的几率也大大提高了，这似乎并不是最安全的方案。因此我们来学习使用sudo程序来把特定命令的执行权限赋予给指定的用户，这样既可保证了正常工作的同时也避免了泄露root超级用户密码，平时只要合理的配置sudo服务便可以合理的兼顾系统的安全性和用户便捷性，配置的原则也很简单—— 在保证普通用户完成工作的前提下，尽可能少的给予额外的权限，总结来说sudo服务程序的特色功能有： 限制用户执行指定的命令。 记录用户执行的每一条命令。 配置文件（/etc/sudoers）提供集中的管理用户、权限与主机等参数。 验证过密码后5分钟(默认值)内无须再让用户验证密码，更加的方便。 sudo服务用于给普通用户提供额外权利来完成原本超级用户才能完成的任务，格式为：“sudo [参数] 命令名称”。 参数 作用 -h 列出帮助信息 -l 列出当前用户可执行的命令 -u 用户名或UID值 以指定的用户身份执行命令 -k 清空安全时间，下次执行sudo时需要再次验证密码 -b 在后台执行指定的命令 -p 更改询问密码的提示语 当然如果感觉直接修改配置文件不太放心，担心出现问题的话还可以使用sudo服务提供的visudo命令来配置用户权限，这条命令在配置用户权限时可以避免多个用户同时修改配置文件，以及对配置文件内的参数进行语法检查，在发现错误参数时会直接提示并报错。 只用超级用户才可以使用visudo命令编辑sudo程序的配置文件（/etc/sudoers），平时还可以使用visudo命令来配置用户权限吧，这样既能防止多个用户同时修改配置文件，还能对配置文件内的参数进行语法检查，对于错误的参数会直接提示并报错：visudo: &gt;&gt;&gt; /etc/sudoers: syntax error near line 111 &lt;&lt;&lt;What now?Options are:(e)dit sudoers file again(x)it without saving changes to sudoers file(Q)uit and save changes to sudoers file (DANGER!) 使用visudo命令配置sudo服务的服务文件时，操作的方法与咱们学习过的vim编辑器是一致的，因此在编写完成后记得在末行模式下保存并退出。sudo服务程序配置文件中约第99行按照下面的格式填写上指定的信息即可： 谁可以使用超级用户身份 允许使用sudo命令的主机=（以谁的身份执行命令） 可执行命令的列表 [root@caijy ~]# visudo## Allow root to run any commands anywhereroot ALL=(ALL) ALLcaijy ALL=(ALL) ALL 这样填写后记得要保存后再退出，然后切换至指定的用户身份就可以用sudo -l命令查看到所有可执行的命令啦（此处验证的是该普通用户的密码，而不是root用户的密码，同学们不要搞混喽）：[root@caijy ~]# su - caijyLast login: Fri Sep 15 16:22:01 CST 2017 on pts/0[caijy@caijy ~]$ sudo -l[sudo] password for caijy:Matching Defaults entries for caijy on this host:requiretty, !visiblepw, always_set_home, env_reset, env_keep=&quot;COLORSDISPLAY HOSTNAME HISTSIZE INPUTRC KDEDIR LS_COLORS&quot;, env_keep+=&quot;MAIL PS1PS2 QTDIR USERNAME LANG LC_ADDRESS LC_CTYPE&quot;, env_keep+=&quot;LC_COLLATELC_IDENTIFICATION LC_MEASUREMENT LC_MESSAGES&quot;,env_keep+=&quot;LC_MONETARYLC_NAME LC_NUMERIC LC_PAPER LC_TELEPHONE&quot;, env_keep+=&quot;LC_TIME LC_ALLLANGUAGE LINGUAS _XKB_CHARSET XAUTHORITY&quot;,secure_path=/sbin\:/bin\:/usr/sbin\:/usr/binUser caijy may run the following commands on this host:(ALL) ALL(ALL) ALL接下来就是见证奇迹的时刻，因为作为一名普通用户是肯定不能查看到root超级用户家目录(/root)中的文件信息的，但咱们只需要在想执行的命令前面加上sudo命令就变得有权限了：[caijy@caijy root]$ ls /rootls: cannot open directory /root: Permission denied[caijy@caijy root]$ sudo ls /root[sudo] password for caijy:anaconda-ks.cfg initial-setup-ks.cfg效果非常明显哦！但是考虑到真实的工作环境中肯定不能允许某个普通用户拥有了整个系统中所有命令的最高执行权，也不符合刚刚提到的权限赋予原则——在保证普通用户完成工作的前提下，尽可能少的给予额外的权限，因此ALL的参数就显得有些不合适了，应该代之以具体的命令来既让用户满足了工作需求，也能够受到必要的权限约束。如果需要让某个用户只能使用超级用户的身份执行指定的命令，切记一定要写上的是该命令的绝对路径，否则系统会识别不出来哦，咱们可以先用whereis命令找出命令所对应的保存路径，然后把刚刚配置文件中约第99行的用户权限参数修改成对应的路径即可：[root@caijy ~]# whereis catcat: /usr/bin/cat /usr/share/man/man1/cat.1.gz /usr/share/man/man1p/cat.1p.gz[root@caijy ~]# visudo## Allow root to run any commands anywhereroot ALL=(ALL) ALLcaijy ALL=(ALL) /bin/cat这样编辑好后依然是记得要保存退出，然后咱们再次切换到指定的普通用户上面，尝试正常查看某个文件的内容被提示没有权限，然后再用sudo命令后就可以顺利的查看文件内容啦：[root@caijy ~]# su - caijyLast login: Fri Sep 15 16:46:38 CST 2017 on pts/0[caijy@caijy ~]$ cat /etc/shadowcat: /etc/shadow: Permission denied[caijy@caijy ~]$ sudo cat /etc/shadow[sudo] password for caijy:root:$6$dVUdyi82$u11lUZwsCwYv92m92nCjP9My1dT.QH.j463.MUeREj5C6pkOmNpY2ugpg5pGJ2kXrphOC7qFViD8mrfvZs.9W/:17424:0:99999:7:::bin:*:16141:0:99999:7:::......这样当咱们切换到普通用户后再执行命令时，就不用再频繁麻烦的要求验证密码了，在日常工作会一定会感觉到痛快极了~ 转载自：http://www.linuxprobe.com/chapter-05.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础课程04]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F14%2FLinux%E5%9F%BA%E7%A1%80%E8%AF%BE%E7%A8%8B04%2F</url>
    <content type="text"><![CDATA[首先来学习如何使用vim编辑器来编写、修改文档，然后通过逐个配置主机名称、系统网卡以及Yum仓库参数文件等实验来加深对vim编辑器中诸多命令、快捷键的执行方法与各个模式切换的方法。然后把前面的Linux命令、命令语法与Shell脚本中的if条件测试语句、for条件测试循环语句、while条件循环语句以及case条件测试语句通过vim编辑器写到Shell脚本中结合到一起，实现最终能够自动化工作的软件脚本工具。最后为读者们演示了怎样通过at命令与crond计划任务服务来分别实现一次性与长期性的系统任务设置方法，让日常的工作更加高效自动化，一劳永逸。 Vim文本编辑器“Linux系统中一切都是文件，而配置一个服务就是在修改其配置文件的参数”。而且在日常工作中也一定免不了遇到编写文档的事情吧，这些都是要通过文本编辑器来完成的，咱们选择学习vim这个当前整个linux操作系统中都会默认安装好的一款超棒文本编辑器，学会后绝对会能让您“通吃”当前主流的系统。Vim能够得到广大厂商与众多用户的认可，原因就是在Vim编辑器中内设有的三种模式——命令模式、末行模式 和 编辑模式，每种模式分别又支持多种不同的命令快捷键组合，大大的提高了工作效率，用习惯后会觉得非常的顺手。而要想在文本操作时更加高效率，就必须先搞清Vim编辑器的三种模式的操作不同与切换方法： 命令模式：控制光标移动，可对文本进行删除、复制、粘贴和查找等工作。 输入模式：正常的文本录入。 末行模式：保存、退出与设置编辑环境。 每次运行vim编辑器后都默认会是 “命令模式”，需要先进入到 “输入模式” 后再进行编写文档的工作，而每次编辑完成需先返回到 “命令模式” 后再进入 “末行模式” 中执行对文本的保存或退出操作，并不能直接从 “输入模式” 切换到 “末行模式” 。vim编辑器内设支持的命令有成百上千种用法，为了能够帮助读者更快的掌握vim编辑器，刘遄老师分别总结了在 命令模式 和 末行模式 中最常用的一些快捷键命令，如下表所示： 命令 作用 dd 删除（剪切）光标所在整行。 5dd 删除(剪切)从光标处开始的5行。 yy 复制光标所在整行 5yy 复制从光标处开始的5行。 n 显示搜索命令定位到的下一个字符串 N 显示搜索命令定位到的上一个字符串 u 撤销上一步操作 p 将之前删除（dd）或复制（yy）过的数据粘贴到光标后。 /字符串 在文本中从上至下搜索该字符串。 ?字符串 在文本中从下至上搜索该字符串。 末行模式主要用于保存或退出文件，能够设置vim编辑器的整体使用环境，还可以让用户执行外部Linux命令或跳转到特定的行数，切换到末行模式的方式就是在命令模式中输入一个冒号就可以的，末行模式中可用的命令如下表： 命令 作用 :w 保存 :q 推出 :q! 强制推出 :wq! 强制保存退出 :set nu 设置行号 :set nonu 不显示行号 :命令 执行该命令 :整数 跳转到该行 :s/one/two 将当前光标所在行的第一个one替换成two :s/one/two/g 将当前光标所在行的所有one替换成two :%s/one/two/g 将全文中的所有one替换成two 编写简单文档现在就让咱们一起动手编写个简单的文档吧，编写脚本的第1步就是给文件取个名字，如果文档的名称存在则打开它，如果不存在则是创建一个临时的输入文件。[root@localhost workdir]# vim practice.txt进入文件后默认看到的是vim编辑器的命令模式，这时只能够执行命令快捷键而不能随意输入文本内容，必须切换到输入模式才可以开始编写工作。有些读者应该能够猜出a、i、o三键的区别了吧，对，就是光标的位置不同！a键与i键分别是在光标右一位和光标当前位置切换到输入模式，而o键则是在光标的下面再创建一个空行，此时可敲击a键进入到编辑器的输入模式，输入模式是可以随意输入文本内容的，更不会把您输入的文本内容当作命令而执行:如果想要保存并退出这个文本文件，必须先从 输入模式 返回到 命令模式，然后切换至 末行模式 中才能完成保存退出操作。当咱们在末行模式中键入:wq!时就意味着强制保存并退出文件，然后便可以用cat命令查看到保存文件后的信息了[root@localhost workdir]# cat practice.txtYou can write in it. 感觉是不是很简单，咱们接下来继续编辑这个文件，因为要在原有文本的内容下面追加内容，所以在命令模式中敲击o键的话会更高效呢.现在是不是感觉对vim编辑器有了一些实战经验呢，也不是想象中的那么难吧~现在咱们查看下文本的内容会发现果然后面一次输入的内容并没有被保存下来:[root@localhost workdir]# cat practice.txtYou can write in it. 配置主机名称为了便于在局域网中指定查找某个用户的电脑或区别主机的作用，除了要有IP地址外还要配置一个主机名，用户之间可以通过这个类似于域名的名称来便捷的相互访问。绝大部分的Linux系统主机名都是保存在/etc/hostname文件中的，咱们要想将其内容修改为”linuxprobe.com”，思路大致如下： 使用vim编辑器修改”/etc/hostname”主机名称文件。 把原始主机名称删除后追加”linuxprobe.com”。 保存退出文档并用hostname命令检查是否修改成功。 使用hostname命令查看当前的主机名称，但有时系统不能立即同步到主机名称已经发生改变，所以如果您确认修改完成却还显示原来的主机名称，可重启虚拟机后再查看下：[root@localhost workdir]# hostnamecaijy.com 配置网卡信息能够正确的配置网卡IP地址是保证两台服务器互相通信的前提，而Linux系统中的一切都是文件，配置网络的工作其实就是在编辑网卡配置文件，因此这个小任务不仅是帮助您熟练操作vim编辑器的过程，还是在为以后学习各种服务课程打下深深的基础。 在红帽RHEL7系统中的网卡配置文件前缀则以 “ifcfg-eno” 开始的,例如现在要想配置一个名称为eno16777736的网卡设备开机自启动并且IP地址、子网、网关等信息由人工指定的话思路应该是： 首先要切换到”/etc/sysconfig/network-scripts”目录中（该目录存放着网卡的配置文件）。 使用vim编辑器修改网卡文件”ifcfg-eno16777736”，逐项写入配置参数并保存退出，因每台电脑的硬件及架构情况都是不一样的，同学们的网卡默认名称请通过ifconfig命令自行确认。 设备类型:TYPE=Ethernet 地址分配模式:BOOTPROTO=static 网卡名称:NAME=eno16777736 是否启动:ONBOOT=yes IP地址:IPADDR=192.168.10.10 子网掩码:NETMASK=255.255.255.0 网关地址:GATEWAY=192.168.10.1 DNS地址:DNS1=192.168.10.1 重启网卡设备并测试网络是否联通。 进入到网卡配置文件所在的目录，然后编辑网卡配置文件填入下面的信息：执行重启网卡设备的命令，正常情况不会有提示信息，然后通过ping命令测试网络能否联通。[root@localhost network-scripts]# systemctl restart network[root@localhost network-scripts]# ping 192.168.10.10PING 192.168.10.10 (192.168.10.10) 56(84) bytes of data.64 bytes from 192.168.10.10: icmp_seq=1 ttl=64 time=0.029 ms64 bytes from 192.168.10.10: icmp_seq=2 ttl=64 time=0.032 ms64 bytes from 192.168.10.10: icmp_seq=3 ttl=64 time=0.032 ms64 bytes from 192.168.10.10: icmp_seq=4 ttl=64 time=0.040 ms64 bytes from 192.168.10.10: icmp_seq=5 ttl=64 time=0.066 ms64 bytes from 192.168.10.10: icmp_seq=6 ttl=64 time=0.031 ms^C--- 192.168.10.10 ping statistics ---6 packets transmitted, 6 received, 0% packet loss, time 5002msrtt min/avg/max/mdev = 0.029/0.038/0.066/0.013 ms 配置Yum仓库前面了解过Yum软件仓库的作用是为了进一步简化RPM管理软件难度以及自动分析所需软件包及其依赖关系的技术。您可以把Yum想象成是一个硕大的软件仓库，里面保存有几乎所有常用的工具，而只需要说出所需的软件包名称，系统就会自动的为您搞定一切。那么既然要使用Yum技术，就要先把软件仓库搭建起来，然后将其配置规则确定好才行 首先要进入到”/etc/yum.repos.d/“目录中（因为该目录存放着yum仓库的配置文件） 使用vim编辑器创建一个名为rhel7.repo的新配置文件（文件名称可随意，但后缀必须为repo），逐项写入下面加粗的配置参数并保存退出（不写中文注释）。 [rhel-media] yum仓库唯一标识符，避免与其他仓库冲突。 name=linuxprobe yum仓库的名称描述，易于识别仓库用处。。 baseurl=file:///media/cdrom 提供方式包括FTP（ftp://..）、HTTP（http://..）、本地（file:///..） enabled=1 设置此源是否可用，1为可用，0为禁用。 gpgcheck=1 设置此源是否校验文件，1为校验，0为不校验。 gpgkey=file:///media/cdrom/RPM-GPG-KEY-redhat-release 若为校验请指定公钥文件地址。 按配置参数的路径把光盘挂载，并把光盘挂载信息写入到/etc/fstab文件中。 使用”yum install httpd -y”命令检查Yum仓库是否已经可用。 进入到/etc/yum.repos.d目录中后创建Yum配置文件：[root@localhost network-scripts]# cd /etc/yum.repos.d/[root@localhost yum.repos.d]# vim rehl17.repo[rhel7]name=rhel7baseurl=file:///media/cdromenabled=1gpgcheck=0 创建挂载点后进行挂载操作，并设置成开机自动挂载[root@localhost yum.repos.d]# mkdir -p /media/cdrom[root@localhost yum.repos.d]# mount /dev/cdrom /media/cdrommount: /dev/sr0 is write-protected, mounting read-only[root@localhost yum.repos.d]# vim /etc/fstab/dev/cdrom /media/cdrom iso9660 defaults 0 0 尝试使用Yum软件仓库来安装Web服务，出现Complete（完成）则代表Yum仓库配置正确：[root@localhost yum.repos.d]# yum install httpdLoaded plugins: langpacks, product-id, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.......Complete! 编写Shell脚本Shell终端解释器被形容是人与计算机硬件的“翻译官”，它作为用户与Linux系统内部通讯的媒介，除了允许了各种变量与参数外还提供了诸如循环、分支等高级语言才有的控制结构特性，如何正确的使用这些功能，准确下达命令尤为重要。Shell脚本的工作方式有两种，首先是前面所接触的交互方式(Interactive)，即当用户每输入一条命令就执行一次，而批处理(Batch)则是由用户事先编写好一个完整的Shell脚本，Shell会一次性执行脚本中诸多的命令。因此在Shell脚本中不仅需要用到很多前面学习过的Linux命令以及正则表达式、管道符、数据流重定向等语法规则，还需要把内部功能模块化后通过逻辑语句进行加工，最终才能成为日常所见的Shell脚本程序，可以通过SHELL变量来查看到当前系统已经默认使用bash解释器作为命令行终端了：[root@localhost Desktop]# echo $SHELL/bin/bash 编写简单的脚本估计读者看完上面对Shell脚本如此复杂的描述都有一种心累想放弃的感觉了吧，但这仅指的是一个高深Shell脚本的编写原则，其实使用vim编辑器把linux命令按照顺序依次写入文件就是编写完成一个最简单的脚本啦。例如想查看当前所在工作路径并列出当前目录下所有文件及属性信息，编写一个脚本来完成的话是这样：[root@localhost Desktop]# vim example.sh#! /bin/bash#For Examplepwdls -alShell脚本文件的名称是可以任意起，但咱们应该遵守运维行业人员大众的规范把.sh后缀写上，这样让其他人一看就知道是个脚本文件，与人方便自己方便。在这个脚本中实际上出现了三种不同的元素，第一行脚本声明(#!)是用来告知系统用何种shell解释器来执行本脚本程序，第二行注释信息(#)是对程序功能和某些命令的介绍信息，使得自己或他人再次看到这个脚本内容时可以快速知道这些功能的作用或一些警告信息，第三、四行可执行语句也就是咱们平时执行的Linux命令啦~什么？同学们不相信这么简单就编写出来了一个脚本程序，那来执行看一看吧：[root@localhost Desktop]# bash example.sh/home/caijy/Desktoptotal 4848drwxr-xr-x. 4 caijy caijy 93 Sep 14 16:29 .drwx------. 14 caijy caijy 4096 Sep 14 11:05 ..drwxrwxr-x. 3 caijy caijy 20 Sep 14 12:34 c-rw-rw-r--. 1 caijy caijy 4946304 Sep 13 20:29 etc.tar.gz-rw-r--r--. 1 root root 38 Sep 14 16:28 example.sh-rw-rw-r--. 1 caijy caijy 0 Sep 13 20:21 linux.logdrwxrwxr-x. 2 caijy caijy 4096 Sep 13 21:06 mydir-rw-rw-r--. 1 caijy caijy 50 Sep 14 10:31 readme.txt第二种运行脚本程序的方法是以输入完整路径的方式来执行，但默认会因为权限不足而提示报错信息，这种情况只需要为脚本文件增加执行权限即可:[root@localhost Desktop]# ./example.shbash: ./example.sh: Permission denied[root@localhost Desktop]# chmod u+x example.sh[root@localhost Desktop]# bash example.sh/home/caijy/Desktoptotal 4848drwxr-xr-x. 4 caijy caijy 93 Sep 14 16:29 .drwx------. 14 caijy caijy 4096 Sep 14 11:05 ..drwxrwxr-x. 3 caijy caijy 20 Sep 14 12:34 c-rw-rw-r--. 1 caijy caijy 4946304 Sep 13 20:29 etc.tar.gz-rw-r--r--. 1 root root 38 Sep 14 16:28 example.sh-rw-rw-r--. 1 caijy caijy 0 Sep 13 20:21 linux.logdrwxrwxr-x. 2 caijy caijy 4096 Sep 13 21:06 mydir-rw-rw-r--. 1 caijy caijy 50 Sep 14 10:31 readme.txt 接收用户的参数但是像上面这样的脚本程序在功能上真的太过于“死板”，为了能够让Shell脚本程序更好的满足用户对灵活完成工作的热切需要，必须要让脚本程序能够像咱们以前执行命令时那样来接收用户输入进来的参数。 其实Shell脚本早就考虑到了这些，已经在脚本中定义好了很多变量功能，例如$0对应当前Shell脚本程序的名称，$#对应总共有几个参数，$*对应所有位置的参数值，而$1,$2,$3……依次类推则分别对应着第N个位置的参数:尝试来编写一个测试用的脚本程序，通过引用上面的变量参数来看下真实效果：[root@localhost Desktop]# vim example.sh#! /bin/bashecho &quot;当前脚本名称为$0.&quot;echo &quot;总共有$#个参数，分别是$*.&quot;echo &quot;第1个参数为$1,第5个为$5.&quot;[root@localhost Desktop]# bash example.sh one two three four five当前脚本名称为example.sh.总共有5个参数，分别是one two three four five.第1个参数为one,第5个为five. 判断用户的参数学习就像是在登台阶，在您学习完执行linux命令，掌握脚本语法变量和接收用户输入信息等方法后就要踏上新的高度——即能够进一步去处理接收到的用户的参数。因为有时咱们也需要像前面学习过的mkdir命令一样来判断用户输入的信息，从而判断用户指定的文件夹名称是否已经存在，已存在则提示报错，不存在则自动的创建。条件测试语法能够判断表达式是否成立，若条件成立则返回数字0，否则便返回其他随机数值。 条件判断语句按照测试对象可分为 文件测试、逻辑测试、整数值比较与字符串比较，文件测试即用来按照指定条件来判断文件是否存在或权限是否满足，具体的参数包括有： 操作符 作用 -d 测试是否为目录 -e 测试文件或目录是否存在 -f 判断是否为文件 -r 测试当前用户是否有权限读取 -w 测试当前用户是否有权限写入 -x 测试当前用户是否有权限执行 好啦，那么先通过文件测试语句来判断/etc/fstab是否为一个目录文件，然后通过$?变量来显示上一条命令执行后的返回值，这样就可以通过返回的非零值判断目录是不存在的了（即文件测试语句判断结果不符合）：[root@localhost Desktop]# [ -d /etc/fstab ][root@localhost Desktop]# echo $?1再来用文件测试语句来判断下/etc/fstab是否为一般文件，这样看到返回值是0即代表这个一般文件是存在的：[root@localhost Desktop]# [ -f /etc/fstab ][root@localhost Desktop]# echo $?0逻辑测试则是用于判断用户给出的条件是为真还是假，从而把条件测试语句与逻辑语句相搭配结合使用可以实现一个更高级的使用方法，例如在Shell终端中逻辑“与”符号是&amp;&amp;，它代表当前面的命令执行成功后才会执行后面的命令，因此可以用来判断/dev/cdrom设备是否存在，若存在时才输出Exist字样。[root@localhost Desktop]# [ -e /dev/cdrom ] &amp;&amp; echo &quot;exist&quot;exist除了“与”逻辑测试符号外,还有逻辑“或”，“非”符号，在Linux系统中逻辑“非”的符号就是一个叹号，它代表把条件测试中的判断结果取相反值。 整数比较运算符是仅对数字的测试操作，不能把数字与字符串、文件等内容一起操作，而且不能想当然的使用日常生活中的等号、大于号、小于号等来做判断，因为等号与是赋值命令符冲突，大于号和小于号分别是和输出重定向命令符和输入重定向命令符冲突。虽然有时候碰巧也能执行成功，但是在后面脚本程序中普遍会产生错误，一定要使用规范的整数比较运算符来进行操作： 操作符 作用 -eq 判断是否等于 -ne 判断是否不等于 -gt 判断是否大于 -lt 判断是否小于 -le 判断是否等于或小于 -ge 判断是否大于或等于 咱们先小试牛刀的测试下10是否大于10以及10是否等于10，依次通过判断输出的返回值内容来进行判断：[root@caijy Desktop]# [ 10 -gt 10 ][root@caijy Desktop]# echo $?1[root@caijy Desktop]# [ 10 -eq 10 ][root@caijy Desktop]# echo $?0在前面第2章的第四小节中学习过一个叫做free的命令，它能够获取到当前系统正在使用及可用的内存量信息。接下来咱们先用free -m命令查看以兆为单位的内存使用量情况，然后通过grep Mem:命令对关键词匹配过滤出剩余内存量的行，再用awk ‘{print $4}’命令过滤只保留第三列，最后用FreeMem=`语句`的方式把语句内执行的结果赋值给变量，这个演示确实有些难度，但看懂后会觉得很有意思，写到笔记本上在运维工作时也会用得上。[root@caijy Desktop]# free -mtotal used free shared buffers cachedMem: 1826 867 959 9 0 278-/+ buffers/cache: 588 1238Swap: 2047 0 2047[root@caijy Desktop]# free -m | grep -n Mem2:Mem: 1826 867 959 9 0 278[root@caijy Desktop]# free -m | grep -n Mem | awk &#39;{print $4}&#39;955[root@caijy Desktop]# FreeMem=`free -m | grep Mem | awk &#39;{print $4}&#39;[root@caijy Desktop]# echo $FreeMem953上面做的获取内存可用量的步骤有些难度“超纲”了，如果不能够马上理解也不用担心，接下来才是重点，需要通过整数运算符来判断内存可用量的值是否小于1024，若小于则会提示内存不足的字样：[root@caijy Desktop]# [ $FreeMem -lt 1024 ] &amp;&amp; echo &quot;Insufficient Memory&quot;Insufficient Memory字符串比较是判断测试字符串是否为空值，或两个字符串是否相同的操作，常常用来判断某个变量是否未被定义（即内容为空值），理解起来也比较简单，常见的操作运算符如下： 操作符 作用 = 比较字符串内容是否相同。 != 比较字符串内容是否不同。 -z 判断字符串内容是否为空。 咱们可以通过判断String变量是否为空值，进而判断是否未被定义：[root@caijy Desktop]# [ -z $String ][root@caijy Desktop]# echo $?0最后再尝试把逻辑运算符引入来试试，当判断用于保存当前语系的环境变量值LANG不是为英语（en.US）则会满足逻辑条件并输出非英语的字样：[root@caijy Desktop]# echo $LANGen_US.utf8[root@caijy Desktop]# [ $LANG != &quot;en.US.utf8&quot; ] &amp;&amp; echo &quot;Not en.US.utf8&quot;Not en.US.utf8 流程控制语句接下来咱们通过if、for、while、case四种条件、循环语句来学习相对更高难度级别的Shell脚本. if条件测试语句if条件语句可以让脚本根据实际情况的不同而自动切换命令执行方案，从技术角度上来说分为单分支结构、双分支结构、多分支结构，复杂度随着灵活度一起逐级上升。 单分支的if条件语句结构，这种结构仅用if、then、fi关键词组成，只在条件成立后才执行预设命令，相当于口语的“如果……那么……”，属于最简单的一种条件判断结构，操作语法如图4-17所示：使用单分支的if条件语句来判断某个目录是否存在，若已经存在就结束条件判断和整个Shell脚本，而如果不存在则去创建这个目录：[root@caijy Desktop]# vim mkcdrom.sh#! /bin/bashDIR=&quot;/media/cdrom&quot;if [ ! -e $DIR ]thenmkdir -p $DIRfi 双分支的if条件语句结构，这种结构仅用if、then、else、fi关键词组成，进行两次条件判断匹配，两次判断中任何一项匹配成功后都会执行预设命令，相当于口语的“如果……那么……或者……那么……”，也是属于很简单的一种条件判断结构，操作语法如图4-18所示： 使用双分支的if条件语句来验证某个主机是否在线，然后根据判断执行返回值结果分别给予对方主机是在线还是不在线的提示信息。脚本中我主要是使用ping命令来测试与对方主机的网络联通性，而linux系统中的ping命令不像windows系统一样仅会尝试四次就结束，因此为了避免用户等待时间过长，而通过-c参数来规定尝试的次数，-i参数定义每个数据包的发送间隔时间以及-W参数定义最长的等待超时时间。[root@caijy Desktop]# vim chkhost.sh#! /bin/bashping -c 3 -i 0.2 -W 3 $1 &amp;&gt; /dev/nullif [ $? -eq 0 ]thenecho &quot;Host $1 is On-line.&quot;elseecho &quot;Host $1 is Off-line.&quot;fi192.168.10.10是服务器本机地址，验证下脚本的效果吧：[root@caijy Desktop]# bash chkhost.sh 192.168.10.10Host 192.168.10.10 is On-line.[root@caijy Desktop]# bash chkhost.sh 192.168.10.20Host 192.168.10.20 is Off-line.多分支的if条件语句结构，这种结构需要使用if、then、else、elif、fi关键词组成，进行多次条件判断匹配，多次判断中任何一项匹配成功后都会执行预设命令，相当于口语的“如果……那么……如果……那么……N次等等”，这是一种工作中最常使用的条件判断结构，虽然相对复杂但更加灵活，操作语法如图4-19所示：使用多分支的if条件语句来判断用户输入的分数在那个成绩区间内，然后输出如优秀、合格、不合格等提示信息。read是用来读取用户输入信息的命令，它能够把接收到的用户输入信息赋值给后面的指定变量，而-p参数则是给予了用户一定的提示信息。下面实例中判断用户输入的分数是否同时具备大于等于85分且小于等于100分，这样的话才输出Excellent字样，若上一条件没有匹配成功则继续判断用户输入分数是否大于等于70分且小于等于84分，这样的话输出Pass字样，如果两次都落空没有匹配成功，则最终输出Fail字样：[root@caijy Desktop]# vim chkscore.sh#!/bin/bashread -p &quot;Enter your score(0-100): &quot; GRADEif [ $GRADE -ge 85 ] &amp;&amp; [ $GRADE -le 100 ]then echo &quot;$GRADE is Excellent&quot;elif [ $GRADE -ge 70 ] &amp;&amp; [ $GRADE -le 84 ]then echo &quot;$GRADE is Pass&quot;elseecho &quot;$GRADE is Fail&quot;fi[root@caijy Desktop]# bash chkscore.shEnter your score(0-100): 8989 is Excellent[root@caijy Desktop]# bash chkscore.shEnter your score(0-100): 7575 is Pass[root@caijy Desktop]# bash chkscore.shEnter your score(0-100): 5656 is Fail for条件循环语句for循环语句可以让脚本一次性读取多个信息值，然后逐一对信息值进行循环操作处理，因此当您要处理的数据是有目标和范围时简直再适合不过了~例如使用for循环语句来从列表文件中读取多个用户名，然后逐一创建用户帐号并为其设置密码。[root@caijy Desktop]# vim users.txtandybarrycarldukeericgeorgeShell脚本中使用read命令来读取用户输入的密码值后赋值给PASSWD变量，并通过-p参数来显示一段给用户的提示内容，告诉用户正在输入的内容即将作为帐号密码。当下面的脚本执行后会自动的用users.txt列表文件中获取到所有的用户名称值，然后逐一使用id 用户名的方式查看用户的信息，并使用$?变量判断这条命令是否执行成功，也就是判断该用户是否已经存在。而/dev/null是被称作Linux的黑洞的文件，把输出信息重定向到这个文件后等同于删除数据（没有回收功能的垃圾箱），让用户的屏幕窗口保持简洁。[root@caijy Desktop]# vim Example.sh#!/bin/bashread -p &quot;Enter The Users Password :&quot; PASSWD`for UNAME incat users.txt`` do`id $UNAME &amp;&gt; /dev/nullif [ $? -eq 0 ]thenecho &quot;Already exists&quot;elseuseradd $UNAME &amp;&gt; /dev/nullecho &quot;$PASSWD&quot; | passwd --stdin $UNAME &amp;&gt; /dev/nullif [ $? -eq 0 ]thenecho &quot;$UNAME, Create success&quot;elseecho &quot;$UNAME, Create failure&quot;fifidone[root@caijy Desktop]# bash Example.shEnter The Users Password :123456andy, Create successbarry, Create successcarl, Create successduke, Create successeric, Create successgeorge, Create success[root@caijy Desktop]# tail -6 /etc/passwdandy:x:1001:1001::/home/andy:/bin/bashbarry:x:1002:1002::/home/barry:/bin/bashcarl:x:1003:1003::/home/carl:/bin/bashduke:x:1004:1004::/home/duke:/bin/basheric:x:1005:1005::/home/eric:/bin/bashgeorge:x:1006:1006::/home/george:/bin/bash while条件循环语句这是一种让脚本根据某些条件来重复执行命令的条件循环语句，而这种循环结构往往在执行前并不确定最终执行的次数，完全不同于for循环语句中有目的、有范围的使用场景。而while循环语句判断是否继续执行命令的依据一般是检查若条件为真就继续执行，而条件为假就结束循环，循环结构如图4-21所示：接下来就来利用多重分支的if条件测试语句与while条件循环语句来结合写一个用来判断数值的脚本吧，脚本中会使用$RANDOM变量来调取出一个随机的数值（范围:0–32767），然后通过expr命令计算取整出1000以内的一个随机数值，用这个数值来跟用户通过read命令输入的数值做比较判断。判断语句结构分为三项，分别是判断是否相等、是否大于随机值以及是否小于随机值，但这不是重点~关键是在于while条件循环语句的判断值为true，因此会无限的运行下去，直到猜中后运行exit 0命令才终止脚本。[root@caijy Desktop]# vim Guess.sh#!/bin/bashPRICE=$(expr $RANDOM % 1000)TIMES=0echo &quot;商品实际价格为0-999之间，猜猜看是多少？&quot;while truedoread -p &quot;请输入您猜测的价格数目：&quot; INTlet TIMES++if [ $INT -eq $PRICE ]thenecho &quot;恭喜您答对了，实际价格是 $PRICE&quot;echo &quot;您总共猜测了 $TIMES 次&quot;exit 0elif [ $INT -gt $PRICE ]thenecho &quot;太高了！&quot;elseecho &quot;太低了！&quot;fidone[root@caijy Desktop]# bash Guess.sh商品实际价格为0-999之间，猜猜看是多少？请输入您猜测的价格数目：500太低了！请输入您猜测的价格数目：750太低了！请输入您猜测的价格数目：850太低了！请输入您猜测的价格数目：920太高了！请输入您猜测的价格数目：880太高了！请输入您猜测的价格数目：865太低了！请输入您猜测的价格数目：870太低了！请输入您猜测的价格数目：875太高了！请输入您猜测的价格数目：873恭喜您答对了，实际价格是 873您总共猜测了 9 次 case条件测试语句如果您学习过C语言，此刻一定是会心一笑，这不就是switch语句吗？是的，功能非常相似！case条件测试语句是在多个范围内匹配数据，若匹配到则执行相关命令并结束整个条件测试，而如果数据不在所列出的范围内，则会去执行)中所规定的默认命令，测试结构如图4-22所示：刚刚学习的脚本普遍有一个致命的弱点，不信您就输入一个字母或乱码试一试~脚本立即就崩溃了。这是由于字母是不能跟数字做大小比较的，例如a是否大于等于3，这样的命题完全错误，变量操作会直接导致系统崩溃。咱们必须马上想出一个办法来判断用户的输入内容，一旦碰到字母或乱码也能予以提示，不至于因错误输入而崩溃，因此这样的需求用case条件测试语句和第3章节中学习的通配符来一起组合写一个脚本简直再适合不过了~提示用户输入一个字符并将其赋值给变量KEY，判断变量KEY为何种字符后分别输出是字母、数字还是其他字符：[root@caijy Desktop]# vim CheckKeys.sh#!/bin/bashread -p &quot;请输入一个字符，并按Enter键确认：&quot; KEYcase &quot;$KEY&quot; in[a-z]|[A-Z])echo &quot;您输入的是 字母。&quot;;;[0-9])echo &quot;您输入的是 数字。&quot;;;`)`echo &quot;您输入的是 空格、功能键或其他控制字符。&quot;esac[root@caijy Desktop]# bash CheckKeys.sh请输入一个字符，并按Enter键确认：w您输入的是 字母。[root@caijy Desktop]# bash CheckKeys.sh请输入一个字符，并按Enter键确认：1您输入的是 数字。[root@caijy Desktop]# bash CheckKeys.sh请输入一个字符，并按Enter键确认：` 您输入的是 空格、功能键或其他控制字符。 计划任务服务程序厉害的系统运维工程师能够让Linux系统实现自动化工作，无需人工的干预就可以让各个服务、命令在指定的时间段执行、服务或停止。更何况咱们已经有了如此彪悍的脚本程序，如果只是需要每天凌晨两点敲一下回车去执行这个Shell脚本程序，这样的工作简直就是痛苦死了（或者训练您家的小猫半夜按下回车键）。接下来学习如何来设置服务器的计划任务服务，把有周期规律性的工作交给系统去自动完成。计划任务有“一次性”与“长期性”的区分，可以理解为： 一次性计划任务:今晚11点30分开启网站服务（例如新网站的公测） 长期性计划任务:每周一的凌晨3点25分把/home/wwwroot目录打包备份为backup.tar.gz 一次性计划任务顾名思义就只是一次性有效，一般用于临时的工作需要，咱们可以用at命令实现这种功能，只需要写成”at 时间”的形式就可以，如果想要查看已设置好但还未执行的计划任务可以用”at -l”命令，而删除的话可以用”atrm 任务序号”即可，默认用at命令来设置计划任务的话是通过交互式的方法，例如设置系统在今晚23:30分自动重启网站服务吧：[root@caijy Desktop]# at 20.30at&gt; systemctl restart httpdat&gt; &lt;EOT&gt; --注：此处请同时按下Ctrl+d来结束编写计划任务job 1 at Thu Sep 14 20:30:00 2017[root@caijy Desktop]# al -lbash: al: command not found...[root@caijy Desktop]# at -l1 Thu Sep 14 20:30:00 2017 a root当然如果您想挑战一下更加高难度但又简便的方式，可以把前面章节中学习的管道符（任意门）放到两条命令之间，让at命令接收前面echo命令的输出信息，以达到通过非交互式的方式创建计划任务，这样的话在Shell脚本中都可以做引用了~[root@caijy Desktop]# echo &quot;systemctl restart httpd&quot; | at 21.00job 2 at Thu Sep 14 21:00:00 2017[root@caijy Desktop]# at -l1 Thu Sep 14 20:30:00 2017 a root2 Thu Sep 14 21:00:00 2017 a root如果一不不小心设置了两条，想要删除其中一条的话也是很简单的：[root@caijy Desktop]# atrm 1[root@caijy Desktop]# at -l2 Thu Sep 14 21:00:00 2017 a root而如果您的工作需要是有周期规律性的，那Linux系统中默认启用的crond服务简直再适合不过了，创建、编辑计划任务的命令为”crontab -e”，查看当前计划任务的命令为”crontab -l”，删除某条计划任务的命令为”crontab -r”，另外如果您登录的是超级用户的话，还可以通过加上-u参数来编辑其他人的计划任务。不过在正式的部署计划任务前，请念一下口诀“分、时、日、月、星期 命令”，这是使用crond服务设置任务的参数格式，没有设置的位置也要用*号占位： 字段 说明 分钟 取值为从0到59之间的整数 小时 取值为从0到23之间的任意整数 日期 取值为1到31之间的任意整数 月份 取值为1到12之间的任意整数 星期 取值为0到7之间的任意整数，其中0与7均为星期日 命令 要执行的命令或程序脚本 参考上面crond计划任务实现的参数格式，假设目前每周一、三、五的凌晨3点25分都需要把某个网站数据目录通过tar命令打包成一个压缩包来当做备份文件，那么除了用减号(-)来表示一段连续的时间周期，例如12-15就可以代表每月的12-15日，除号（/）代表任务的间隔时间，例如/2就是每隔2分钟执行一次的意思，还可以用逗号（,）来分别表示多个时间段，如8,9,12来代表八月、九月和12月执行任务，那么来尝试做一下吧：[root@caijy Desktop]# crontab -eno crontab for root - using an empty onecrontab: installing new crontab[root@caijy Desktop]# crontab -l25 3 * * 1,3,5 /usr/bin/tar -czvf backup.tar.gz /home/wwwroot而如果计算机服务器中需要有多条计划任务，并且这次的工作是每周一至五的每天的凌晨1点钟清空/tmp临时目录中的所有文件，就可以把相应的参数依次写到下面。而在crond服务的计划任务参数中所有的命令请一定要用绝对路径的方式来写，如果不知道的话用whereis命令来查下吧：[root@caijy Desktop]# whereis rmrm: /usr/bin/rm /usr/share/man/man1/rm.1.gz /usr/share/man/man1p/rm.1p.gz[root@caijy Desktop]# crontab -ecrontab: installing new crontab[root@caijy Desktop]# crontab -l25 3 * * 1,3,5 /usr/bin/tar -czvf backup.tar.gz /home/wwwroot0 1 * * 1-5 /usr/bin/rm -rf /tmp/*对同学们今后工作中使用计划服务来嘱咐几句建议，首先是crond服务的配置参数中可以像Shell脚本一样以#号开头来写上注释信息，这样方便以后再看到这段命令代码时快速回忆起功能、需求以及当时编写人等等重要信息，其次是计划任务中的分钟项目必须有数值，绝对不能为空或是*号，而日和周不能同时使用，否则就会发生冲突，这些细节我想您一定要记下。 转载自：http://www.linuxprobe.com/chapter-04.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础课程03]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F14%2FLinux%E5%9F%BA%E7%A1%80%E8%AF%BE%E7%A8%8B03%2F</url>
    <content type="text"><![CDATA[我们已经学习了数十个常用的Linux系统命令，以后要把这些命令通过语法结合使用。这里学习Linux命令与文件读写操作有关的重定向技术的五种模式——标准覆盖输出重定向、标准追加输出重定向、错误覆盖输出重定向、错误追加输出重定向、输入重定向。 输入输出重定向简单用一句话来概括即 “使用输入重定向能够把文件导入到命令中，而输出重定向则是能够把原本要输出到屏幕的数据信息写入到指定文件中”。平常输出重定向会使用得多一些，细分之下又有 标准输出重定向 和 错误输出重定向 两种技术以及 清空写入 和 追加写入 两种模式。 标准输入(STDIN，文件描述符为0)：默认从键盘输入，为0时表示是从其他文件或命令的输入。 标准输出(STDOUT，文件描述符为1)：默认输出到屏幕，为1时表示是文件。 错误输出(STDERR，文件描述符为2)：默认输出到屏幕，为2时表示是文件。 对于输入重定向有这些情况： 符号 作用 命令 &lt; 文件 将文件作为命令的标准输入 命令 &lt;&lt; 分界符 从标准输入中读入，直到遇见“分界符”才停止 命令 &lt; 文件1 &gt; 文件2 将文件1作为命令的标准输入并将标准输出到文件2 对于输出重定向有这些情况： 符号 作用 命令 &gt; 文件 将标准输出重定向到一个文件中（清空原有文件的数据） 命令 2&gt; 文件 将错误输出重定向到一个文件中（清空原有文件的数据） 命令 &gt;&gt; 文件 将标准输出重定向到一个文件中（追加到原有内容的后面） 命令 2&gt;&gt; 文件 将错误输出重定向到一个文件中（追加到原有内容的后面） 命令 &gt;&gt; 文件 2&gt; &amp;1 或 命令 &amp;&gt;&gt; 文件 将标准输出与错误输出共同写入到文件中（追加到原有内容的后面） 试一下吧，通过标准输出重定向将“man bash”命令原本要输出到屏幕的信息写入到文件中去，效果类似于： 有没有感觉到特别方便呢？那么接下来试试输出重定向技术中的 清空写入 与 追加写入 两种不同模式带来的变化吧~先通过清空模式向文件写入一行数据（该文件中包含上一个实验的man命令信息），然后再通过追加模式向文件再写入一次数据，最终咱们看到的文件内容会是这个样子的：[caijy@localhost Desktop]$ echo &quot;Welcome to linux&quot; &gt; readme.txt[caijy@localhost Desktop]$ echo &quot;Quality linux learning materials&quot; &gt;&gt; readme.txt[caijy@localhost Desktop]$ cat readme.txtWelcome to linuxQuality linux learning materials 虽然都是输出重定向技术，但对于不同命令的标准输出和错误输出还都有点区别，例如查看下当前目录中某个文件的信息吧。因为这个文件是真实存在的，因此使用标准输出即可将数据写入到文件中，而错误的输出重定向则不行，依然会把信息输出到了屏幕上。[caijy@localhost Desktop]$ touch out.txt[caijy@localhost Desktop]$ ls -l readme.txt &gt; out.txt[caijy@localhost Desktop]$ cat out.txt-rw-rw-r--. 1 caijy caijy 50 Sep 14 10:31 readme.txt[caijy@localhost Desktop]$ ls -l readme.txt 2&gt; out.txt-rw-rw-r--. 1 caijy caijy 50 Sep 14 10:31 readme.txt 那如果是想把命令的报错信息写入到文件呢？例如当您在执行一个自动化的Shell脚本时会特别的实用，因为可以通过把整个脚本执行过程中的报错信息都记录到文件中，便于安装后的排错工作。接下来学习实践中咱们就以一个不存在的文件做演示吧：[caijy@localhost Desktop]$ touch out.txt[caijy@localhost Desktop]$ ls -l xxxls: cannot access xxx: No such file or directory[caijy@localhost Desktop]$ ls -l xxx &gt; out.txtls: cannot access xxx: No such file or directory[caijy@localhost Desktop]$ ls -l xxx 2&gt; out.txt[caijy@localhost Desktop]$ cat out.txtls: cannot access xxx: No such file or directory 输入重定向作用是把文件直接导入到命令中。接下来使用输入重定向把文件导入给“wc -l”命令来统计下内容行数吧，这样命令其实等同于接下来要学习的“cat readme.txt | wc-l”的管道符命令组合。[caijy@localhost Desktop]$ wc -l &lt; readme.txt2 管道命令符管道符的输入方法是同时按下键盘的“Shift”与“\”键，执行格式为“命令A | 命令B”，其实管道命令符的作用也能用一句话来概括： “把前一个命令原本要输出到屏幕的数据当作是后一个命令的标准输入” 。回想前面学习过的grep文本搜索命令通过匹配关键词/sbin/nologin找出了所有被限制登录系统的用户，其实只要学完了这个小节，完全可以把下面的两条命令合并到一起。[caijy@localhost Desktop]$ grep &quot;/sbin/nologin&quot; /etc/passwd | wc -l33 学习到了这个管道符就像拿到了一个法宝，让咱们来套用到其他不同的命令上吧，比如用翻页的形式查看/etc目录中的文件列表及属性信息吧（默认会一股脑的都显示到屏幕上，根本看不清楚）： [root@localhost Desktop]# echo &quot;linux&quot; | passwd --stdin rootChanging password for user root.passwd: all authentication tokens updated successfully. 对于这个管道符命令是不是觉得有些相见恨晚？其实玩法还有很多，比如默认发送邮件需要交互式的进行才行，而此时则可以通过一条结合了管道符的命令语句把编辑好的内容与标题一起的“打包”，最终用一条命令就顺利的给用户发送了邮件。[root@localhost Desktop]# echo &quot;Context&quot; | mail -s &quot;Subject&quot; caijy[root@localhost Desktop]# su caijy[caijy@localhost Desktop]$ mailHeirloom Mail version 12.5 7/5/10. Type ? for help.&quot;/var/spool/mail/caijy&quot;: 1 message 1 new&gt;N 1 root Thu Sep 14 11:01 18/612 &quot;Subject&quot; 能不能让这样方便的命令写的更高级一些呢？下面这条自造命令就是通过把mail邮件命令与输入重定向的分界符来结合使用，效果是让用户可以一直的输入内容，直到系统遇到匹配上了用户定义的分界符才最终结束。[root@localhost Desktop]# mail -s &quot;Readme&quot; root@localhost.localdomain &lt;&lt; over&gt; I think linux is very practical&gt; I hope to learn more&gt; can you teach me ?&gt; over 当然大家可不要误解管道命令符只能用一次哦，完全可以这样用：“命令A|命令B|命令C”。 命令行的通配符例如想批量查看所有硬盘文件的相关权限属性，笨笨的命令会是这样的：[root@localhost Desktop]# ls -l /dev/sdabrw-rw----. 1 root disk 8, 0 Sep 13 04:43 /dev/sda[root@localhost Desktop]# ls -l /dev/sda1brw-rw----. 1 root disk 8, 1 Sep 13 04:43 /dev/sda1[root@localhost Desktop]# ls -l /dev/sda2brw-rw----. 1 root disk 8, 2 Sep 13 04:43 /dev/sda2[root@localhost Desktop]# ls -l /dev/sda3ls: cannot access /dev/sda3: No such file or directory幸亏我的硬盘文件和分区只有3个，要是有几百个的话，估计一天的工作时间都要忙活这个事了。咱们此时已经能看出一些简单规律了，比如这些硬盘设备文件共性都是以sda开头并且存放到了/dev目录中，那即便不知道分区编号和具体分区的个数也一样可以用通配符来搞定。通配符顾名思义就是通用的匹配信息的符号，比如星号(*)就是代表匹配零个或多个字符，问号(?)是代表匹配单个字符，中括号内加上数字[0-9]代表匹配单个阿拉伯数字的字符，而中括号内加上字母[abc]则是代表匹配单个指定的英文字母。[root@localhost Desktop]# ls -l /dev/sda*brw-rw----. 1 root disk 8, 0 Sep 13 04:43 /dev/sdabrw-rw----. 1 root disk 8, 1 Sep 13 04:43 /dev/sda1brw-rw----. 1 root disk 8, 2 Sep 13 04:43 /dev/sda2如果只需要看sda后面一定要有个字符的文件相关信息呢？那就要用到问号来通配了。[root@localhost Desktop]# ls -l /dev/sda?brw-rw----. 1 root disk 8, 1 Sep 13 04:43 /dev/sda1brw-rw----. 1 root disk 8, 2 Sep 13 04:43 /dev/sda2您除了可以用[0-9]来通配所有的单个阿拉伯数字，也可以用[135]这样的方式仅匹配这三个指定数字，若没有通配到即不会显示出来：[root@localhost Desktop]# ls -l /dev/sda[0-9]brw-rw----. 1 root disk 8, 1 Sep 13 04:43 /dev/sda1brw-rw----. 1 root disk 8, 2 Sep 13 04:43 /dev/sda2[root@localhost Desktop]# ls -l /dev/sda[135]brw-rw----. 1 root disk 8, 1 Sep 13 04:43 /dev/sda1 常用的转义字符Shell解释器为了能够更好的理解您想表达的意思，还提供了特别丰富的转义符号来帮助程序员处理输入的特殊数据。常见的转义字符包括有：反斜杠()的作用就是转义后面的一个变量变为单纯的字符串，单引号(‘’)则是转义其中所有的变量为单纯的字符串，而双引号（””）是保留其中的变量属性不转义，反引号(``)则是把其中的命令执行后返回一个结果。例如咱们先定义一个名称为PRICE的变量并赋值为5，然后通过双引号括起来输出字符串与变量结合的结果：[root@localhost Desktop]# PRICE=5[root@localhost Desktop]# echo &quot;Price is $PRICE&quot;Price is 5[root@localhost Desktop]# echo &quot;Price is $$PRICE&quot;Price is 44837PRICE原本刚刚是希望能够进一步输出“Price is $5”即价格是五美元的字符串信息，但碰巧美元符号与变量提取符号冲突了，因此输出的并不是预想的信息。需要用转义符把第一个$符号转换成单纯的字符串，再或者把整段都转义成单纯的字符串吧（当然这个只是让您看下效果，并不符合实验需要）：[root@localhost Desktop]# echo &quot;Price is \$$PRICE&quot;Price is $5[root@localhost Desktop]# echo &#39;Price is \$$PRICE&#39;Price is \$$PRICE 最后一个您可能看到结果时会觉得很无用，因此暂且先不用管具体的使用场景，就当作是提前为SHELL编程知识学习做一点小小的铺垫吧。如果只需要某个命令的返回输出值时，就可以用像 命令 这样用反引号括起来的命令格式来达到效果，例如通过反引号与uname -a命令结合通过返回值来查看下本机版本和内核信息吧：[root@localhost Desktop]# echo `uname -a` Linux localhost.localdomain 3.10.0-123.el7.x86_64 #1 SMP Mon May 5 11:16:57 EDT 2014 x86_64 x86_64 x86_64 GNU/Linux 重要的环境变量变量是计算机系统中用于保存可变值的数据类型，在Linux系统中一般变量名称都是大写的，这仅算是一种约定俗成的规范，平时可以直接通过变量名称来提取到对应的变量值。Linux系统中的环境变量是用来指定系统运行环境的一些参数，比如每个用户不同的家目录、邮件保存存放位置等等。 前面小节中提到的一个概念——即Linux系统中一切都是文件，因此Linux命令肯定也不例外，那当用户执行了一条命令之后到底发生了什么事情呢？简单来说就是四个步骤： 第1步骤阶段是判断用户是否以绝对路径或相对路径的方式输入命令（如/bin/ls），如果是的话则直接执行。 第2步骤阶段是检查用户输入的命令是否为“别名命令”，即用一个自创的命令名称来替换原本的命令名称。可以用alias命令来创建一个属于自己的命令别名，格式为: alias 新的命令=’原命令 -选项/参数’，若要取消一个别名的话则是用unalias命令，格式为：“unalias 别名”。例如以前每次用rm命令删除文件的时候都要被要求再确认是否执行删除操作，其实这就是Linux系统为了防止用户误删除文件而特意设置的rm别名命令，咱们可以把它取消掉：[root@localhost Desktop]# alias rmalias rm=&#39;rm -i&#39;[root@localhost Desktop]# unalias rm[root@localhost Desktop]# rm out.txt 第3步骤阶段就是由Bash解释器来判断用户输入的是个内部命令还是个外部命令，内部命令是解释器内部的指令，会被直接的执行，而绝大部分的时候都会是外部命令，交由给第4步骤来继续处理，您可以使用“type 命令名称”来手工判断是内部命令还是外部命令，也是很有趣的。 第4步骤阶段是系统在多个路径中查找用户输入的命令文件，而定义这些路径的变量叫做PATH，可以简单把它理解成是“解释器的小助手”，作用是告诉Bash解释器要执行的命令可能存放到了那里，然后Bash解释器就会乖乖的在这些目录中逐个查找。PATH是由多个路径值组成的变量，每个路径值之间用冒号间隔，咱们对PATH变量内这些路径的增加和删除操作将会直接影响bash解释器搜索linux命令的位置。[root@localhost Desktop]# echo $PATH/usr/local/bin:/usr/local/sbin:/usr/bin:/usr/sbin:/bin:/sbin:/home/caijy/.local/bin:/home/caijy/bin[root@localhost Desktop]# echo PATH=$PATH:/root/binPATH=/usr/local/bin:/usr/local/sbin:/usr/bin:/usr/sbin:/bin:/sbin:/home/caijy/.local/bin:/home/caijy/bin:/root/bin 这里有比较经典的问题：“为什么不能在$PATH中添加进当前目录(.)?”答案：虽然把$PATH变量添加了当前目录(.)会在一些情况让用户免去输入命令所在路径的麻烦，但如果黑客在比较常用的公共目录/tmp中存放了一个名为”ls”或”cd”的同名木马文件，那么用户就极有可能错误的执行了。作为一名态度谨慎、有经验的运维人员在接手了一台Linux系统后一定会在执行命令前先检查下PATH变量中是否有可疑的目录，另外读者们从PATH变量的例子中是不是也感觉到环境变量特别实用呢~您可以使用env命令来查看到linux系统中所有的环境变量，在此摘录最重要的10个环境变量： 变量名称 作用 HOME 用户的主目录（即家目录） SHELL 用户在使用的SHELL解释器名称。 HISTSIZE 定义了 history 命令输出的记录数 HISTFILESIZE 定义了在文件 ~/.bash_history 中保存命令的记录总数 MAIL 邮件信箱文件保存路径。 LANG 系统语言、语系名称。 RANDOM 生成一个随机数字。 PS1 bash解释器的提示符。 PATH 定义解释器搜索用户执行命令的路径。 EDITOR 用户默认的文本编辑器。 Linux系统为了能够为每个用户提供独立的、合适的工作运行环境，因此在不同的用户身份下提取一个相同的变量也可能会获得不同的值，例如查看下HOME变量在不同用户身份下的值都有那些吧（su是用于切换用户身份的命令）：[root@localhost Desktop]# echo $HOME/root[root@localhost Desktop]# su - caijyLast login: Thu Sep 14 11:01:16 CST 2017 on pts/0[caijy@localhost ~]$ echo $HOME/home/caijy 其实变量是由固定的变量名与用户或系统设置的变量值两部分组成的，如果工作需要完全可以自己手工创建的，例如设置一个名称为WORKDIR的变量，方便用户更轻松的进入一个很深层的目录：[caijy@localhost Desktop]$ mkdir -p c/workdir[caijy@localhost Desktop]$ WORKDIR=c/workdir[caijy@localhost Desktop]$ cd $WORKDIR[caijy@localhost workdir]$ pwd/home/caijy/Desktop/c/workdir 但是这样的变量不具有全局性，作用范围也是有限的，默认不能够被其他用户使用的，如果工作需要的话咱们可以使用export命令将其提升为全局变量，这样其他的用户也就可以使用到这个变量了。 转载自：http://www.linuxprobe.com/chapter-03.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础课程02]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F12%2FLinux%E5%9F%BA%E7%A1%80%E8%AF%BE%E7%A8%8B02%2F</url>
    <content type="text"><![CDATA[新手必须掌握的Linux命令 shell简介通常计算机硬件是由运算器、控制器、存储器、输入/输出设备等等这些物理设备共同组成的，而能够让机箱内各种硬件设备各司其职的东西就叫做系统内核。Linux系统的内核负责驱动硬件、管理活动和分配/管理硬件资源等等任务，如此说来系统内核对计算机正常稳定的运行来讲可真的是太重要了，因此一般不建议直接去编辑内核中的参数，而是让用户通过基于“系统调用接口”开发出的程序/服务来管理计算机，这样一层层环环相扣来满足咱们的日常工作需要.“Shell”——也可称为“壳”，充当的是人与内核（硬件）的翻译官，用户把一些命令“告诉”Shell终端，它就会调用相应的程序服务执行工作啦主流Linux系统选择Bash解释器作为命令行终端主要有以下4项优势: 通过上下方向键来调取过往执行过的Linux命令。 命令或参数仅需输入前几位就可以用tab键补全。 强大的批处理脚本。 实用的环境变量。 man–帮助命令常见执行Linux命令的格式是这样的(中间有空格)： 命令名称 [命令参数] [命令对象] 命令对象一般是指要被处理的文件、目录、用户等资源，而命令参数可以选用长格式（完整的选项名称）也可选用短格式（单个字母的缩写），一般分别用”–”与”-“做前缀。 长格式如:man –help短格式如:man -h 进入Linux，打开terminal,输入：man man,便可看到man命令自身的帮助信息： 进入man命令帮助信息界面后的常用操作按键包括有（与后面章节中学习的vim编辑器非常相像）: 按键 用处 空格键 向下翻一页 Page Down 向下翻一页 Page Up 向上翻一页 HOME 去往首页 END 去往尾页 /关键词 从上至下搜索“关键词” ？关键词 从下至上搜索“关键词” n 定位到下一个关键词 N 定位到上一个关键词 q 退出帮助文档 一般帮助文档都很长，我们应该了解它们的结构来更好得获得帮助 结构名称 代表意义 NAME 命令的名称 SYNOPSIS 参数的大致用法 DESCRIPTION 介绍说明 EXAMPLES 举例说明 OVERVIEW 概述 DEFAULTS 默认的功能 OPTIONS 可用的选项 ENVIRONMENT 环境变量 FILES 用到的文件 SEE ALSO 相关的资料 HISTORY 维护历史 常用系统工作命令echo命令用于在终端显示字符串或输出变量提取后的值，格式为：“echo [字符串 | $变量]”。把指定字符串输出到终端屏幕：使用$变量的方式提取变量值并输出到屏幕： date命令用于显示及设置系统的时间或日期，格式为：”date [选项] [+指定的格式]”。date命令参数常见的格式如下： 参数 作用 %t 跳格（tab键） %H 小时（00-23） %I 小时（00-12） %M 分钟（00-59） %S 秒（00-59） %p 显示本地AM或PM %X 相当于%I:%M:%S %p %Z 显示时区 %A 星期几 (Sunday-Saturday) %a 星期几 (Sun-Sat) %B 完整月份 (January-December) %b 缩写月份 (Jan-Dec) %d 日(01-31) %j 一年中的第几天(001-366) %m 月份(01-12) %Y 完整的年份 按照默认的格式查看当前的系统时间：[caijy@localhost Desktop]$ dateTue Sep 12 20:33:37 CST 2017按照”年-月-日 小时:分钟:秒”的格式查看当前的系统时间：[caijy@localhost Desktop]$ date &quot;+%Y-%m-%d %H:%M:%S&quot;2017-09-12 20:35:30设置当前的系统时间为2017年9月12日21点00分：[caijy@localhost Desktop]$ sudo date -s &quot;20170912 21:00:00&quot;Tue Sep 12 21:00:00 CST 2017再次查看系统时间[caijy@localhost Desktop]$ dateTue Sep 12 21:01:04 CST 2017查看今天是一年中的第几天，其实用这个参数也能够很好的区分备份时间的新旧，即数字越大，越靠近当前时间：[caijy@localhost Desktop]$ date &quot;+%j&quot;255 reboot命令用于重启系统，格式为：”reboot”。重启计算机这种操作会涉及到对硬件资源的管理权限，因此默认只能使用root用户来重启您的电脑：[caijy@localhost Desktop]$ reboot poweroff命令用于关闭系统，格式为：”poweroff”。关机命令也同理，默认只有root管理员用户才可以关闭您的电脑：[caijy@localhost Desktop]$ poweroff wget命令用于在终端中下载网络文件，格式为：“wget [参数] 下载地址”。 参数 说明 -b 后台下载模式 -O 下载到指定mul -t 最大尝试次数 -c 断点续传 -p 下载页面内所有资源,包括图片、视频等。 -r 递归下载 ps命令用于查看系统中的进程状态，格式为：“ps [参数]”，常见的ps命令参数有 参数 作用 -a 显示所有的进程（包括其他用户的） -u 用户以及其他详细信息 -x 显示没有控制终端的进程 Linux系统中时刻运行着许许多多的进程，如果能够合理的管理它们，绝对有益于对系统的性能优化，Linux系统中进程最常见的5种不同的状态是运行、中断、不可中断、僵死与停止，它们的含义分别是： R(运行):正在运行或在运行队列中等待。 S(中断):休眠中, 在等待某个条件的形成或接收到信号。 D(不可中断):收到信号不唤醒和不可运行, 进程必须等待直到有中断发生。 Z:(僵死):进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放。 T:(停止):进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行。 top命令用于动态的监视进程活动与系统负载等信息，格式为：“top”。这个top命令可真的是太厉害了，它能够动态的查看系统运维状态，完全可以比喻成是“强化版的Windows任务管理器”， top命令前面的五行为系统整体的统计信息： 第1行:系统时间，运行时间，登录终端数，系统负载（分别为1分钟、5分钟、15分钟的平均值，数值越小意味着负载越低）。 第2行:进程总数，运行中的，睡眠中的，停止的，僵死的。 第3行:用户占用资源，系统内核占用资源，改变过优先级的进程，空闲的资源，等待输入输出的时间。此行数据均为CPU数据并以百分比格式显示，例如”99.2 id”意味着有99.2%的CPU处理器资源正在空闲中。 第4行:物理内存总量，使用量，空闲量，作为内核缓存的内存量。 第5行:虚拟内存总量，使用量，空闲量，已被提前加载的内存数据。 pidof命令用于查询某个指定服务进程的PID号码值，格式为：“pidof [参数] [服务名称]”。PID值是区别每个进程的唯一号码，每次在计算机上运行相同的服务程序都很少会获得同样值的PID号码，例如查询下本机sshd服务程序的PID进程号码值：[caijy@localhost Desktop]$ pidof sshd1736 kill命令用于终止某个指定PID号码的服务进程，格式为：“kill [参数] [进程PID号]”。咱们来动手把上面pidof命令查询到的PID号码给终止掉吧，这样操作的效果等同于把sshd服务强制停止。[caijy@localhost Desktop]$ sudo kill 1736killall命令用于终止某个指定名称的服务所对应的全部进程，格式为：“killall [参数] [进程名称]”。(目前尚未安装网卡，找个例子)[root@linuxprobe ~]# pidof httpd13581 13580 13579 13578 13577 13576[root@linuxprobe ~]# killall httpd[root@linuxprobe ~]# pidof httpd[root@linuxprobe ~]# 平时在系统终端中执行一个命令后如果想立即的停止它，您可以同时按下系统组合键“Ctrl+c”，这样命令的进程将会立即被终止，是生产工作中比较常用的命令行快捷键之一。或者有些命令在执行时会不断的在屏幕上输出信息，影响到咱们继续输入命令了，便可以在执行命令时在命令最后面添加上一个“&amp;”符号，这样命令从开始执行就默认被放到系统后台了。 常用系统工作命令为了更好的了解Linux服务器，成为一名合格的运维人员，您必须具备快速查看Linux系统运行状态的能力，因此接下来咱们会逐个来学习下对于网卡网络、系统内核、系统负载、内存使用情况、当前启用终端数量、历史登录记录、命令执行记录以及救援诊断命令的使用方法，都是超级实用的Linux命令哦~ ifconfig用于获取网卡配置与网络状态等信息:格式为”ifconfig [网络设备] [参数]”。查看本机当前的网卡配置与网络状态等信息，主要就是看每段开头的网卡名称、inet参数后面的IP地址、ether参数后面的MAC网卡物理地址以及RX、TX的接收与发送数据包的流量大小。 uname命令用于查看系统内核与系统版本等信息，格式为：“uname [-a]”。一般会固定搭配上-a参数来完整查看当前系统的内核名称、主机名、内核发行版本、节点名、系统时间、硬件名称、硬件平台、处理器类型以及操作系统名称等信息:[caijy@localhost Desktop]$ uname -aLinux localhost.localdomain 3.10.0-123.el7.x86_64 #1 SMP Mon May 5 11:16:57 EDT 2014 x86_64 x86_64 x86_64 GNU/Linux顺便说下，如果您想查看当前系统版本的详细信息需要看redhat-release文件：[caijy@localhost Desktop]$ cat /etc/redhat-releaseRed Hat Enterprise Linux Server release 7.0 (Maipo) uptime命令用于查看系统的负载信息，格式为：“uptime”。这个命令可以为您显示当前系统时间、系统已运行时间、启用终端数量以及平均负载值等信息数据。平均负载值指的是最近1分钟、5分钟、15分钟的系统压力情况（下面加粗的信息部分），负载值越低越好[caijy@localhost Desktop]$ uptime21:14:39 up 31 min, 2 users, load average: 0.20, 0.19, 0.14 free命令用于显示当前系统中内存的使用量信息，格式为：“free [-h]”。为了保证Linux系统不会因硬件故障而突然卡住宕机，那么内存使用量当之无愧是运维人员最应该时刻要关注的数据对象啦，可以使用-h参数来以更人性化的样输出当前内存的实时使用量信息 who命令用于查看当前登入主机的用户终端信息，格式为：”who [参数]”。简单三个字母就可以快捷的显示出所有正在登录着本机的用户名称以及他们正在开启的终端信息： last命令用于查看所有系统的登入记录，格式为：”last [参数]”。使用last命令可以看到本机的登录记录，但由于这些信息都是被以日志文件的形式保存在系统中的数据内容，骇客们很轻易的便可对内容进行篡改，所以千万不要单纯以该命令的输出信息而判断系统有无被恶意入侵！ history命令用于显示历史执行过的命令，格式为：“history [-c]”。执行history命令能显示出当前用户在本地计算机中执行过的最近1000条命令记录，觉得1000不够用的话还可以修改/etc/profile文件的HISTSIZE变量值，或者使用-c参数来清空里面的历史数据，还可以使用“!编码数字”的方式来重复执行某一次的命令，有很多种有趣的玩法： 历史命令会被保存到用户家目录中的”.bash_history”文件中。Linux系统中以点(.)开头的文件均代表隐藏文件，一般大多会是系统服务文件。[caijy@localhost Desktop]$ cat ~/.bash_history清空该用户在本机中执行的Linux命令历史记录信息：[caijy@localhost Desktop]$ history -c sosreport命令用于收集系统配置并诊断信息后输出结论文档，格式为：“sosreport”。。。有待学习 工作目录切换命令pwd命令用于显示当前所处的工作目录，格式为：“pwd [选项]”。[caijy@localhost Desktop]$ pwd/home/caijy/Desktop cd命令用于切换工作路径，格式为：“cd [目录名称]”。这个命令应该是最最常用的Linux命令之一了，您可以通过cd命令来便捷的切换到不同的工作目录。除了常见的切换目录的方式，还可以使用“cd -”命令来返回到上一次所处的目录或使用“cd ~”命令来切换到当前用户的家目录，亦或使用“cd ~username”则可以切换到其他用户的家目录了~例如使用“cd 路径”的方式切换进/etc目录中：[caijy@localhost Desktop]$ cd /etc同样的道理，再尝试切换进/bin目录中：[caijy@localhost etc]$ cd /bin此时返回到上一次的目录（即/etc目录）：[caijy@localhost bin]$ cd -/etc还可以快速的切换到用户自己的家目录呢：[caijy@localhost etc]$ cd ~[caijy@localhost ~]$ ls命令用于显示目录中的文件信息，格式为：“ls [选项] [文件] ”。当咱们处在不同的工作目录下时，能够看到当前目录下的文件也在发生变化，ls命令的“-a”参数看到全部文件（包括隐藏文件），再结合“-l”参数来查看文件的属性、大小等详细信息。整合之后的命令即可实现查看当前目录中所有文件列表并输出这些文件的属性信息：需要看目录属性信息的话，需要额外添加一个-d参数才可以，例如查看/etc目录的权限与属性信息：[caijy@localhost ~]$ ls -ld /etcdrwxr-xr-x. 132 root root 8192 Sep 12 20:48 /etc 文本文件编辑命令在Linux系统中一切都是文件，而对于服务程序的配置自然也就是在编辑程序的配置文件，如果不能熟练的查阅数据，那以后工作时可就真的要尴尬了。接下来学习几条用于查看文本文件内容的命令吧cat命令用于查看纯文本文件（较短的），格式为：“cat [选项] [文件]”。Linux系统中有需要用于查看文本内容的命令，但其中每个命令又都有自己的特色特点，比如这个cat命令就是用于查看比较精简的文本内容的。这个其实是最好记的命令之一，因为cat在英语中是猫的意思，小猫咪是不是总给您一种娇小、可爱的感觉呢？另外如果您想看文本内容时还顺便显示行号的话，不妨再追加一个“-n”参数试试吧：more命令用于查看纯文本文件（较长的），格式为：“more [选项] 文件”。对于长篇的文本内容，推荐使用more命令来查看文本内容，不仅可以提示您已经阅读了百分之多少，还可以使用空格或回车键向下翻页：head命令用于查看纯文本文档的前N行，格式为：“head [选项] [文件]”。tail命令用于查看纯文本文档的后N行或持续刷新内容，格式为：“tail [选项] [文件]”。当然咱们还会遇到一种更奇葩的情况，比如需要去查看文本内容的最后20行，那么操作方法其实跟head命令是非常相似的，只需要执行“tail -n 20 文件名”命令就可以达到这样的效果。而tail命令最强悍的功能是用于持续刷新一个文件的内容，尤其是对于想要实时看到最新日志文件的时候特别有用：tr命令用于替换文本文件中的字符，格式为:“tr [原始字符] [目标字符]”。例如试试把某个文本内容完整替换成大写英文吧：[caijy@localhost Desktop]$ cat 2.txtabcdefghijklmnopqrstuvwxyz[caijy@localhost Desktop]$ cat 2.txt | tr [a-z] [A-Z]ABCDEFGHIJKLMNOPQRSTUVWXYZ wc命令用于统计指定文本的行数、字数、字节数，格式为“wc [参数] 文本”。 参数 作用 -l 只显示行数 -w 只显示单词数 -c 只显示字节数 例如可以使用“-l”参数来统计行数，而passwd是用于保存系统帐户信息的文件，因此下面的命令就是用于统计当前系统中有多少个用户的作用啦：[caijy@localhost Desktop]$ wc -l /etc/passwd38 /etc/passwd stat命令用于查看文件的具体存储信息和时间等信息，格式“stat 文件名称”。 cut命令用于按“列”来提取文本字符，格式为：“cut [参数] 文本”。如何准确的提取出最想要的数据，这也应该是咱们学习研究的方向之一，按基于“行”的方式来提取是比较简单的，只需要设置好要搜索的关键词即可，但是按列搜索的话不仅要使用“-f”参数来设置需要看的列数，还必须使用“-d”参数来设置间隔符号。因为passwd是用于保存用户信息数据的文件且每一项值都是通过冒号来间隔的，因此可以来尝试下提取出passwd文件中的用户名信息吧，即提取以:（冒号）为间隔符号的第一列内容：[caijy@localhost Desktop]$ head -n 2 /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologin[caijy@localhost Desktop]$ cut -d: -f1 /etc/passwdrootbindaemonadmlpsyncshutdownhaltmailoperatorgamesftpnobodydbuspolkitdunboundcolordusbmuxdavahiavahi-autoipdlibstoragemgmtsaslauthqemurpcrpcusernfsnobodyrtkitradvdntpchronyabrtpulsegdmgnome-initial-setuppostfixsshdtcpdumpcaijy diff命令用于比较多个文本文件的差异，格式为：”diff [参数] 文件”。仅仅显示比较后的结果，判断文件是否相同：diff --brief diff_A.txt diff_B.txt使用详细的上下文输出格式来描述文件内容具体的不同：diff -c diff_A.txt diff_B.txt 文件目录管理命令touch命令用于创建空白文件与设置文件的各种时间，格式为：“touch [选项] [文件]”。touch命令能够创建出空白的文本文件，但这实在太简单不需要去讲，例如“touch linuxprobe”这样就可以创建出一个空白的名为linuxprobe的文本文件，而有难度的操作主要是用于设置文件内容的修改时间（mtime）、文件权限或属性的更改时间（ctime）与文件的读取时间（atime）。 参数 作用 -a 仅修改访问时间“atime” -m 仅修改更改时间“mtime” -d 同时修改atime与mtime [caijy@localhost Desktop]$ ls -l 1.txt-rw-rw-r--. 1 caijy caijy 16314 Sep 12 21:42 1.txt[caijy@localhost Desktop]$ echo &quot;hello,linux&quot; &gt;&gt; 1.txt[caijy@localhost Desktop]$ ls -l 1.txt-rw-rw-r--. 1 caijy caijy 16326 Sep 13 19:46 1.txt[caijy@localhost Desktop]$ touch -d &quot;2017-06-06 12:22&quot; 1.txt[caijy@localhost Desktop]$ ls -l 1.txt-rw-rw-r--. 1 caijy caijy 16326 Jun 6 12:22 1.txt mkdir命令用于创建空白的文件夹，格式为：“mkdir [选项] 目录”。在Linux系统中文件夹是最常见的文件类型之一，除了能创建单个目录外，还可以使用“-p”参数来递归创建出具有嵌套叠层关系的文件目录。[caijy@localhost Desktop]$ mkdir linux[caijy@localhost Desktop]$ cd linux[caijy@localhost linux]$ mkdir -p a/b/c/d[caijy@localhost linux]$ cd a[caijy@localhost a]$ cd b[caijy@localhost b]$ cp命令用于复制文件或目录，格式为：“cp [选项] 源文件 目标文件”。在Linux系统中的复制操作具体还分为3种情况，第一种情况是如果目标对象是个目录，则会把源文件复制到该目录中.，第二种情况是如果目标对象也是个普通文件，则会询问是否要覆盖它.最后是第三种的情况了，如果目标文件是不存在的，则会是正常的复制操作啦。 参数 作用 -p 保留原始文件的属性 -d 若对象为”链接文件”，则保留该”链接文件”的属性 -r 递归持续复制（用于目录） -i 若目标文件存在则询问是否覆盖 -a 相当于-pdr（p,d,r为上述的参数） 首先创建一个名为install.log的普通空白文件，然后把其复制出来一份名为x.log的备份文件：[caijy@localhost Desktop]$ touch install.log[caijy@localhost Desktop]$ cp install.log x.log[caijy@localhost Desktop]$ lsinstall.log x.log mv命令用于移动文件或改名，格式为：“mv [选项] 源文件 [目标路径|目标文件名]”。剪切操作不同于复制操作，因为它会默认把源文件删除掉，操作后就只有剪切后的文件了，并且如果对一个文件在同一个目录中进行剪切操作，其实也是重命名的作用：[caijy@localhost Desktop]$ mv x.log linux.log rm命令用于删除文件或目录，格式为：“rm [选项] 文件”。使用“-i”参数删除文件时向您询问是否要执行删除操作，您可以使用“-f”参数来直接强制删除，另外想要删除一个目录文件夹的话就需要再追加一个“-r”参数才可以，否则是删除不掉的，例如来尝试删除下刚刚那两个文件吧：[caijy@localhost Desktop]$ lsinstall.log linux.log[caijy@localhost Desktop]$ rm -i install.logrm: remove regular empty file ‘install.log’? y[caijy@localhost Desktop]$ rm -rf linux.log[caijy@localhost Desktop]$ ls[caijy@localhost Desktop]$ dd命令用于指定大小的拷贝文件或指定转换文件，格式为：“dd [参数]”。dd命令是个比较重要且具有特色的一个命令，它能够让用户指定数据块的大小和个数来复制一个文件的内容，当然如果您愿意的话还可以在复制过程中转换其中的数据。Linux系统中有一个叫做/dev/zero的设备文件，这个文件不会占用您的系统存储空间，但里面却可以提供无穷无尽的数据，因此用dd命令来生成出来一个指定大小的文件是再好不过的了。 参数 作用 if 输入的文件名称。 of 输出的文件名称。 bs 设置每个“块”的大小。 count 设置要拷贝“块”的个数。 [caijy@localhost Desktop]$ dd if=/dev/zero of=560_file count=1 bs=560M1+0 records in1+0 records out587202560 bytes (587 MB) copied, 2.62394 s, 224 MB/s dd命令也绝对不仅限于复制文件这么简单，如果您想把一个光盘设备制作成iso格式的镜像文件，在Windows系统中一定免不了要用到第三方软件才能做到，但在Linux系统中就可以直接使用dd命令来复制并压制光盘设备变成一个可立即使用的iso镜像哦，例如：[root@linuxprobe ~]# dd if=/dev/cdrom of=RHEL-server-7.0-x86_64-LinuxProbe.Com.iso7311360+0 records in7311360+0 records out3743416320 bytes (3.7 GB) copied, 370.758 s, 10.1 MB/s file命令用于查看文件的类型，格式为：“file 文件名”。如此看来在Linux系统中文本、目录、设备等等这些一切都会可以被统称为文件，而咱们一般又不能单凭后缀就知道具体的文件类型，这时只能用file命令来查看下文件类型啦~[caijy@localhost Desktop]$ touch linux.log[caijy@localhost Desktop]$ file linux.loglinux.log: empty[caijy@localhost Desktop]$ file /dev/sda/dev/sda: block special 打包压缩与搜索命令tar命令用于对文件打包压缩或解压，格式为：“tar [选项] [文件]”。Linux系统中常见的格式比较多，主要使用的是.tar或.tar.gz或.tar.bz2格式，大部分都是由tar命令来完成的，首先“-c”参数是用于创建压缩文件的，“-x”参数是用于解压文件的，因此这两个不能同时放一起使用，其次“-z”参数是指定使用Gzip格式来压缩解压文件，“-j”参数是指定使用bzip2格式来压缩解压文件。解压时候则是根据文件的后缀来决定是何种格式参数，而有些打包操作要数个小时，屏幕没有输出的话您一定会怀疑电脑死机了，也不好判断打包的进度情况，因此非常推荐使用“-v”参数来不断显示压缩或解压的过程给用户，“-C”参数用于指定要解压到的哪个指定的目录，而“-f”参数特别重要，它必须放到参数的最后一位，代表要压缩或解压的软件包名称。我会一般使用“tar -czvf 压缩包名称.tar.gz 要打包的目录”命令来把指定的文件来打包压缩，解压的话则是“tar -xzvf 压缩包名称.tar.gz”命令，接下来使用tar命令把/etc目录通过gzip格式进行打包压缩，并把文件命名为etc.tar.gz：[caijy@localhost Desktop]$ tar -czvf etc.tar.gz /etctar: Removing leading `/&#39; from member names/etc//etc/fstabtar: /etc/crypttab: Cannot open: Permission denied/etc/mtab/etc/fonts//etc/fonts/conf.d//etc/fonts/conf.d/65-0-lohit-bengali.conf...... 然后把刚刚打包的压缩包文件指定解压到mydir目录中：[caijy@localhost Desktop]$ tar -xzvf etc.tar.gz -C mydiretc/etc/fstabetc/mtabetc/fonts/etc/fonts/conf.d/etc/fonts/conf.d/65-0-lohit-bengali.conf grep命令用于对文本内容进行关键词的搜索匹配，格式为：“grep [选项] [文件]”。可以把grep命令当作是用途最广泛的文本搜索匹配工具，参数虽然很多但基本是用不到的.这里只说两个最最最常用的参数，只要会使用“-n”参数显示搜索到信息的行号，使用“-v”参数用于反选信息（即没有包含关键词的所有信息行）。Linux系统中的/etc/passwd文件是保存着所有用户信息的文件，而一旦用户的登录终端被设置成“/sbin/nologin”则不再允许登录系统，因此可以通过使用grep命令来匹配出当前系统中所有不允许登录系统的用户信息：[caijy@localhost Desktop]$ grep -n /sbin/nologin /etc/passwd2:bin:x:1:1:bin:/bin:/sbin/nologin3:daemon:x:2:2:daemon:/sbin:/sbin/nologin4:adm:x:3:4:adm:/var/adm:/sbin/nologin5:lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin...... find命令用于在Linux系统中按照指定条件查找文件，格式为：“find [查找路径] 寻找条件 操作”。“Linux系统中的一切都是文件”，在Linux系统中的搜索工作一般都是通过find命令来完成的，它可以根据不同的文件特性来做为匹配项（如文件名、大小、修改时间、权限等信息），一旦匹配到了则会默认为用户显示到屏幕上来，基础的匹配项目请见下表即可。我主要讲解下“–exec”参数重要的作用，这个参数是用于把find命令搜索到的结果交由给后面的命令再进一步做处理，十分类似于后面博文提到的管道符技术。 参数 作用 -name 匹配名称 -perm 匹配权限（mode为完全匹配，-mode为包含即可） -user 匹配所有者 -group 匹配所有组 -mtime 匹配修改内容的时间（-n指n天以内，+n指n天以前） -atime -n +n 匹配访问文件的时间-n指n天以内，+n指n天以前 -ctime -n +n 匹配修改权限的时间-n指n天以内，+n指n天以前 -nouser 匹配无所有者的文件 -nogroup 匹配无所有组的文件 -newer f1 !f2 匹配比文件f1新却比f2旧的文件 –type b/d/c/p/l/f 匹配文件类型（块设备、目录、字符设备、管道、链接文件、文件文件） -size 匹配文件的大小（+50k查找超过50k的文件,而-50k则代表查找小于50k的文件） -prune 忽略某个目录 -exec {} \; 后面可接对搜索到结果进一步处理的命令（下面会有演示） Linux系统中的配置文件根据FHS协议会被保存到/etc目录中，如果要想获取到该目录中所有以host开头的文件列表就可以这样做：[caijy@localhost Desktop]$ sudo find /etc -name &quot;host*&quot; -print[sudo] password for caijy:/etc/avahi/hosts/etc/host.conf/etc/hosts 想要在整个系统中搜索所有权限中包括SUID权限的文件，只需使用减号-4000即可：[caijy@localhost Desktop]$ sudo find / -perm -4000 -print/usr/bin/fusermount/usr/bin/su/usr/bin/chage/usr/bin/gpasswd...... 转载自：http://www.linuxprobe.com/chapter-02.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础课程01]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F12%2FLinux%E5%9F%BA%E7%A1%80%E8%AF%BE%E7%A8%8B01%2F</url>
    <content type="text"><![CDATA[经济有限，笔者在虚拟机上安装的“红帽”，具体安装步骤在此不展开论述，不会的同学参考虚拟机/红帽安装及工具下载。 重置root用户密码记得笔者一次面试的时候被问到：如果忘记MySQL root用户的密码怎么办？我一想，这种问题就该直接谷歌，结果被鄙视一脸。后来查了一下，无非是几个命令。在此记录这个比较重要的问题，此处以红帽系统为例（大家先确认自己的Linux系统是不是红帽）： 重启Linux，在引导界面按“e” 在linux16参数这行的后面追加“rd.break”参数并同时一起按下键盘“ctrl“和“x”按键来执行内核参数 过一会儿便进入系统的紧急求援模式。依次输入一下命令（其中第三行命令的“123456”是你新的root用户密码）： mount -o remount,rw /sysroot chroot /sysroot echo “123456” | passwd –stdin root touch /.autorelabel exit reboot然后等待重启即可 RPM红帽软件包这里总结一下常用的软件包命令： 安装软件的命令格式:rpm -ivh filename.rpm 升级软件的命令格式:rpm -Uvh filename.rpm 卸载软件的命令格式:rpm -e filename.rpm 查询软件的描述信息的命令格式:rpm -qpi filename.rpm 列出软件的文件信息的命令格式:rpm -qpl filename.rpm 查询文件属于哪个RPM的命令格式:rpm -qf filename Yum软件仓库Yum软件仓库是为了进一步降低软件安装难度和复杂度而设计的技术，Yum软件仓库可以根据用户的要求分析出所需软件包及其相关依赖关系，然后自动从服务器下载软件包并安装到系统，下面的Yum命令过一下即可。 命令 作用 yum repolist all 列出所有仓库 yum list all 列出仓库中所有软件包 yum info 软件包名称 查看软件包信息 yum install 软件包名称 安装软件包 yum reinstall 软件包名称 重新安装软件包 yum update 软件包名称 升级软件包 yum remove 软件包名称 移除软件包 yum clean all 清除所有仓库缓存 yum check-update 检查可更新的软件包 yum grouplist 查看系统中已经安装的软件包组 yum groupinstall 软件包组 安装指定的软件包组 yum groupremove 软件包组 移除指定的软件包组 yum groupinfo 软件包组 查询指定的软件包组信息 Systemd初始化进程Linux操作系统开机过程首先从BIOS开始，进入“Boot Loader”，加载系统内核，，内核进行初始化，启动初始化进程。初始化进程作为系统第一个进程，它需要完成Linux系统中相关的初始化工作，为用户提供合适的工作环境。systemd初始化进程服务采用了并发启动机制，开机速度得到了不小的提升。红帽RHEL7系统启动时要做大量的初始化工作，例如挂在文件系统和交换分区。启动各类进程服务等操作，这些都可以看作一个个的单元（Unit），即用”目标(target)”代替了“运行级别”这个概念，区别如下表所示： Sysvinit运行级别 System目标名称 作用 0 runlevel0.target, poweroff.target 关机 1 runlevel1.target, rescue.target 单用户模式 2 runlevel2.target, multi-user.target 等同于级别3 3 runlevel3.target, multi-user.target 多用户的文本界面 4 runlevel4.target, multi-user.target 等同于级别3 5 runlevel5.target, graphical.target 多用户的图形界面 6 runlevel6.target, reboot.target 重启 emergency emergency.target 紧急Shell 红帽RHEL6系统使用service、chkconfig等命令来管理系统服务，红帽RHEL7系统中管理服务使用的是systemctl命令：systemctl管理服务的启动、重启、停止、重载、查看状态的命令： Sysvinit命令(红帽RHEL6系统) Systemctl命令（红帽RHEL7系统） 作用 service foo start systemctl start foo.service 启动服务 service foo restart systemctl restart foo.service 重启服务 service foo stop systemctl stop foo.service 停止服务 service foo reload systemctl reload foo.service 重新加载配置文件（不终止服务） service foo status systemctl status foo.service 查看服务状态 systemctl设置服务的开机启动、不启动、查看各级别下服务启动状态的命令： Sysvinit命令(红帽RHEL6系统) Systemctl命令（红帽RHEL7系统） 作用 chkconfig foo on systemctl enable foo.service 开机自动启动 chkconfig foo off systemctl disable foo.service 开机不自动启动 chkconfig foo systemctl is-enabled foo.service 查看特定服务是否为开机自启动 chkconfig –list systemctl list-unit-files –type=service 查看各个级别下服务的启动与禁用情况 转载自：http://www.linuxprobe.com/chapter-01.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[My Linux Blog]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F12%2F%E9%A6%96%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[你好，欢迎来到我的个人技术博客。 –《Linux就该这么学》读书笔记]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fsakura-hly.github.io%2F2017%2F09%2F12%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
